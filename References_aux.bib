@article{em_seq,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1555527},
 abstract = {A popular way to account for unobserved heterogeneity is to assume that the data are drawn from a finite mixture distribution. A barrier to using finite mixture models is that parameters that could previously be estimated in stages must now be estimated jointly: using mixture distributions destroys any additive separability of the log-likelihood function. We show, however, that an extension of the EM algorithm reintroduces additive separability, thus allowing one to estimate parameters sequentially during each maximization step. In establishing this result, we develop a broad class of estimators for mixture models. Returning to the likelihood problem, we show that, relative to full information maximum likelihood, our sequential estimator can generate large computational savings with little loss of efficiency.},
 author = {Peter Arcidiacono and John Bailey Jones},
 journal = {Econometrica},
 number = {3},
 pages = {933--946},
 publisher = {[Wiley, Econometric Society]},
 title = {Finite Mixture Distributions, Sequential Likelihood and the EM Algorithm},
 volume = {71},
 year = {2003}
}

@article{em,
 ISSN = {00361445},
 URL = {http://www.jstor.org/stable/2030064},
 abstract = {The problem of estimating the parameters which determine a mixture density has been the subject of a large, diverse body of literature spanning nearly ninety years. During the last two decades, the method of maximum likelihood has become the most widely followed approach to this problem, thanks primarily to the advent of high speed electronic computers. Here, we first offer a brief survey of the literature directed toward this problem and review maximum-likelihood estimation for it. We then turn to the subject of ultimate interest, which is a particular iterative procedure for numerically approximating maximum-likelihood estimates for mixture density problems. This procedure, known as the EM algorithm, is a specialization to the mixture density context of a general algorithm of the same name used to approximate maximum-likelihood estimates for incomplete data problems. We discuss the formulation and theoretical and practical properties of the EM algorithm for mixture densities, focussing in particular on mixtures of densities from exponential families.},
 author = {Richard A. Redner and Homer F. Walker},
 journal = {SIAM Review},
 number = {2},
 pages = {195--239},
 publisher = {Society for Industrial and Applied Mathematics},
 title = {Mixture Densities, Maximum Likelihood and the Em Algorithm},
 volume = {26},
 year = {1984}
}

﻿@Article{grun,
author={Gr{\"u}n, Bettina
and Leisch, Friedrich},
title={Identifiability of Finite Mixtures of Multinomial Logit Models with Varying and Fixed Effects},
journal={Journal of Classification},
year={2008},
month={Nov},
day={01},
volume={25},
number={2},
pages={225-247},
abstract={Unique parametrizations of models are very important for parameter interpretation and consistency of estimators. In this paper we analyze the identifiability of a general class of finite mixtures of multinomial logits with varying and fixed effects, which includes the popular multinomial logit and conditional logit models. The application of the general identifiability conditions is demonstrated on several important special cases and relations to previously established results are discussed. The main results are illustrated with a simulation study using artificial data and a marketing dataset of brand choices.},
issn={1432-1343},
doi={10.1007/s00357-008-9022-8},
url={https://doi.org/10.1007/s00357-008-9022-8}
}





@article{nguyen,
author = {Hien D. Nguyen and Geoffrey McLachlan},
title = {On approximations via convolution-defined mixture models},
journal = {Communications in Statistics - Theory and Methods},
volume = {48},
number = {16},
pages = {3945-3955},
year  = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/03610926.2018.1487069},

URL = { 
        https://doi.org/10.1080/03610926.2018.1487069
    
},
eprint = { 
        https://doi.org/10.1080/03610926.2018.1487069
    
}

}


@article{mcfadden,
 ISSN = {08837252, 10991255},
 URL = {http://www.jstor.org/stable/2678603},
 abstract = {This paper considers mixed, or random coefficients, multinomial logit (MMNL) models for discrete response, and establishes the following results. Under mild regularity conditions, any discrete choice model derived from random utility maximization has choice probabilities that can be approximated as closely as one pleases by a MMNL model. Practical estimation of a parametric mixing family can be carried out by Maximum Simulated Likelihood Estimation or Method of Simulated Moments, and easily computed instruments are provided that make the latter procedure fairly efficient. The adequacy of a mixing specification can be tested simply as an omitted variable test with appropriately defined artificial variables. An application to a problem of demand for alternative vehicles shows that MMNL provides a flexible and computationally practical approach to discrete response analysis.},
 author = {Daniel McFadden and Kenneth Train},
 journal = {Journal of Applied Econometrics},
 number = {5},
 pages = {447--470},
 publisher = {Wiley},
 title = {Mixed MNL Models for Discrete Response},
 volume = {15},
 year = {2000}
}

@article{TRAIN200840,
title = {EM Algorithms for nonparametric estimation of mixing distributions},
journal = {Journal of Choice Modelling},
volume = {1},
number = {1},
pages = {40-69},
year = {2008},
issn = {1755-5345},
doi = {https://doi.org/10.1016/S1755-5345(13)70022-8},
url = {https://www.sciencedirect.com/science/article/pii/S1755534513700228},
author = {Kenneth E. Train},
keywords = {Mixed logit, probit, random coefficients, EM algorithm, nonparametric estimation},
abstract = {This paper describes and implements three computationally attractive procedures for nonparametric estimation of mixing distributions in discrete choice models. The procedures are specific types of the well known EM (Expectation-Maximization) algorithm based on three different ways of approximating the mixing distribution nonparametrically: (1) a discrete distribution with mass points and frequencies treated as parameters, (2) a discrete mixture of continuous distributions, with the moments and weight for each distribution treated as parameters, and (3) a discrete distribution with fixed mass points whose frequencies are treated as parameters. The methods are illustrated with a mixed logit model of households' choices among alternative-fueled vehicles.}
}

@article{nielsen,
 ISSN = {13507265},
 URL = {http://www.jstor.org/stable/3318671},
 abstract = {The EM algorithm is a much used tool for maximum likelihood estimation in missing or incomplete data problems. However, calculating the conditional expectation required in the E-step of the algorithm may be infeasible, especially when this expectation is a large sum or a high-dimensional integral. Instead the expectation can be estimated by simulation. This is the common idea in the stochastic EM algorithm and the Monte Carlo EM algorithm. In this paper some asymptotic results for the Stochastic EM algorithm are given, and estimation based on this algorithm is discussed. In particular, asymptotic equivalence of certain simple estimators is shown, and a simulation experiment is carried out to investigate this equivalence in small and moderate samples. Furthermore, some implementation issues and the possibility of allowing unidentified parameters in the algorithm are discussed.},
 author = {Søren Feodor Nielsen},
 journal = {Bernoulli},
 number = {3},
 pages = {457--489},
 publisher = {International Statistical Institute (ISI) and Bernoulli Society for Mathematical Statistics and Probability},
 title = {The Stochastic EM Algorithm: Estimation and Asymptotic Results},
 volume = {6},
 year = {2000}
}

@article{GOLDMAN2018143,
title = {Comparing distributions by multiple testing across quantiles or CDF values},
journal = {Journal of Econometrics},
volume = {206},
number = {1},
pages = {143-166},
year = {2018},
issn = {0304-4076},
doi = {https://doi.org/10.1016/j.jeconom.2018.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0304407618300812},
author = {Matt Goldman and David M. Kaplan},
keywords = {Dirichlet, Familywise error rate, Kolmogorov–Smirnov, Probability integral transform, Regression discontinuity},
abstract = {We first show that one-sample and two-sample Kolmogorov–Smirnov tests may be interpreted as multiple testing procedures, nonparametrically testing equality at each point in the distribution with strong control of the finite-sample familywise error rate. Second, we provide an alternative procedure that distributes power across the distribution more evenly than the Kolmogorov–Smirnov test, which suffers low sensitivity to tail deviations. Third, we provide a formula for near-instant one-sample computation. Fourth, we improve power with stepdown and pre-test procedures. Finally, we extend our results to conditional distributions and regression discontinuity designs. Simulations, empirical examples, and code are provided.}
}