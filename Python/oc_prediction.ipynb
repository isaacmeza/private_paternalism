{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dca9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.load_session('.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff684151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c6733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5158399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.inspection import permutation_importance\n",
    "import multiprocessing\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3578c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceea18a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/isaac/Dropbox/Apps/ShareLaTeX/Donde2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25172534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prenda</th>\n",
       "      <th>val_pren</th>\n",
       "      <th>genero</th>\n",
       "      <th>edad</th>\n",
       "      <th>pres_antes</th>\n",
       "      <th>ahorros</th>\n",
       "      <th>cta_tanda</th>\n",
       "      <th>rec_cel</th>\n",
       "      <th>prestamo</th>\n",
       "      <th>des_c</th>\n",
       "      <th>...</th>\n",
       "      <th>dummy_prenda_tipo2</th>\n",
       "      <th>dummy_prenda_tipo3</th>\n",
       "      <th>dummy_prenda_tipo4</th>\n",
       "      <th>dummy_prenda_tipo5</th>\n",
       "      <th>dummy_educacion2</th>\n",
       "      <th>dummy_educacion3</th>\n",
       "      <th>dummy_educacion4</th>\n",
       "      <th>dummy_educacion5</th>\n",
       "      <th>dummy_plan_gasto2</th>\n",
       "      <th>dummy_plan_gasto3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78133041</td>\n",
       "      <td>1895.252563</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5521269</td>\n",
       "      <td>5566.590820</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3440</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5521268</td>\n",
       "      <td>7710.254883</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4780</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5521267</td>\n",
       "      <td>2351.094727</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1430</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42124669</td>\n",
       "      <td>3780.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1260</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prenda     val_pren  genero  edad  pres_antes  ahorros  cta_tanda  \\\n",
       "0  78133041  1895.252563       1  47.0           1        0          0   \n",
       "1   5521269  5566.590820       1  50.0           1        0          0   \n",
       "2   5521268  7710.254883       1  50.0           1        0          0   \n",
       "3   5521267  2351.094727       1  50.0           1        0          0   \n",
       "4  42124669  3780.000000       1  50.0           1        0          0   \n",
       "\n",
       "   rec_cel  prestamo  des_c  ...  dummy_prenda_tipo2  dummy_prenda_tipo3  \\\n",
       "0        0      1200      0  ...                   1                   0   \n",
       "1        0      3440      1  ...                   0                   0   \n",
       "2        0      4780      1  ...                   0                   0   \n",
       "3        0      1430      1  ...                   0                   0   \n",
       "4        1      1260      0  ...                   0                   0   \n",
       "\n",
       "   dummy_prenda_tipo4  dummy_prenda_tipo5  dummy_educacion2  dummy_educacion3  \\\n",
       "0                   0                   0                 0                 1   \n",
       "1                   0                   1                 0                 1   \n",
       "2                   0                   1                 0                 1   \n",
       "3                   0                   1                 0                 1   \n",
       "4                   0                   0                 0                 0   \n",
       "\n",
       "   dummy_educacion4  dummy_educacion5  dummy_plan_gasto2  dummy_plan_gasto3  \n",
       "0                 0                 0                  0                  0  \n",
       "1                 0                 0                  1                  0  \n",
       "2                 0                 0                  1                  0  \n",
       "3                 0                 0                  1                  0  \n",
       "4                 0                 1                  0                  0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data \n",
    "data = pd.read_csv(path + '/_aux/data_oc.csv') \n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d46f3e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinguish numerical variables\n",
    "numeric_features = ['val_pren', 'edad',  'prestamo',  'faltas']\n",
    "\n",
    "categorical_features = ['genero',\n",
    "            'pres_antes',\n",
    "            'ahorros',\n",
    "            'cta_tanda',\n",
    "            'rec_cel',\n",
    "            'tentado',\n",
    "            'dummy_prenda_tipo2',\n",
    "            'dummy_prenda_tipo3',\n",
    "            'dummy_prenda_tipo4',\n",
    "            'dummy_prenda_tipo5',\n",
    "            'dummy_educacion2',\n",
    "            'dummy_educacion3',\n",
    "            'dummy_educacion4',\n",
    "            'dummy_educacion5',\n",
    "            'dummy_plan_gasto2',\n",
    "            'dummy_plan_gasto3']\n",
    "\n",
    "# Pre-processing of numerical variables \n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('polynomial', PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse = False)\n",
    "\n",
    "\n",
    "# First step of Pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519a3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['val_pren', 'edad',  'prestamo',  'faltas', 'genero',\n",
    "            'pres_antes',\n",
    "            'ahorros',\n",
    "            'cta_tanda',\n",
    "            'rec_cel',\n",
    "            'tentado',\n",
    "            'dummy_prenda_tipo2',\n",
    "            'dummy_prenda_tipo3',\n",
    "            'dummy_prenda_tipo4',\n",
    "            'dummy_prenda_tipo5',\n",
    "            'dummy_educacion2',\n",
    "            'dummy_educacion3',\n",
    "            'dummy_educacion4',\n",
    "            'dummy_educacion5',\n",
    "            'dummy_plan_gasto2',\n",
    "            'dummy_plan_gasto3']]\n",
    "\n",
    "y = data['des_c']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be613d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__algorithm</th>\n",
       "      <th>param_model__n_neighbors</th>\n",
       "      <th>param_model__weights</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>brute</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.619211</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kd_tree</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.619211</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ball_tree</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.619211</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.619211</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__algorithm param_model__n_neighbors param_model__weights  \\\n",
       "39                  brute                        6             distance   \n",
       "29                kd_tree                        6             distance   \n",
       "19              ball_tree                        6             distance   \n",
       "9                    auto                        6             distance   \n",
       "\n",
       "    mean_test_score  std_test_score  mean_train_score  std_train_score  \n",
       "39         0.619211        0.010494               1.0              0.0  \n",
       "29         0.619211        0.010494               1.0              0.0  \n",
       "19         0.619211        0.010494               1.0              0.0  \n",
       "9          0.619211        0.010494               1.0              0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Hyperparameters - grid\n",
    "# ==============================================================================\n",
    "param_grid = {'model__n_neighbors'  : [2, 3, 4, 5, 6],\n",
    "              'model__weights'     : ['uniform', 'distance'],\n",
    "              'model__algorithm'     : ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "             }\n",
    "\n",
    "\n",
    "knn_est = KNeighborsClassifier(\n",
    "    leaf_size=30,\n",
    "    p=2,\n",
    "    metric='minkowski',\n",
    "    metric_params=None,\n",
    "    n_jobs=None)\n",
    "\n",
    "# KNN Model\n",
    "KNN = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', knn_est)])\n",
    "\n",
    "\n",
    "# Grid search by cross-validation\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(KNN,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_weighted',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Results\n",
    "# ==============================================================================\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d84bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the best model\n",
    "final_model_knn = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e174d09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>0.550285</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>0.542398</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.896340</td>\n",
       "      <td>0.035690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.531921</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.034709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.529670</td>\n",
       "      <td>0.024306</td>\n",
       "      <td>0.622494</td>\n",
       "      <td>0.033702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_model__max_depth  mean_test_score  std_test_score  mean_train_score  \\\n",
       "9                     50         0.550285        0.008763          1.000000   \n",
       "8                     20         0.542398        0.002754          0.896340   \n",
       "7                     10         0.531921        0.018136          0.690300   \n",
       "5                      7         0.529670        0.024306          0.622494   \n",
       "\n",
       "   std_train_score  \n",
       "9         0.000000  \n",
       "8         0.035690  \n",
       "7         0.034709  \n",
       "5         0.033702  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Hyperparameters - grid\n",
    "# ==============================================================================\n",
    "param_grid = {'model__max_depth'  : [2, 3, 4, 5, 6, 7, 8, 10, 20, 50]\n",
    "             }\n",
    "\n",
    "\n",
    "dt_est = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "# DT Model\n",
    "DT = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', dt_est)])\n",
    "\n",
    "\n",
    "# Grid search by cross-validation\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(DT,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_weighted',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Results\n",
    "# ==============================================================================\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68da18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the best model\n",
    "final_model_dt = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cece023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.40408076 0.39584984 0.39584984        nan 0.44758221 0.45828939\n",
      " 0.52031574        nan 0.45707716 0.48520606 0.52926188        nan\n",
      " 0.4696991  0.49418074 0.52509432        nan 0.479531   0.50241944\n",
      " 0.52923396        nan 0.48429473 0.50843824 0.52601479        nan\n",
      " 0.48869851 0.51241128 0.52694585        nan 0.49398906 0.51605127\n",
      " 0.52690194        nan 0.49508735 0.52453963 0.52146373        nan\n",
      " 0.50065746 0.53051043 0.52104156        nan 0.5031104  0.53366102\n",
      " 0.52198851        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\isaac\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the train scores are non-finite: [0.41335902 0.39581785 0.39581785        nan 0.46414898 0.47014385\n",
      " 0.5222745         nan 0.48075684 0.50402739 0.51643364        nan\n",
      " 0.49166508 0.51771431 0.51933002        nan 0.50341873 0.52578027\n",
      " 0.52491352        nan 0.5116813  0.5341228  0.52321261        nan\n",
      " 0.5171128  0.54171498 0.52556053        nan 0.52282878 0.54859435\n",
      " 0.52411287        nan 0.52971795 0.55525698 0.52171758        nan\n",
      " 0.53480106 0.55925422 0.52053286        nan 0.5398689  0.56819687\n",
      " 0.52215452        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__C</th>\n",
       "      <th>param_model__kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.533661</td>\n",
       "      <td>0.027531</td>\n",
       "      <td>0.568197</td>\n",
       "      <td>0.005540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.9</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.530510</td>\n",
       "      <td>0.026682</td>\n",
       "      <td>0.559254</td>\n",
       "      <td>0.003440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.529262</td>\n",
       "      <td>0.018166</td>\n",
       "      <td>0.516434</td>\n",
       "      <td>0.010005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.4</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.529234</td>\n",
       "      <td>0.015489</td>\n",
       "      <td>0.524914</td>\n",
       "      <td>0.013745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__C param_model__kernel  mean_test_score  std_test_score  \\\n",
       "41              1                 rbf         0.533661        0.027531   \n",
       "37            0.9                 rbf         0.530510        0.026682   \n",
       "10            0.2             sigmoid         0.529262        0.018166   \n",
       "18            0.4             sigmoid         0.529234        0.015489   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "41          0.568197         0.005540  \n",
       "37          0.559254         0.003440  \n",
       "10          0.516434         0.010005  \n",
       "18          0.524914         0.013745  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Hyperparameters - grid\n",
    "# ==============================================================================\n",
    "param_grid = {'model__kernel': ['poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "              'model__C'     : [0.01, 0.1, 0.2, 0.3, 0.4 , 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "             }\n",
    "\n",
    "\n",
    "svm_est = svm.SVC()\n",
    "\n",
    "# SVM Model\n",
    "SVM = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', svm_est)])\n",
    "\n",
    "\n",
    "# Grid search by cross-validation\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(SVM,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_weighted',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Results\n",
    "# ==============================================================================\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52c69146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the best model\n",
    "final_model_svm = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4373f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.40471605        nan        nan 0.50031809        nan\n",
      "        nan 0.53876687        nan        nan 0.54096457        nan\n",
      "        nan 0.54381484        nan        nan 0.5411435         nan\n",
      "        nan 0.54078586        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\isaac\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the train scores are non-finite: [       nan 0.40755465        nan        nan 0.50604705        nan\n",
      "        nan 0.54516609        nan        nan 0.54962339        nan\n",
      "        nan 0.55634793        nan        nan 0.56022979        nan\n",
      "        nan 0.55918139        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__C</th>\n",
       "      <th>param_model__penalty</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.543815</td>\n",
       "      <td>0.012443</td>\n",
       "      <td>0.556348</td>\n",
       "      <td>0.007073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.541144</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.560230</td>\n",
       "      <td>0.009690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.540965</td>\n",
       "      <td>0.013866</td>\n",
       "      <td>0.549623</td>\n",
       "      <td>0.002449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.540786</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.559181</td>\n",
       "      <td>0.009076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__C param_model__penalty  mean_test_score  std_test_score  \\\n",
       "13              1                   l2         0.543815        0.012443   \n",
       "16             10                   l2         0.541144        0.004759   \n",
       "10            0.1                   l2         0.540965        0.013866   \n",
       "19             20                   l2         0.540786        0.004234   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "13          0.556348         0.007073  \n",
       "16          0.560230         0.009690  \n",
       "10          0.549623         0.002449  \n",
       "19          0.559181         0.009076  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Hyperparameters - grid\n",
    "# ==============================================================================\n",
    "param_grid = {'model__penalty'  : ['l1', 'l2', 'elasticnet'],\n",
    "              'model__C'     : [0.0001, 0.001, 0.01, 0.1, 1, 10, 20]\n",
    "             }\n",
    "\n",
    "\n",
    "logit_est = LogisticRegression(random_state = 0,\n",
    "                              max_iter = 10000)\n",
    "\n",
    "# Logit Model\n",
    "LOGIT = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', logit_est)])\n",
    "\n",
    "\n",
    "# Grid search by cross-validation\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(LOGIT,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_weighted',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Results\n",
    "# ==============================================================================\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecf810eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the best model\n",
    "final_model_logit = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ca38ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2070c7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.48714724 0.48944678 0.51778418 0.56456665 0.48972944 0.49360866\n",
      " 0.541541   0.56446792 0.4915914  0.49620482 0.54853547 0.5615992\n",
      " 0.49949786 0.50151978 0.5488411  0.56891366 0.49885888 0.50180854\n",
      " 0.55329712 0.56904237 0.49979199 0.50416677 0.55716087 0.57706811\n",
      " 0.50168334 0.50555698 0.54960105 0.57776659 0.50586389 0.50797854\n",
      " 0.56061933 0.57536022 0.5066252  0.51778188 0.56698695 0.57696559\n",
      " 0.54992597 0.55168801 0.58568106 0.59715994 0.55258286 0.56126184\n",
      " 0.59230212 0.59254296 0.55773197 0.5686589  0.59435011 0.59213659\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\isaac\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the train scores are non-finite: [0.49805955 0.50043834 0.56625306 0.79451692 0.50048125 0.50765776\n",
      " 0.62127916 0.87666721 0.50569757 0.51344135 0.66388564 0.91920336\n",
      " 0.52561353 0.53180136 0.65451205 0.94542921 0.53073288 0.54588468\n",
      " 0.73054844 0.9941396  0.5380199  0.55797074 0.79528264 0.99958145\n",
      " 0.54626554 0.55364818 0.70604491 0.98408814 0.55288369 0.57298479\n",
      " 0.79528057 0.99986054 0.56051366 0.59359281 0.85476413 1.\n",
      " 0.74006792 0.76642087 0.92381309 1.         0.76642603 0.80191278\n",
      " 0.97946027 1.         0.78796211 0.8292085  0.9955343  1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6821235\ttotal: 422ms\tremaining: 3m 30s\n",
      "1:\tlearn: 0.6677906\ttotal: 695ms\tremaining: 2m 53s\n",
      "2:\tlearn: 0.6537527\ttotal: 985ms\tremaining: 2m 43s\n",
      "3:\tlearn: 0.6470815\ttotal: 1.25s\tremaining: 2m 35s\n",
      "4:\tlearn: 0.6401002\ttotal: 1.6s\tremaining: 2m 38s\n",
      "5:\tlearn: 0.6303299\ttotal: 1.87s\tremaining: 2m 34s\n",
      "6:\tlearn: 0.6231334\ttotal: 2.13s\tremaining: 2m 30s\n",
      "7:\tlearn: 0.6148067\ttotal: 2.38s\tremaining: 2m 26s\n",
      "8:\tlearn: 0.6058666\ttotal: 2.69s\tremaining: 2m 26s\n",
      "9:\tlearn: 0.5951090\ttotal: 2.98s\tremaining: 2m 25s\n",
      "10:\tlearn: 0.5922606\ttotal: 3.25s\tremaining: 2m 24s\n",
      "11:\tlearn: 0.5851274\ttotal: 3.53s\tremaining: 2m 23s\n",
      "12:\tlearn: 0.5820496\ttotal: 3.79s\tremaining: 2m 21s\n",
      "13:\tlearn: 0.5773835\ttotal: 4.08s\tremaining: 2m 21s\n",
      "14:\tlearn: 0.5723414\ttotal: 4.37s\tremaining: 2m 21s\n",
      "15:\tlearn: 0.5667039\ttotal: 4.7s\tremaining: 2m 22s\n",
      "16:\tlearn: 0.5591125\ttotal: 4.97s\tremaining: 2m 21s\n",
      "17:\tlearn: 0.5538084\ttotal: 5.25s\tremaining: 2m 20s\n",
      "18:\tlearn: 0.5517967\ttotal: 5.57s\tremaining: 2m 20s\n",
      "19:\tlearn: 0.5492412\ttotal: 5.91s\tremaining: 2m 21s\n",
      "20:\tlearn: 0.5450687\ttotal: 6.21s\tremaining: 2m 21s\n",
      "21:\tlearn: 0.5438461\ttotal: 6.33s\tremaining: 2m 17s\n",
      "22:\tlearn: 0.5396055\ttotal: 6.61s\tremaining: 2m 17s\n",
      "23:\tlearn: 0.5370966\ttotal: 6.88s\tremaining: 2m 16s\n",
      "24:\tlearn: 0.5343947\ttotal: 7.16s\tremaining: 2m 16s\n",
      "25:\tlearn: 0.5311615\ttotal: 7.46s\tremaining: 2m 16s\n",
      "26:\tlearn: 0.5282979\ttotal: 7.81s\tremaining: 2m 16s\n",
      "27:\tlearn: 0.5236867\ttotal: 8.16s\tremaining: 2m 17s\n",
      "28:\tlearn: 0.5215837\ttotal: 8.46s\tremaining: 2m 17s\n",
      "29:\tlearn: 0.5193320\ttotal: 8.81s\tremaining: 2m 18s\n",
      "30:\tlearn: 0.5163958\ttotal: 9.12s\tremaining: 2m 18s\n",
      "31:\tlearn: 0.5134407\ttotal: 9.41s\tremaining: 2m 17s\n",
      "32:\tlearn: 0.5089768\ttotal: 9.73s\tremaining: 2m 17s\n",
      "33:\tlearn: 0.5067004\ttotal: 10s\tremaining: 2m 17s\n",
      "34:\tlearn: 0.5038458\ttotal: 10.3s\tremaining: 2m 17s\n",
      "35:\tlearn: 0.5010496\ttotal: 10.7s\tremaining: 2m 17s\n",
      "36:\tlearn: 0.4985010\ttotal: 11s\tremaining: 2m 17s\n",
      "37:\tlearn: 0.4954157\ttotal: 11.3s\tremaining: 2m 17s\n",
      "38:\tlearn: 0.4929970\ttotal: 11.6s\tremaining: 2m 17s\n",
      "39:\tlearn: 0.4896616\ttotal: 11.9s\tremaining: 2m 16s\n",
      "40:\tlearn: 0.4847268\ttotal: 12.3s\tremaining: 2m 17s\n",
      "41:\tlearn: 0.4823925\ttotal: 12.5s\tremaining: 2m 16s\n",
      "42:\tlearn: 0.4797410\ttotal: 12.8s\tremaining: 2m 15s\n",
      "43:\tlearn: 0.4775882\ttotal: 13.1s\tremaining: 2m 15s\n",
      "44:\tlearn: 0.4752236\ttotal: 13.4s\tremaining: 2m 15s\n",
      "45:\tlearn: 0.4710061\ttotal: 13.7s\tremaining: 2m 14s\n",
      "46:\tlearn: 0.4699948\ttotal: 13.9s\tremaining: 2m 14s\n",
      "47:\tlearn: 0.4631304\ttotal: 14.2s\tremaining: 2m 13s\n",
      "48:\tlearn: 0.4619448\ttotal: 14.5s\tremaining: 2m 13s\n",
      "49:\tlearn: 0.4609697\ttotal: 14.8s\tremaining: 2m 12s\n",
      "50:\tlearn: 0.4602813\ttotal: 15.1s\tremaining: 2m 12s\n",
      "51:\tlearn: 0.4567609\ttotal: 15.3s\tremaining: 2m 11s\n",
      "52:\tlearn: 0.4558686\ttotal: 15.6s\tremaining: 2m 11s\n",
      "53:\tlearn: 0.4549065\ttotal: 15.9s\tremaining: 2m 11s\n",
      "54:\tlearn: 0.4505016\ttotal: 16.2s\tremaining: 2m 10s\n",
      "55:\tlearn: 0.4461370\ttotal: 16.4s\tremaining: 2m 10s\n",
      "56:\tlearn: 0.4430408\ttotal: 16.7s\tremaining: 2m 9s\n",
      "57:\tlearn: 0.4391453\ttotal: 17s\tremaining: 2m 9s\n",
      "58:\tlearn: 0.4355592\ttotal: 17.3s\tremaining: 2m 9s\n",
      "59:\tlearn: 0.4333148\ttotal: 17.5s\tremaining: 2m 8s\n",
      "60:\tlearn: 0.4321272\ttotal: 17.8s\tremaining: 2m 7s\n",
      "61:\tlearn: 0.4295880\ttotal: 18.1s\tremaining: 2m 7s\n",
      "62:\tlearn: 0.4280578\ttotal: 18.3s\tremaining: 2m 6s\n",
      "63:\tlearn: 0.4267866\ttotal: 18.6s\tremaining: 2m 6s\n",
      "64:\tlearn: 0.4225061\ttotal: 18.8s\tremaining: 2m 6s\n",
      "65:\tlearn: 0.4206129\ttotal: 19.2s\tremaining: 2m 5s\n",
      "66:\tlearn: 0.4189566\ttotal: 19.4s\tremaining: 2m 5s\n",
      "67:\tlearn: 0.4154910\ttotal: 19.7s\tremaining: 2m 5s\n",
      "68:\tlearn: 0.4139642\ttotal: 20s\tremaining: 2m 5s\n",
      "69:\tlearn: 0.4119302\ttotal: 20.4s\tremaining: 2m 5s\n",
      "70:\tlearn: 0.4103014\ttotal: 20.6s\tremaining: 2m 4s\n",
      "71:\tlearn: 0.4075044\ttotal: 20.9s\tremaining: 2m 4s\n",
      "72:\tlearn: 0.4059715\ttotal: 21.2s\tremaining: 2m 4s\n",
      "73:\tlearn: 0.4041588\ttotal: 21.5s\tremaining: 2m 4s\n",
      "74:\tlearn: 0.4021308\ttotal: 21.8s\tremaining: 2m 3s\n",
      "75:\tlearn: 0.4007370\ttotal: 22.2s\tremaining: 2m 3s\n",
      "76:\tlearn: 0.3967742\ttotal: 22.5s\tremaining: 2m 3s\n",
      "77:\tlearn: 0.3939425\ttotal: 22.8s\tremaining: 2m 3s\n",
      "78:\tlearn: 0.3913982\ttotal: 23.1s\tremaining: 2m 3s\n",
      "79:\tlearn: 0.3881328\ttotal: 23.3s\tremaining: 2m 2s\n",
      "80:\tlearn: 0.3869351\ttotal: 23.6s\tremaining: 2m 2s\n",
      "81:\tlearn: 0.3832455\ttotal: 23.9s\tremaining: 2m 1s\n",
      "82:\tlearn: 0.3803611\ttotal: 24.2s\tremaining: 2m 1s\n",
      "83:\tlearn: 0.3760689\ttotal: 24.5s\tremaining: 2m 1s\n",
      "84:\tlearn: 0.3743549\ttotal: 24.8s\tremaining: 2m 1s\n",
      "85:\tlearn: 0.3726898\ttotal: 25.1s\tremaining: 2m\n",
      "86:\tlearn: 0.3713376\ttotal: 25.3s\tremaining: 2m\n",
      "87:\tlearn: 0.3695115\ttotal: 25.6s\tremaining: 1m 59s\n",
      "88:\tlearn: 0.3667720\ttotal: 25.9s\tremaining: 1m 59s\n",
      "89:\tlearn: 0.3648619\ttotal: 26.2s\tremaining: 1m 59s\n",
      "90:\tlearn: 0.3625975\ttotal: 26.5s\tremaining: 1m 59s\n",
      "91:\tlearn: 0.3619631\ttotal: 26.7s\tremaining: 1m 58s\n",
      "92:\tlearn: 0.3597178\ttotal: 27s\tremaining: 1m 58s\n",
      "93:\tlearn: 0.3579757\ttotal: 27.2s\tremaining: 1m 57s\n",
      "94:\tlearn: 0.3554831\ttotal: 27.5s\tremaining: 1m 57s\n",
      "95:\tlearn: 0.3524421\ttotal: 27.7s\tremaining: 1m 56s\n",
      "96:\tlearn: 0.3512753\ttotal: 28s\tremaining: 1m 56s\n",
      "97:\tlearn: 0.3504583\ttotal: 28.3s\tremaining: 1m 56s\n",
      "98:\tlearn: 0.3478924\ttotal: 28.5s\tremaining: 1m 55s\n",
      "99:\tlearn: 0.3465370\ttotal: 28.8s\tremaining: 1m 55s\n",
      "100:\tlearn: 0.3456056\ttotal: 29s\tremaining: 1m 54s\n",
      "101:\tlearn: 0.3446618\ttotal: 29.3s\tremaining: 1m 54s\n",
      "102:\tlearn: 0.3435076\ttotal: 29.6s\tremaining: 1m 54s\n",
      "103:\tlearn: 0.3402761\ttotal: 29.9s\tremaining: 1m 53s\n",
      "104:\tlearn: 0.3368646\ttotal: 30.1s\tremaining: 1m 53s\n",
      "105:\tlearn: 0.3356230\ttotal: 30.4s\tremaining: 1m 53s\n",
      "106:\tlearn: 0.3345582\ttotal: 30.7s\tremaining: 1m 52s\n",
      "107:\tlearn: 0.3327222\ttotal: 30.9s\tremaining: 1m 52s\n",
      "108:\tlearn: 0.3316258\ttotal: 31.2s\tremaining: 1m 51s\n",
      "109:\tlearn: 0.3301450\ttotal: 31.5s\tremaining: 1m 51s\n",
      "110:\tlearn: 0.3293555\ttotal: 31.8s\tremaining: 1m 51s\n",
      "111:\tlearn: 0.3279413\ttotal: 32.1s\tremaining: 1m 51s\n",
      "112:\tlearn: 0.3272438\ttotal: 32.4s\tremaining: 1m 50s\n",
      "113:\tlearn: 0.3257002\ttotal: 32.7s\tremaining: 1m 50s\n",
      "114:\tlearn: 0.3241804\ttotal: 32.9s\tremaining: 1m 50s\n",
      "115:\tlearn: 0.3205668\ttotal: 33.2s\tremaining: 1m 49s\n",
      "116:\tlearn: 0.3194472\ttotal: 33.5s\tremaining: 1m 49s\n",
      "117:\tlearn: 0.3165684\ttotal: 33.8s\tremaining: 1m 49s\n",
      "118:\tlearn: 0.3155376\ttotal: 34.1s\tremaining: 1m 49s\n",
      "119:\tlearn: 0.3149142\ttotal: 34.3s\tremaining: 1m 48s\n",
      "120:\tlearn: 0.3131732\ttotal: 34.6s\tremaining: 1m 48s\n",
      "121:\tlearn: 0.3125758\ttotal: 34.9s\tremaining: 1m 48s\n",
      "122:\tlearn: 0.3110332\ttotal: 35.2s\tremaining: 1m 47s\n",
      "123:\tlearn: 0.3093242\ttotal: 35.4s\tremaining: 1m 47s\n",
      "124:\tlearn: 0.3082043\ttotal: 35.7s\tremaining: 1m 47s\n",
      "125:\tlearn: 0.3072411\ttotal: 36s\tremaining: 1m 46s\n",
      "126:\tlearn: 0.3043455\ttotal: 36.3s\tremaining: 1m 46s\n",
      "127:\tlearn: 0.3034606\ttotal: 36.6s\tremaining: 1m 46s\n",
      "128:\tlearn: 0.3027871\ttotal: 36.9s\tremaining: 1m 46s\n",
      "129:\tlearn: 0.3016496\ttotal: 37.3s\tremaining: 1m 46s\n",
      "130:\tlearn: 0.3001187\ttotal: 37.7s\tremaining: 1m 46s\n",
      "131:\tlearn: 0.2973781\ttotal: 38s\tremaining: 1m 45s\n",
      "132:\tlearn: 0.2956958\ttotal: 38.4s\tremaining: 1m 45s\n",
      "133:\tlearn: 0.2944279\ttotal: 38.7s\tremaining: 1m 45s\n",
      "134:\tlearn: 0.2936410\ttotal: 39s\tremaining: 1m 45s\n",
      "135:\tlearn: 0.2922413\ttotal: 39.3s\tremaining: 1m 45s\n",
      "136:\tlearn: 0.2907977\ttotal: 39.6s\tremaining: 1m 44s\n",
      "137:\tlearn: 0.2879350\ttotal: 39.8s\tremaining: 1m 44s\n",
      "138:\tlearn: 0.2855006\ttotal: 40.1s\tremaining: 1m 44s\n",
      "139:\tlearn: 0.2842370\ttotal: 40.4s\tremaining: 1m 43s\n",
      "140:\tlearn: 0.2836341\ttotal: 40.6s\tremaining: 1m 43s\n",
      "141:\tlearn: 0.2826776\ttotal: 40.9s\tremaining: 1m 43s\n",
      "142:\tlearn: 0.2820467\ttotal: 41.1s\tremaining: 1m 42s\n",
      "143:\tlearn: 0.2807224\ttotal: 41.4s\tremaining: 1m 42s\n",
      "144:\tlearn: 0.2798565\ttotal: 41.8s\tremaining: 1m 42s\n",
      "145:\tlearn: 0.2792686\ttotal: 42s\tremaining: 1m 41s\n",
      "146:\tlearn: 0.2782617\ttotal: 42.3s\tremaining: 1m 41s\n",
      "147:\tlearn: 0.2770361\ttotal: 42.6s\tremaining: 1m 41s\n",
      "148:\tlearn: 0.2754514\ttotal: 42.9s\tremaining: 1m 41s\n",
      "149:\tlearn: 0.2741066\ttotal: 43.2s\tremaining: 1m 40s\n",
      "150:\tlearn: 0.2733843\ttotal: 43.5s\tremaining: 1m 40s\n",
      "151:\tlearn: 0.2730500\ttotal: 43.7s\tremaining: 1m 40s\n",
      "152:\tlearn: 0.2724605\ttotal: 44s\tremaining: 1m 39s\n",
      "153:\tlearn: 0.2712360\ttotal: 44.3s\tremaining: 1m 39s\n",
      "154:\tlearn: 0.2703874\ttotal: 44.6s\tremaining: 1m 39s\n",
      "155:\tlearn: 0.2677705\ttotal: 44.8s\tremaining: 1m 38s\n",
      "156:\tlearn: 0.2663682\ttotal: 45.2s\tremaining: 1m 38s\n",
      "157:\tlearn: 0.2648479\ttotal: 45.5s\tremaining: 1m 38s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 0.2638876\ttotal: 45.8s\tremaining: 1m 38s\n",
      "159:\tlearn: 0.2627658\ttotal: 46.1s\tremaining: 1m 37s\n",
      "160:\tlearn: 0.2615277\ttotal: 46.4s\tremaining: 1m 37s\n",
      "161:\tlearn: 0.2599443\ttotal: 46.7s\tremaining: 1m 37s\n",
      "162:\tlearn: 0.2583400\ttotal: 47s\tremaining: 1m 37s\n",
      "163:\tlearn: 0.2579596\ttotal: 47.3s\tremaining: 1m 36s\n",
      "164:\tlearn: 0.2567733\ttotal: 47.6s\tremaining: 1m 36s\n",
      "165:\tlearn: 0.2553567\ttotal: 47.9s\tremaining: 1m 36s\n",
      "166:\tlearn: 0.2548102\ttotal: 48.2s\tremaining: 1m 36s\n",
      "167:\tlearn: 0.2536932\ttotal: 48.5s\tremaining: 1m 35s\n",
      "168:\tlearn: 0.2517863\ttotal: 48.8s\tremaining: 1m 35s\n",
      "169:\tlearn: 0.2500416\ttotal: 49.1s\tremaining: 1m 35s\n",
      "170:\tlearn: 0.2496646\ttotal: 49.4s\tremaining: 1m 35s\n",
      "171:\tlearn: 0.2493633\ttotal: 49.7s\tremaining: 1m 34s\n",
      "172:\tlearn: 0.2470389\ttotal: 50s\tremaining: 1m 34s\n",
      "173:\tlearn: 0.2460360\ttotal: 50.4s\tremaining: 1m 34s\n",
      "174:\tlearn: 0.2447864\ttotal: 50.6s\tremaining: 1m 34s\n",
      "175:\tlearn: 0.2431603\ttotal: 50.9s\tremaining: 1m 33s\n",
      "176:\tlearn: 0.2423083\ttotal: 51.2s\tremaining: 1m 33s\n",
      "177:\tlearn: 0.2415818\ttotal: 51.5s\tremaining: 1m 33s\n",
      "178:\tlearn: 0.2404042\ttotal: 51.8s\tremaining: 1m 32s\n",
      "179:\tlearn: 0.2396403\ttotal: 52.1s\tremaining: 1m 32s\n",
      "180:\tlearn: 0.2377078\ttotal: 52.4s\tremaining: 1m 32s\n",
      "181:\tlearn: 0.2356201\ttotal: 52.7s\tremaining: 1m 32s\n",
      "182:\tlearn: 0.2349662\ttotal: 53.1s\tremaining: 1m 32s\n",
      "183:\tlearn: 0.2342431\ttotal: 53.5s\tremaining: 1m 31s\n",
      "184:\tlearn: 0.2329303\ttotal: 53.8s\tremaining: 1m 31s\n",
      "185:\tlearn: 0.2321173\ttotal: 54.1s\tremaining: 1m 31s\n",
      "186:\tlearn: 0.2313013\ttotal: 54.5s\tremaining: 1m 31s\n",
      "187:\tlearn: 0.2307830\ttotal: 54.8s\tremaining: 1m 31s\n",
      "188:\tlearn: 0.2297817\ttotal: 55.1s\tremaining: 1m 30s\n",
      "189:\tlearn: 0.2289738\ttotal: 55.4s\tremaining: 1m 30s\n",
      "190:\tlearn: 0.2273822\ttotal: 55.7s\tremaining: 1m 30s\n",
      "191:\tlearn: 0.2263406\ttotal: 55.9s\tremaining: 1m 29s\n",
      "192:\tlearn: 0.2256446\ttotal: 56.2s\tremaining: 1m 29s\n",
      "193:\tlearn: 0.2251773\ttotal: 56.5s\tremaining: 1m 29s\n",
      "194:\tlearn: 0.2245693\ttotal: 56.8s\tremaining: 1m 28s\n",
      "195:\tlearn: 0.2233002\ttotal: 57.1s\tremaining: 1m 28s\n",
      "196:\tlearn: 0.2224082\ttotal: 57.4s\tremaining: 1m 28s\n",
      "197:\tlearn: 0.2213105\ttotal: 57.6s\tremaining: 1m 27s\n",
      "198:\tlearn: 0.2206773\ttotal: 57.9s\tremaining: 1m 27s\n",
      "199:\tlearn: 0.2194871\ttotal: 58.2s\tremaining: 1m 27s\n",
      "200:\tlearn: 0.2191968\ttotal: 58.5s\tremaining: 1m 27s\n",
      "201:\tlearn: 0.2179330\ttotal: 58.8s\tremaining: 1m 26s\n",
      "202:\tlearn: 0.2172780\ttotal: 59.1s\tremaining: 1m 26s\n",
      "203:\tlearn: 0.2156034\ttotal: 59.4s\tremaining: 1m 26s\n",
      "204:\tlearn: 0.2154150\ttotal: 59.8s\tremaining: 1m 26s\n",
      "205:\tlearn: 0.2149709\ttotal: 1m\tremaining: 1m 25s\n",
      "206:\tlearn: 0.2146152\ttotal: 1m\tremaining: 1m 25s\n",
      "207:\tlearn: 0.2136867\ttotal: 1m\tremaining: 1m 25s\n",
      "208:\tlearn: 0.2127077\ttotal: 1m 1s\tremaining: 1m 25s\n",
      "209:\tlearn: 0.2115841\ttotal: 1m 1s\tremaining: 1m 24s\n",
      "210:\tlearn: 0.2108193\ttotal: 1m 1s\tremaining: 1m 24s\n",
      "211:\tlearn: 0.2094351\ttotal: 1m 1s\tremaining: 1m 24s\n",
      "212:\tlearn: 0.2089250\ttotal: 1m 2s\tremaining: 1m 23s\n",
      "213:\tlearn: 0.2081764\ttotal: 1m 2s\tremaining: 1m 23s\n",
      "214:\tlearn: 0.2072399\ttotal: 1m 2s\tremaining: 1m 23s\n",
      "215:\tlearn: 0.2060826\ttotal: 1m 2s\tremaining: 1m 22s\n",
      "216:\tlearn: 0.2055896\ttotal: 1m 3s\tremaining: 1m 22s\n",
      "217:\tlearn: 0.2040429\ttotal: 1m 3s\tremaining: 1m 22s\n",
      "218:\tlearn: 0.2032316\ttotal: 1m 3s\tremaining: 1m 21s\n",
      "219:\tlearn: 0.2021975\ttotal: 1m 4s\tremaining: 1m 21s\n",
      "220:\tlearn: 0.2013726\ttotal: 1m 4s\tremaining: 1m 21s\n",
      "221:\tlearn: 0.1998743\ttotal: 1m 4s\tremaining: 1m 20s\n",
      "222:\tlearn: 0.1995411\ttotal: 1m 4s\tremaining: 1m 20s\n",
      "223:\tlearn: 0.1986375\ttotal: 1m 5s\tremaining: 1m 20s\n",
      "224:\tlearn: 0.1975848\ttotal: 1m 5s\tremaining: 1m 20s\n",
      "225:\tlearn: 0.1968299\ttotal: 1m 5s\tremaining: 1m 19s\n",
      "226:\tlearn: 0.1956414\ttotal: 1m 5s\tremaining: 1m 19s\n",
      "227:\tlearn: 0.1951572\ttotal: 1m 6s\tremaining: 1m 19s\n",
      "228:\tlearn: 0.1947484\ttotal: 1m 6s\tremaining: 1m 18s\n",
      "229:\tlearn: 0.1935432\ttotal: 1m 6s\tremaining: 1m 18s\n",
      "230:\tlearn: 0.1924137\ttotal: 1m 7s\tremaining: 1m 18s\n",
      "231:\tlearn: 0.1915269\ttotal: 1m 7s\tremaining: 1m 17s\n",
      "232:\tlearn: 0.1908314\ttotal: 1m 7s\tremaining: 1m 17s\n",
      "233:\tlearn: 0.1903190\ttotal: 1m 7s\tremaining: 1m 17s\n",
      "234:\tlearn: 0.1893010\ttotal: 1m 8s\tremaining: 1m 16s\n",
      "235:\tlearn: 0.1884412\ttotal: 1m 8s\tremaining: 1m 16s\n",
      "236:\tlearn: 0.1870129\ttotal: 1m 8s\tremaining: 1m 16s\n",
      "237:\tlearn: 0.1863808\ttotal: 1m 9s\tremaining: 1m 16s\n",
      "238:\tlearn: 0.1851735\ttotal: 1m 9s\tremaining: 1m 15s\n",
      "239:\tlearn: 0.1845215\ttotal: 1m 9s\tremaining: 1m 15s\n",
      "240:\tlearn: 0.1835063\ttotal: 1m 10s\tremaining: 1m 15s\n",
      "241:\tlearn: 0.1826509\ttotal: 1m 10s\tremaining: 1m 15s\n",
      "242:\tlearn: 0.1820087\ttotal: 1m 10s\tremaining: 1m 14s\n",
      "243:\tlearn: 0.1814667\ttotal: 1m 11s\tremaining: 1m 14s\n",
      "244:\tlearn: 0.1810418\ttotal: 1m 11s\tremaining: 1m 14s\n",
      "245:\tlearn: 0.1802835\ttotal: 1m 11s\tremaining: 1m 13s\n",
      "246:\tlearn: 0.1800086\ttotal: 1m 11s\tremaining: 1m 13s\n",
      "247:\tlearn: 0.1797569\ttotal: 1m 12s\tremaining: 1m 13s\n",
      "248:\tlearn: 0.1791714\ttotal: 1m 12s\tremaining: 1m 13s\n",
      "249:\tlearn: 0.1786061\ttotal: 1m 12s\tremaining: 1m 12s\n",
      "250:\tlearn: 0.1773395\ttotal: 1m 13s\tremaining: 1m 12s\n",
      "251:\tlearn: 0.1766881\ttotal: 1m 13s\tremaining: 1m 12s\n",
      "252:\tlearn: 0.1756320\ttotal: 1m 13s\tremaining: 1m 11s\n",
      "253:\tlearn: 0.1748077\ttotal: 1m 13s\tremaining: 1m 11s\n",
      "254:\tlearn: 0.1739776\ttotal: 1m 14s\tremaining: 1m 11s\n",
      "255:\tlearn: 0.1727477\ttotal: 1m 14s\tremaining: 1m 10s\n",
      "256:\tlearn: 0.1721780\ttotal: 1m 14s\tremaining: 1m 10s\n",
      "257:\tlearn: 0.1717730\ttotal: 1m 15s\tremaining: 1m 10s\n",
      "258:\tlearn: 0.1710477\ttotal: 1m 15s\tremaining: 1m 10s\n",
      "259:\tlearn: 0.1706883\ttotal: 1m 15s\tremaining: 1m 9s\n",
      "260:\tlearn: 0.1699705\ttotal: 1m 15s\tremaining: 1m 9s\n",
      "261:\tlearn: 0.1695556\ttotal: 1m 16s\tremaining: 1m 9s\n",
      "262:\tlearn: 0.1690677\ttotal: 1m 16s\tremaining: 1m 8s\n",
      "263:\tlearn: 0.1687213\ttotal: 1m 16s\tremaining: 1m 8s\n",
      "264:\tlearn: 0.1677979\ttotal: 1m 16s\tremaining: 1m 8s\n",
      "265:\tlearn: 0.1674247\ttotal: 1m 17s\tremaining: 1m 7s\n",
      "266:\tlearn: 0.1667399\ttotal: 1m 17s\tremaining: 1m 7s\n",
      "267:\tlearn: 0.1657789\ttotal: 1m 17s\tremaining: 1m 7s\n",
      "268:\tlearn: 0.1650296\ttotal: 1m 18s\tremaining: 1m 7s\n",
      "269:\tlearn: 0.1645088\ttotal: 1m 18s\tremaining: 1m 6s\n",
      "270:\tlearn: 0.1642086\ttotal: 1m 18s\tremaining: 1m 6s\n",
      "271:\tlearn: 0.1631670\ttotal: 1m 18s\tremaining: 1m 6s\n",
      "272:\tlearn: 0.1624216\ttotal: 1m 19s\tremaining: 1m 5s\n",
      "273:\tlearn: 0.1615755\ttotal: 1m 19s\tremaining: 1m 5s\n",
      "274:\tlearn: 0.1612587\ttotal: 1m 19s\tremaining: 1m 5s\n",
      "275:\tlearn: 0.1608656\ttotal: 1m 19s\tremaining: 1m 4s\n",
      "276:\tlearn: 0.1598108\ttotal: 1m 20s\tremaining: 1m 4s\n",
      "277:\tlearn: 0.1587432\ttotal: 1m 20s\tremaining: 1m 4s\n",
      "278:\tlearn: 0.1581246\ttotal: 1m 20s\tremaining: 1m 4s\n",
      "279:\tlearn: 0.1576287\ttotal: 1m 21s\tremaining: 1m 3s\n",
      "280:\tlearn: 0.1574673\ttotal: 1m 21s\tremaining: 1m 3s\n",
      "281:\tlearn: 0.1571825\ttotal: 1m 21s\tremaining: 1m 3s\n",
      "282:\tlearn: 0.1569310\ttotal: 1m 21s\tremaining: 1m 2s\n",
      "283:\tlearn: 0.1560988\ttotal: 1m 22s\tremaining: 1m 2s\n",
      "284:\tlearn: 0.1556436\ttotal: 1m 22s\tremaining: 1m 2s\n",
      "285:\tlearn: 0.1548056\ttotal: 1m 22s\tremaining: 1m 1s\n",
      "286:\tlearn: 0.1538424\ttotal: 1m 23s\tremaining: 1m 1s\n",
      "287:\tlearn: 0.1526489\ttotal: 1m 23s\tremaining: 1m 1s\n",
      "288:\tlearn: 0.1522720\ttotal: 1m 23s\tremaining: 1m 1s\n",
      "289:\tlearn: 0.1520197\ttotal: 1m 24s\tremaining: 1m\n",
      "290:\tlearn: 0.1514213\ttotal: 1m 24s\tremaining: 1m\n",
      "291:\tlearn: 0.1510167\ttotal: 1m 24s\tremaining: 1m\n",
      "292:\tlearn: 0.1507869\ttotal: 1m 24s\tremaining: 60s\n",
      "293:\tlearn: 0.1506589\ttotal: 1m 25s\tremaining: 59.7s\n",
      "294:\tlearn: 0.1499016\ttotal: 1m 25s\tremaining: 59.5s\n",
      "295:\tlearn: 0.1494015\ttotal: 1m 25s\tremaining: 59.2s\n",
      "296:\tlearn: 0.1491530\ttotal: 1m 26s\tremaining: 58.9s\n",
      "297:\tlearn: 0.1487796\ttotal: 1m 26s\tremaining: 58.7s\n",
      "298:\tlearn: 0.1479370\ttotal: 1m 26s\tremaining: 58.4s\n",
      "299:\tlearn: 0.1477464\ttotal: 1m 27s\tremaining: 58.1s\n",
      "300:\tlearn: 0.1468812\ttotal: 1m 27s\tremaining: 57.8s\n",
      "301:\tlearn: 0.1463300\ttotal: 1m 27s\tremaining: 57.5s\n",
      "302:\tlearn: 0.1458964\ttotal: 1m 28s\tremaining: 57.2s\n",
      "303:\tlearn: 0.1450778\ttotal: 1m 28s\tremaining: 57s\n",
      "304:\tlearn: 0.1442666\ttotal: 1m 28s\tremaining: 56.6s\n",
      "305:\tlearn: 0.1440697\ttotal: 1m 28s\tremaining: 56.4s\n",
      "306:\tlearn: 0.1437398\ttotal: 1m 29s\tremaining: 56.1s\n",
      "307:\tlearn: 0.1435427\ttotal: 1m 29s\tremaining: 55.8s\n",
      "308:\tlearn: 0.1431583\ttotal: 1m 29s\tremaining: 55.6s\n",
      "309:\tlearn: 0.1424998\ttotal: 1m 30s\tremaining: 55.3s\n",
      "310:\tlearn: 0.1419231\ttotal: 1m 30s\tremaining: 55s\n",
      "311:\tlearn: 0.1414518\ttotal: 1m 30s\tremaining: 54.7s\n",
      "312:\tlearn: 0.1406348\ttotal: 1m 31s\tremaining: 54.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313:\tlearn: 0.1401654\ttotal: 1m 31s\tremaining: 54.1s\n",
      "314:\tlearn: 0.1400155\ttotal: 1m 31s\tremaining: 53.8s\n",
      "315:\tlearn: 0.1393280\ttotal: 1m 31s\tremaining: 53.5s\n",
      "316:\tlearn: 0.1386488\ttotal: 1m 32s\tremaining: 53.2s\n",
      "317:\tlearn: 0.1378516\ttotal: 1m 32s\tremaining: 53s\n",
      "318:\tlearn: 0.1375302\ttotal: 1m 32s\tremaining: 52.7s\n",
      "319:\tlearn: 0.1367554\ttotal: 1m 33s\tremaining: 52.4s\n",
      "320:\tlearn: 0.1362086\ttotal: 1m 33s\tremaining: 52.1s\n",
      "321:\tlearn: 0.1358255\ttotal: 1m 33s\tremaining: 51.8s\n",
      "322:\tlearn: 0.1354790\ttotal: 1m 34s\tremaining: 51.5s\n",
      "323:\tlearn: 0.1352131\ttotal: 1m 34s\tremaining: 51.2s\n",
      "324:\tlearn: 0.1346924\ttotal: 1m 34s\tremaining: 50.9s\n",
      "325:\tlearn: 0.1341660\ttotal: 1m 34s\tremaining: 50.7s\n",
      "326:\tlearn: 0.1331971\ttotal: 1m 35s\tremaining: 50.4s\n",
      "327:\tlearn: 0.1327841\ttotal: 1m 35s\tremaining: 50.2s\n",
      "328:\tlearn: 0.1322894\ttotal: 1m 35s\tremaining: 49.9s\n",
      "329:\tlearn: 0.1320278\ttotal: 1m 36s\tremaining: 49.6s\n",
      "330:\tlearn: 0.1314698\ttotal: 1m 36s\tremaining: 49.4s\n",
      "331:\tlearn: 0.1311890\ttotal: 1m 36s\tremaining: 49.1s\n",
      "332:\tlearn: 0.1307401\ttotal: 1m 37s\tremaining: 48.8s\n",
      "333:\tlearn: 0.1304052\ttotal: 1m 37s\tremaining: 48.5s\n",
      "334:\tlearn: 0.1298702\ttotal: 1m 37s\tremaining: 48.2s\n",
      "335:\tlearn: 0.1292745\ttotal: 1m 38s\tremaining: 47.9s\n",
      "336:\tlearn: 0.1287982\ttotal: 1m 38s\tremaining: 47.7s\n",
      "337:\tlearn: 0.1283601\ttotal: 1m 38s\tremaining: 47.4s\n",
      "338:\tlearn: 0.1281960\ttotal: 1m 39s\tremaining: 47.1s\n",
      "339:\tlearn: 0.1279126\ttotal: 1m 39s\tremaining: 46.7s\n",
      "340:\tlearn: 0.1273135\ttotal: 1m 39s\tremaining: 46.4s\n",
      "341:\tlearn: 0.1271179\ttotal: 1m 39s\tremaining: 46.2s\n",
      "342:\tlearn: 0.1268961\ttotal: 1m 40s\tremaining: 45.9s\n",
      "343:\tlearn: 0.1263529\ttotal: 1m 40s\tremaining: 45.6s\n",
      "344:\tlearn: 0.1258633\ttotal: 1m 40s\tremaining: 45.3s\n",
      "345:\tlearn: 0.1255100\ttotal: 1m 41s\tremaining: 45.1s\n",
      "346:\tlearn: 0.1252702\ttotal: 1m 41s\tremaining: 44.8s\n",
      "347:\tlearn: 0.1249680\ttotal: 1m 41s\tremaining: 44.5s\n",
      "348:\tlearn: 0.1244744\ttotal: 1m 42s\tremaining: 44.3s\n",
      "349:\tlearn: 0.1236549\ttotal: 1m 42s\tremaining: 44.1s\n",
      "350:\tlearn: 0.1233788\ttotal: 1m 43s\tremaining: 43.8s\n",
      "351:\tlearn: 0.1225217\ttotal: 1m 43s\tremaining: 43.5s\n",
      "352:\tlearn: 0.1222627\ttotal: 1m 43s\tremaining: 43.2s\n",
      "353:\tlearn: 0.1218451\ttotal: 1m 43s\tremaining: 42.9s\n",
      "354:\tlearn: 0.1214897\ttotal: 1m 44s\tremaining: 42.6s\n",
      "355:\tlearn: 0.1212358\ttotal: 1m 44s\tremaining: 42.3s\n",
      "356:\tlearn: 0.1208493\ttotal: 1m 44s\tremaining: 42.1s\n",
      "357:\tlearn: 0.1207607\ttotal: 1m 45s\tremaining: 41.8s\n",
      "358:\tlearn: 0.1206275\ttotal: 1m 45s\tremaining: 41.5s\n",
      "359:\tlearn: 0.1202084\ttotal: 1m 46s\tremaining: 41.3s\n",
      "360:\tlearn: 0.1200421\ttotal: 1m 46s\tremaining: 40.9s\n",
      "361:\tlearn: 0.1195970\ttotal: 1m 46s\tremaining: 40.6s\n",
      "362:\tlearn: 0.1192148\ttotal: 1m 46s\tremaining: 40.3s\n",
      "363:\tlearn: 0.1189783\ttotal: 1m 47s\tremaining: 40s\n",
      "364:\tlearn: 0.1186766\ttotal: 1m 47s\tremaining: 39.8s\n",
      "365:\tlearn: 0.1183967\ttotal: 1m 47s\tremaining: 39.5s\n",
      "366:\tlearn: 0.1180778\ttotal: 1m 48s\tremaining: 39.1s\n",
      "367:\tlearn: 0.1178287\ttotal: 1m 48s\tremaining: 38.8s\n",
      "368:\tlearn: 0.1171386\ttotal: 1m 48s\tremaining: 38.6s\n",
      "369:\tlearn: 0.1165808\ttotal: 1m 48s\tremaining: 38.3s\n",
      "370:\tlearn: 0.1160565\ttotal: 1m 49s\tremaining: 38s\n",
      "371:\tlearn: 0.1153511\ttotal: 1m 49s\tremaining: 37.7s\n",
      "372:\tlearn: 0.1143675\ttotal: 1m 49s\tremaining: 37.5s\n",
      "373:\tlearn: 0.1138536\ttotal: 1m 50s\tremaining: 37.2s\n",
      "374:\tlearn: 0.1137098\ttotal: 1m 50s\tremaining: 36.9s\n",
      "375:\tlearn: 0.1133515\ttotal: 1m 50s\tremaining: 36.6s\n",
      "376:\tlearn: 0.1131974\ttotal: 1m 51s\tremaining: 36.3s\n",
      "377:\tlearn: 0.1127755\ttotal: 1m 51s\tremaining: 36s\n",
      "378:\tlearn: 0.1122924\ttotal: 1m 51s\tremaining: 35.7s\n",
      "379:\tlearn: 0.1116380\ttotal: 1m 52s\tremaining: 35.4s\n",
      "380:\tlearn: 0.1115063\ttotal: 1m 52s\tremaining: 35.1s\n",
      "381:\tlearn: 0.1111189\ttotal: 1m 52s\tremaining: 34.8s\n",
      "382:\tlearn: 0.1104732\ttotal: 1m 52s\tremaining: 34.5s\n",
      "383:\tlearn: 0.1103704\ttotal: 1m 53s\tremaining: 34.2s\n",
      "384:\tlearn: 0.1100967\ttotal: 1m 53s\tremaining: 33.9s\n",
      "385:\tlearn: 0.1093809\ttotal: 1m 53s\tremaining: 33.6s\n",
      "386:\tlearn: 0.1091499\ttotal: 1m 54s\tremaining: 33.3s\n",
      "387:\tlearn: 0.1090038\ttotal: 1m 54s\tremaining: 33s\n",
      "388:\tlearn: 0.1085971\ttotal: 1m 54s\tremaining: 32.7s\n",
      "389:\tlearn: 0.1080641\ttotal: 1m 54s\tremaining: 32.4s\n",
      "390:\tlearn: 0.1079006\ttotal: 1m 55s\tremaining: 32.2s\n",
      "391:\tlearn: 0.1073879\ttotal: 1m 55s\tremaining: 31.9s\n",
      "392:\tlearn: 0.1069453\ttotal: 1m 55s\tremaining: 31.6s\n",
      "393:\tlearn: 0.1066172\ttotal: 1m 56s\tremaining: 31.3s\n",
      "394:\tlearn: 0.1064373\ttotal: 1m 56s\tremaining: 31s\n",
      "395:\tlearn: 0.1056908\ttotal: 1m 57s\tremaining: 30.7s\n",
      "396:\tlearn: 0.1049793\ttotal: 1m 57s\tremaining: 30.5s\n",
      "397:\tlearn: 0.1044544\ttotal: 1m 57s\tremaining: 30.2s\n",
      "398:\tlearn: 0.1041165\ttotal: 1m 58s\tremaining: 29.9s\n",
      "399:\tlearn: 0.1038442\ttotal: 1m 58s\tremaining: 29.6s\n",
      "400:\tlearn: 0.1034354\ttotal: 1m 58s\tremaining: 29.3s\n",
      "401:\tlearn: 0.1030971\ttotal: 1m 59s\tremaining: 29s\n",
      "402:\tlearn: 0.1029063\ttotal: 1m 59s\tremaining: 28.7s\n",
      "403:\tlearn: 0.1025235\ttotal: 1m 59s\tremaining: 28.5s\n",
      "404:\tlearn: 0.1022371\ttotal: 2m\tremaining: 28.2s\n",
      "405:\tlearn: 0.1019769\ttotal: 2m\tremaining: 27.9s\n",
      "406:\tlearn: 0.1018298\ttotal: 2m\tremaining: 27.6s\n",
      "407:\tlearn: 0.1015969\ttotal: 2m\tremaining: 27.3s\n",
      "408:\tlearn: 0.1013581\ttotal: 2m 1s\tremaining: 27s\n",
      "409:\tlearn: 0.1012160\ttotal: 2m 1s\tremaining: 26.7s\n",
      "410:\tlearn: 0.1009025\ttotal: 2m 1s\tremaining: 26.4s\n",
      "411:\tlearn: 0.1005590\ttotal: 2m 2s\tremaining: 26.1s\n",
      "412:\tlearn: 0.1004573\ttotal: 2m 2s\tremaining: 25.8s\n",
      "413:\tlearn: 0.1003530\ttotal: 2m 2s\tremaining: 25.5s\n",
      "414:\tlearn: 0.1001779\ttotal: 2m 3s\tremaining: 25.2s\n",
      "415:\tlearn: 0.1000364\ttotal: 2m 3s\tremaining: 24.9s\n",
      "416:\tlearn: 0.0994896\ttotal: 2m 3s\tremaining: 24.6s\n",
      "417:\tlearn: 0.0993055\ttotal: 2m 4s\tremaining: 24.3s\n",
      "418:\tlearn: 0.0991447\ttotal: 2m 4s\tremaining: 24s\n",
      "419:\tlearn: 0.0987232\ttotal: 2m 4s\tremaining: 23.7s\n",
      "420:\tlearn: 0.0983833\ttotal: 2m 4s\tremaining: 23.4s\n",
      "421:\tlearn: 0.0981257\ttotal: 2m 5s\tremaining: 23.1s\n",
      "422:\tlearn: 0.0976541\ttotal: 2m 5s\tremaining: 22.8s\n",
      "423:\tlearn: 0.0975199\ttotal: 2m 5s\tremaining: 22.5s\n",
      "424:\tlearn: 0.0974069\ttotal: 2m 6s\tremaining: 22.2s\n",
      "425:\tlearn: 0.0968380\ttotal: 2m 6s\tremaining: 21.9s\n",
      "426:\tlearn: 0.0965380\ttotal: 2m 6s\tremaining: 21.6s\n",
      "427:\tlearn: 0.0964697\ttotal: 2m 6s\tremaining: 21.3s\n",
      "428:\tlearn: 0.0960231\ttotal: 2m 7s\tremaining: 21s\n",
      "429:\tlearn: 0.0958104\ttotal: 2m 7s\tremaining: 20.8s\n",
      "430:\tlearn: 0.0955778\ttotal: 2m 7s\tremaining: 20.5s\n",
      "431:\tlearn: 0.0954613\ttotal: 2m 8s\tremaining: 20.2s\n",
      "432:\tlearn: 0.0953647\ttotal: 2m 8s\tremaining: 19.9s\n",
      "433:\tlearn: 0.0949943\ttotal: 2m 8s\tremaining: 19.6s\n",
      "434:\tlearn: 0.0948108\ttotal: 2m 8s\tremaining: 19.3s\n",
      "435:\tlearn: 0.0944590\ttotal: 2m 9s\tremaining: 19s\n",
      "436:\tlearn: 0.0939844\ttotal: 2m 9s\tremaining: 18.7s\n",
      "437:\tlearn: 0.0935728\ttotal: 2m 9s\tremaining: 18.4s\n",
      "438:\tlearn: 0.0933778\ttotal: 2m 10s\tremaining: 18.1s\n",
      "439:\tlearn: 0.0930895\ttotal: 2m 10s\tremaining: 17.8s\n",
      "440:\tlearn: 0.0928957\ttotal: 2m 10s\tremaining: 17.5s\n",
      "441:\tlearn: 0.0925959\ttotal: 2m 11s\tremaining: 17.2s\n",
      "442:\tlearn: 0.0923540\ttotal: 2m 11s\tremaining: 16.9s\n",
      "443:\tlearn: 0.0919246\ttotal: 2m 11s\tremaining: 16.6s\n",
      "444:\tlearn: 0.0916230\ttotal: 2m 12s\tremaining: 16.3s\n",
      "445:\tlearn: 0.0914672\ttotal: 2m 12s\tremaining: 16s\n",
      "446:\tlearn: 0.0911255\ttotal: 2m 12s\tremaining: 15.7s\n",
      "447:\tlearn: 0.0908738\ttotal: 2m 12s\tremaining: 15.4s\n",
      "448:\tlearn: 0.0906707\ttotal: 2m 13s\tremaining: 15.1s\n",
      "449:\tlearn: 0.0902936\ttotal: 2m 13s\tremaining: 14.9s\n",
      "450:\tlearn: 0.0900201\ttotal: 2m 14s\tremaining: 14.6s\n",
      "451:\tlearn: 0.0897146\ttotal: 2m 14s\tremaining: 14.3s\n",
      "452:\tlearn: 0.0894130\ttotal: 2m 14s\tremaining: 14s\n",
      "453:\tlearn: 0.0891383\ttotal: 2m 15s\tremaining: 13.7s\n",
      "454:\tlearn: 0.0885785\ttotal: 2m 15s\tremaining: 13.4s\n",
      "455:\tlearn: 0.0882162\ttotal: 2m 15s\tremaining: 13.1s\n",
      "456:\tlearn: 0.0881549\ttotal: 2m 15s\tremaining: 12.8s\n",
      "457:\tlearn: 0.0879164\ttotal: 2m 16s\tremaining: 12.5s\n",
      "458:\tlearn: 0.0877718\ttotal: 2m 16s\tremaining: 12.2s\n",
      "459:\tlearn: 0.0874240\ttotal: 2m 16s\tremaining: 11.9s\n",
      "460:\tlearn: 0.0871625\ttotal: 2m 17s\tremaining: 11.6s\n",
      "461:\tlearn: 0.0869210\ttotal: 2m 17s\tremaining: 11.3s\n",
      "462:\tlearn: 0.0865413\ttotal: 2m 17s\tremaining: 11s\n",
      "463:\tlearn: 0.0863087\ttotal: 2m 17s\tremaining: 10.7s\n",
      "464:\tlearn: 0.0861050\ttotal: 2m 18s\tremaining: 10.4s\n",
      "465:\tlearn: 0.0857704\ttotal: 2m 18s\tremaining: 10.1s\n",
      "466:\tlearn: 0.0856293\ttotal: 2m 18s\tremaining: 9.81s\n",
      "467:\tlearn: 0.0854507\ttotal: 2m 19s\tremaining: 9.51s\n",
      "468:\tlearn: 0.0853325\ttotal: 2m 19s\tremaining: 9.21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469:\tlearn: 0.0851801\ttotal: 2m 19s\tremaining: 8.92s\n",
      "470:\tlearn: 0.0851152\ttotal: 2m 20s\tremaining: 8.62s\n",
      "471:\tlearn: 0.0848627\ttotal: 2m 20s\tremaining: 8.33s\n",
      "472:\tlearn: 0.0845996\ttotal: 2m 20s\tremaining: 8.03s\n",
      "473:\tlearn: 0.0841132\ttotal: 2m 20s\tremaining: 7.73s\n",
      "474:\tlearn: 0.0839462\ttotal: 2m 21s\tremaining: 7.44s\n",
      "475:\tlearn: 0.0836746\ttotal: 2m 21s\tremaining: 7.14s\n",
      "476:\tlearn: 0.0834553\ttotal: 2m 21s\tremaining: 6.84s\n",
      "477:\tlearn: 0.0831155\ttotal: 2m 22s\tremaining: 6.54s\n",
      "478:\tlearn: 0.0828676\ttotal: 2m 22s\tremaining: 6.25s\n",
      "479:\tlearn: 0.0824723\ttotal: 2m 22s\tremaining: 5.95s\n",
      "480:\tlearn: 0.0820589\ttotal: 2m 23s\tremaining: 5.65s\n",
      "481:\tlearn: 0.0818180\ttotal: 2m 23s\tremaining: 5.35s\n",
      "482:\tlearn: 0.0816206\ttotal: 2m 23s\tremaining: 5.05s\n",
      "483:\tlearn: 0.0814453\ttotal: 2m 23s\tremaining: 4.75s\n",
      "484:\tlearn: 0.0811688\ttotal: 2m 24s\tremaining: 4.46s\n",
      "485:\tlearn: 0.0807410\ttotal: 2m 24s\tremaining: 4.16s\n",
      "486:\tlearn: 0.0802995\ttotal: 2m 24s\tremaining: 3.86s\n",
      "487:\tlearn: 0.0798400\ttotal: 2m 24s\tremaining: 3.56s\n",
      "488:\tlearn: 0.0797487\ttotal: 2m 25s\tremaining: 3.27s\n",
      "489:\tlearn: 0.0795189\ttotal: 2m 25s\tremaining: 2.97s\n",
      "490:\tlearn: 0.0794336\ttotal: 2m 25s\tremaining: 2.67s\n",
      "491:\tlearn: 0.0793430\ttotal: 2m 26s\tremaining: 2.37s\n",
      "492:\tlearn: 0.0788921\ttotal: 2m 26s\tremaining: 2.08s\n",
      "493:\tlearn: 0.0786727\ttotal: 2m 26s\tremaining: 1.78s\n",
      "494:\tlearn: 0.0786043\ttotal: 2m 26s\tremaining: 1.48s\n",
      "495:\tlearn: 0.0782588\ttotal: 2m 27s\tremaining: 1.19s\n",
      "496:\tlearn: 0.0780983\ttotal: 2m 27s\tremaining: 891ms\n",
      "497:\tlearn: 0.0779291\ttotal: 2m 27s\tremaining: 594ms\n",
      "498:\tlearn: 0.0775630\ttotal: 2m 28s\tremaining: 297ms\n",
      "499:\tlearn: 0.0772933\ttotal: 2m 28s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__depth</th>\n",
       "      <th>param_model__iterations</th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.597160</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.594350</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.995534</td>\n",
       "      <td>0.001202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.592543</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.592302</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.979460</td>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__depth param_model__iterations param_model__learning_rate  \\\n",
       "39                 10                     500                        0.1   \n",
       "46                 10                    1500                       0.01   \n",
       "43                 10                    1000                        0.1   \n",
       "42                 10                    1000                       0.01   \n",
       "\n",
       "    mean_test_score  std_test_score  mean_train_score  std_train_score  \n",
       "39         0.597160        0.006452          1.000000         0.000000  \n",
       "46         0.594350        0.007996          0.995534         0.001202  \n",
       "43         0.592543        0.009479          1.000000         0.000000  \n",
       "42         0.592302        0.006627          0.979460         0.002821  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid de hiperparÃ¡metros evaluados\n",
    "# ==============================================================================\n",
    "param_grid = {'model__iterations'  : [500, 1000, 1500],\n",
    "              'model__depth'     : [3, 5, 6, 10, 20],\n",
    "              'model__learning_rate' : [0.0005, 0.001, 0.01, 0.1]\n",
    "             }\n",
    "\n",
    "\n",
    "CBC = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', CatBoostClassifier(random_state=123))])\n",
    "\n",
    "\n",
    "# BÃºsqueda por grid search con validaciÃ³n cruzada\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(\n",
    "        estimator  = CBC,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_weighted',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bbc23f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_cbc = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8df35633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__subsample</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593860</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.592053</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_model__learning_rate param_model__max_depth  \\\n",
       "425                        0.1                     20   \n",
       "427                        0.1                     20   \n",
       "285                       0.01                     20   \n",
       "419                        0.1                     20   \n",
       "\n",
       "    param_model__max_features param_model__n_estimators  \\\n",
       "425                      log2                        50   \n",
       "427                      log2                       100   \n",
       "285                      log2                       500   \n",
       "419                      sqrt                       100   \n",
       "\n",
       "    param_model__subsample  mean_test_score  std_test_score  mean_train_score  \\\n",
       "425                      1         0.593860        0.004625               1.0   \n",
       "427                      1         0.593649        0.003115               1.0   \n",
       "285                      1         0.592105        0.003821               1.0   \n",
       "419                      1         0.592053        0.001673               1.0   \n",
       "\n",
       "     std_train_score  \n",
       "425              0.0  \n",
       "427              0.0  \n",
       "285              0.0  \n",
       "419              0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid de hiperparÃ¡metros evaluados\n",
    "# ==============================================================================\n",
    "param_grid = {'model__n_estimators'  : [50, 100, 500, 1000],\n",
    "              'model__max_features'  : ['auto', 'sqrt', 'log2'],\n",
    "              'model__max_depth'     : [None, 1, 3, 5, 10, 20],\n",
    "              'model__subsample'     : [0.5, 1],\n",
    "              'model__learning_rate' : [0.001, 0.01, 0.1]\n",
    "             }\n",
    "\n",
    "\n",
    "GBC = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', GradientBoostingClassifier(random_state=123))])\n",
    "\n",
    "\n",
    "# BÃºsqueda por grid search con validaciÃ³n cruzada\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(\n",
    "        estimator  = GBC,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_weighted',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f49a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_gbc = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe6f619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4184a410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__criterion</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0.582002</td>\n",
       "      <td>0.019135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0.581523</td>\n",
       "      <td>0.021385</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>0.580900</td>\n",
       "      <td>0.018971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>0.580507</td>\n",
       "      <td>0.019149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_model__criterion param_model__max_depth param_model__max_features  \\\n",
       "25                entropy                   None                         5   \n",
       "43                entropy                     20                         5   \n",
       "1                    gini                   None                         5   \n",
       "27                entropy                   None                         7   \n",
       "\n",
       "   param_model__n_estimators  mean_test_score  std_test_score  \\\n",
       "25                       200         0.582002        0.019135   \n",
       "43                       200         0.581523        0.021385   \n",
       "1                        200         0.580900        0.018971   \n",
       "27                       200         0.580507        0.019149   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "25          1.000000         0.000000  \n",
       "43          0.999977         0.000087  \n",
       "1           1.000000         0.000000  \n",
       "27          1.000000         0.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid de hiperparÃ¡metros evaluados\n",
    "# ==============================================================================\n",
    "param_grid = {'model__n_estimators': [150, 200],\n",
    "              'model__max_features': [5, 7, 9],\n",
    "              'model__max_depth'   : [None, 3, 10, 20],\n",
    "              'model__criterion'   : ['gini', 'entropy']\n",
    "             }\n",
    "\n",
    "\n",
    "\n",
    "RFC = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', RandomForestClassifier(random_state=123))])\n",
    "\n",
    "\n",
    "# BÃºsqueda por grid search con validaciÃ³n cruzada\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(\n",
    "        estimator  = RFC,\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_weighted',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6284b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_rfc = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe177f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Logit</th>\n",
       "      <th>GBC</th>\n",
       "      <th>CBC</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.605351</td>\n",
       "      <td>0.520624</td>\n",
       "      <td>0.552954</td>\n",
       "      <td>0.541806</td>\n",
       "      <td>0.556299</td>\n",
       "      <td>0.590858</td>\n",
       "      <td>0.583055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.600887</td>\n",
       "      <td>0.520376</td>\n",
       "      <td>0.485160</td>\n",
       "      <td>0.504828</td>\n",
       "      <td>0.548478</td>\n",
       "      <td>0.586334</td>\n",
       "      <td>0.572496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard</th>\n",
       "      <td>0.431987</td>\n",
       "      <td>0.352538</td>\n",
       "      <td>0.345262</td>\n",
       "      <td>0.352022</td>\n",
       "      <td>0.381799</td>\n",
       "      <td>0.417335</td>\n",
       "      <td>0.405916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log-loss</th>\n",
       "      <td>13.630815</td>\n",
       "      <td>16.557239</td>\n",
       "      <td>15.440461</td>\n",
       "      <td>15.825548</td>\n",
       "      <td>15.325035</td>\n",
       "      <td>14.131383</td>\n",
       "      <td>14.400900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                KNN  Decision Tree        SVM      Logit        GBC  \\\n",
       "Accuracy   0.605351       0.520624   0.552954   0.541806   0.556299   \n",
       "F1         0.600887       0.520376   0.485160   0.504828   0.548478   \n",
       "Jaccard    0.431987       0.352538   0.345262   0.352022   0.381799   \n",
       "Log-loss  13.630815      16.557239  15.440461  15.825548  15.325035   \n",
       "\n",
       "                CBC         RF  \n",
       "Accuracy   0.590858   0.583055  \n",
       "F1         0.586334   0.572496  \n",
       "Jaccard    0.417335   0.405916  \n",
       "Log-loss  14.131383  14.400900  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Metric Results\n",
    "\n",
    "\n",
    "metric_results_oos = pd.DataFrame({'KNN' :  [accuracy_score(y_test, final_model_knn.predict(X_test)),\n",
    "    f1_score(y_test, final_model_knn.predict(X_test), average = 'weighted'),\n",
    "    jaccard_score(y_test, final_model_knn.predict(X_test), average = 'weighted'),\n",
    "    log_loss(y_test, final_model_knn.predict(X_test))],\n",
    "                                     'Decision Tree' :  [accuracy_score(y_test, final_model_dt.predict(X_test)),\n",
    "    f1_score(y_test, final_model_dt.predict(X_test), average = 'weighted'),\n",
    "    jaccard_score(y_test, final_model_dt.predict(X_test), average = 'weighted'),\n",
    "    log_loss(y_test, final_model_dt.predict(X_test))], \n",
    "                                     'SVM' :  [accuracy_score(y_test, final_model_svm.predict(X_test)),\n",
    "    f1_score(y_test, final_model_svm.predict(X_test), average = 'weighted'),\n",
    "    jaccard_score(y_test, final_model_svm.predict(X_test), average = 'weighted'),\n",
    "    log_loss(y_test, final_model_svm.predict(X_test))],\n",
    "                                     'Logit' :  [accuracy_score(y_test, final_model_logit.predict(X_test)),\n",
    "    f1_score(y_test, final_model_logit.predict(X_test), average = 'weighted'),\n",
    "    jaccard_score(y_test, final_model_logit.predict(X_test), average = 'weighted'),\n",
    "    log_loss(y_test, final_model_logit.predict(X_test))],\n",
    "                                    'GBC' :  [accuracy_score(y_test, final_model_gbc.predict(X_test)),\n",
    "    f1_score(y_test, final_model_gbc.predict(X_test), average = 'weighted'),\n",
    "    jaccard_score(y_test, final_model_gbc.predict(X_test), average = 'weighted'),\n",
    "    log_loss(y_test, final_model_gbc.predict(X_test))],\n",
    "                                    'CBC' :  [accuracy_score(y_test, final_model_cbc.predict(X_test)),\n",
    "    f1_score(y_test, final_model_cbc.predict(X_test), average = 'weighted'),\n",
    "    jaccard_score(y_test, final_model_cbc.predict(X_test), average = 'weighted'),\n",
    "    log_loss(y_test, final_model_cbc.predict(X_test))],\n",
    "                                    'RF' :  [accuracy_score(y_test, final_model_rfc.predict(X_test)),\n",
    "    f1_score(y_test, final_model_rfc.predict(X_test), average = 'weighted'),\n",
    "    jaccard_score(y_test, final_model_rfc.predict(X_test), average = 'weighted'),\n",
    "    log_loss(y_test, final_model_rfc.predict(X_test))]                               \n",
    "                        })\n",
    "     \n",
    "     \n",
    "# Change the row indexes\n",
    "metric_results_oos.index = ['Accuracy', 'F1', 'Jaccard', 'Log-loss']\n",
    "\n",
    "\n",
    "metric_results_oos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "786f0de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Logit</th>\n",
       "      <th>GBC</th>\n",
       "      <th>CBC</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.625279</td>\n",
       "      <td>0.588728</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.568329</td>\n",
       "      <td>0.557911</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.420265</td>\n",
       "      <td>0.400847</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log-loss</th>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>12.942432</td>\n",
       "      <td>14.204923</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   KNN  Decision Tree        SVM      Logit           GBC  \\\n",
       "Accuracy  1.000000e+00   1.000000e+00   0.625279   0.588728  1.000000e+00   \n",
       "F1        1.000000e+00   1.000000e+00   0.568329   0.557911  1.000000e+00   \n",
       "Jaccard   1.000000e+00   1.000000e+00   0.420265   0.400847  1.000000e+00   \n",
       "Log-loss  9.992007e-16   9.992007e-16  12.942432  14.204923  9.992007e-16   \n",
       "\n",
       "                   CBC            RF  \n",
       "Accuracy  1.000000e+00  1.000000e+00  \n",
       "F1        1.000000e+00  1.000000e+00  \n",
       "Jaccard   1.000000e+00  1.000000e+00  \n",
       "Log-loss  9.992007e-16  9.992007e-16  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_results_ins = pd.DataFrame({'KNN' :  [accuracy_score(y_train, final_model_knn.predict(X_train)),\n",
    "    f1_score(y_train, final_model_knn.predict(X_train), average = 'weighted'),\n",
    "    jaccard_score(y_train, final_model_knn.predict(X_train), average = 'weighted'),\n",
    "    log_loss(y_train, final_model_knn.predict(X_train))],\n",
    "                                     'Decision Tree' :  [accuracy_score(y_train, final_model_dt.predict(X_train)),\n",
    "    f1_score(y_train, final_model_dt.predict(X_train), average = 'weighted'),\n",
    "    jaccard_score(y_train, final_model_dt.predict(X_train), average = 'weighted'),\n",
    "    log_loss(y_train, final_model_dt.predict(X_train))], \n",
    "                                     'SVM' :  [accuracy_score(y_train, final_model_svm.predict(X_train)),\n",
    "    f1_score(y_train, final_model_svm.predict(X_train), average = 'weighted'),\n",
    "    jaccard_score(y_train, final_model_svm.predict(X_train), average = 'weighted'),\n",
    "    log_loss(y_train, final_model_svm.predict(X_train))],\n",
    "                                     'Logit' :  [accuracy_score(y_train, final_model_logit.predict(X_train)),\n",
    "    f1_score(y_train, final_model_logit.predict(X_train), average = 'weighted'),\n",
    "    jaccard_score(y_train, final_model_logit.predict(X_train), average = 'weighted'),\n",
    "    log_loss(y_train, final_model_logit.predict(X_train))],\n",
    "                                     'GBC' :  [accuracy_score(y_train, final_model_gbc.predict(X_train)),\n",
    "    f1_score(y_train, final_model_gbc.predict(X_train), average = 'weighted'),\n",
    "    jaccard_score(y_train, final_model_gbc.predict(X_train), average = 'weighted'),\n",
    "    log_loss(y_train, final_model_gbc.predict(X_train))],\n",
    "                                     'CBC' :  [accuracy_score(y_train, final_model_cbc.predict(X_train)),\n",
    "    f1_score(y_train, final_model_cbc.predict(X_train), average = 'weighted'),\n",
    "    jaccard_score(y_train, final_model_cbc.predict(X_train), average = 'weighted'),\n",
    "    log_loss(y_train, final_model_cbc.predict(X_train))],\n",
    "                                     'RF' :  [accuracy_score(y_train, final_model_rfc.predict(X_train)),\n",
    "    f1_score(y_train, final_model_rfc.predict(X_train), average = 'weighted'),\n",
    "    jaccard_score(y_train, final_model_rfc.predict(X_train), average = 'weighted'),\n",
    "    log_loss(y_train, final_model_rfc.predict(X_train))]                               \n",
    "                        })\n",
    "     \n",
    "# Change the row indexes\n",
    "metric_results_ins.index = ['Accuracy', 'F1', 'Jaccard', 'Log-loss']\n",
    "\n",
    "\n",
    "metric_results_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91c15ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session('oc_prediction_session.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84c19a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92322dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessor',\n",
       "   ColumnTransformer(transformers=[('num',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(strategy='median')),\n",
       "                                                    ('polynomial',\n",
       "                                                     PolynomialFeatures(degree=3,\n",
       "                                                                        include_bias=False)),\n",
       "                                                    ('scaler', StandardScaler())]),\n",
       "                                    ['val_pren', 'edad', 'prestamo', 'faltas']),\n",
       "                                   ('cat',\n",
       "                                    OneHotEncoder(handle_unknown='ignore',\n",
       "                                                  sparse=False),\n",
       "                                    ['genero', 'pres_antes', 'ahorros',\n",
       "                                     'cta_tanda', 'rec_cel', 'tentado',\n",
       "                                     'dummy_prenda_tipo2', 'dummy_prenda_tipo3',\n",
       "                                     'dummy_prenda_tipo4', 'dummy_prenda_tipo5',\n",
       "                                     'dummy_educacion2', 'dummy_educacion3',\n",
       "                                     'dummy_educacion4', 'dummy_educacion5',\n",
       "                                     'dummy_plan_gasto2', 'dummy_plan_gasto3'])])),\n",
       "  ('model', KNeighborsClassifier(n_neighbors=6, weights='distance'))],\n",
       " 'verbose': False,\n",
       " 'preprocessor': ColumnTransformer(transformers=[('num',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(strategy='median')),\n",
       "                                                  ('polynomial',\n",
       "                                                   PolynomialFeatures(degree=3,\n",
       "                                                                      include_bias=False)),\n",
       "                                                  ('scaler', StandardScaler())]),\n",
       "                                  ['val_pren', 'edad', 'prestamo', 'faltas']),\n",
       "                                 ('cat',\n",
       "                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                sparse=False),\n",
       "                                  ['genero', 'pres_antes', 'ahorros',\n",
       "                                   'cta_tanda', 'rec_cel', 'tentado',\n",
       "                                   'dummy_prenda_tipo2', 'dummy_prenda_tipo3',\n",
       "                                   'dummy_prenda_tipo4', 'dummy_prenda_tipo5',\n",
       "                                   'dummy_educacion2', 'dummy_educacion3',\n",
       "                                   'dummy_educacion4', 'dummy_educacion5',\n",
       "                                   'dummy_plan_gasto2', 'dummy_plan_gasto3'])]),\n",
       " 'model': KNeighborsClassifier(n_neighbors=6, weights='distance'),\n",
       " 'preprocessor__n_jobs': None,\n",
       " 'preprocessor__remainder': 'drop',\n",
       " 'preprocessor__sparse_threshold': 0.3,\n",
       " 'preprocessor__transformer_weights': None,\n",
       " 'preprocessor__transformers': [('num',\n",
       "   Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                   ('polynomial',\n",
       "                    PolynomialFeatures(degree=3, include_bias=False)),\n",
       "                   ('scaler', StandardScaler())]),\n",
       "   ['val_pren', 'edad', 'prestamo', 'faltas']),\n",
       "  ('cat',\n",
       "   OneHotEncoder(handle_unknown='ignore', sparse=False),\n",
       "   ['genero',\n",
       "    'pres_antes',\n",
       "    'ahorros',\n",
       "    'cta_tanda',\n",
       "    'rec_cel',\n",
       "    'tentado',\n",
       "    'dummy_prenda_tipo2',\n",
       "    'dummy_prenda_tipo3',\n",
       "    'dummy_prenda_tipo4',\n",
       "    'dummy_prenda_tipo5',\n",
       "    'dummy_educacion2',\n",
       "    'dummy_educacion3',\n",
       "    'dummy_educacion4',\n",
       "    'dummy_educacion5',\n",
       "    'dummy_plan_gasto2',\n",
       "    'dummy_plan_gasto3'])],\n",
       " 'preprocessor__verbose': False,\n",
       " 'preprocessor__num': Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                 ('polynomial',\n",
       "                  PolynomialFeatures(degree=3, include_bias=False)),\n",
       "                 ('scaler', StandardScaler())]),\n",
       " 'preprocessor__cat': OneHotEncoder(handle_unknown='ignore', sparse=False),\n",
       " 'preprocessor__num__memory': None,\n",
       " 'preprocessor__num__steps': [('imputer', SimpleImputer(strategy='median')),\n",
       "  ('polynomial', PolynomialFeatures(degree=3, include_bias=False)),\n",
       "  ('scaler', StandardScaler())],\n",
       " 'preprocessor__num__verbose': False,\n",
       " 'preprocessor__num__imputer': SimpleImputer(strategy='median'),\n",
       " 'preprocessor__num__polynomial': PolynomialFeatures(degree=3, include_bias=False),\n",
       " 'preprocessor__num__scaler': StandardScaler(),\n",
       " 'preprocessor__num__imputer__add_indicator': False,\n",
       " 'preprocessor__num__imputer__copy': True,\n",
       " 'preprocessor__num__imputer__fill_value': None,\n",
       " 'preprocessor__num__imputer__missing_values': nan,\n",
       " 'preprocessor__num__imputer__strategy': 'median',\n",
       " 'preprocessor__num__imputer__verbose': 0,\n",
       " 'preprocessor__num__polynomial__degree': 3,\n",
       " 'preprocessor__num__polynomial__include_bias': False,\n",
       " 'preprocessor__num__polynomial__interaction_only': False,\n",
       " 'preprocessor__num__polynomial__order': 'C',\n",
       " 'preprocessor__num__scaler__copy': True,\n",
       " 'preprocessor__num__scaler__with_mean': True,\n",
       " 'preprocessor__num__scaler__with_std': True,\n",
       " 'preprocessor__cat__categories': 'auto',\n",
       " 'preprocessor__cat__drop': None,\n",
       " 'preprocessor__cat__dtype': numpy.float64,\n",
       " 'preprocessor__cat__handle_unknown': 'ignore',\n",
       " 'preprocessor__cat__sparse': False,\n",
       " 'model__algorithm': 'auto',\n",
       " 'model__leaf_size': 30,\n",
       " 'model__metric': 'minkowski',\n",
       " 'model__metric_params': None,\n",
       " 'model__n_jobs': None,\n",
       " 'model__n_neighbors': 6,\n",
       " 'model__p': 2,\n",
       " 'model__weights': 'distance'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = final_model_knn.get_params()\n",
    "params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad6c0e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('polynomial',\n",
       "                                                                   PolynomialFeatures(degree=3,\n",
       "                                                                                      include_bias=False)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['val_pren', 'edad',\n",
       "                                                   'prestamo', 'faltas']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['genero', 'pres_antes',\n",
       "                                                   'ahorros', 'cta_tanda',\n",
       "                                                   'rec_cel', 'tentado',\n",
       "                                                   'dummy_prenda_tipo2',\n",
       "                                                   'dummy_prenda_tipo3',\n",
       "                                                   'dummy_prenda_tipo4',\n",
       "                                                   'dummy_prenda_tipo5',\n",
       "                                                   'dummy_educacion2',\n",
       "                                                   'dummy_educacion3',\n",
       "                                                   'dummy_educacion4',\n",
       "                                                   'dummy_educacion5',\n",
       "                                                   'dummy_plan_gasto2',\n",
       "                                                   'dummy_plan_gasto3'])])),\n",
       "                ('model',\n",
       "                 KNeighborsClassifier(n_neighbors=6, weights='distance'))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.set_params(**params)\n",
    "KNN.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e27c458",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-d2634c2b4e0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mKNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \"\"\"\n\u001b[1;32m--> 550\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "print('accuracy :', accuracy_score(y,  KNN.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad82426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones  = KNN.predict_proba(X = X_test)\n",
    "predicciones\n",
    "prob_positivo = predicciones[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc8a41cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x552.96 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fraccion_positivos, media_prob_predicha = calibration_curve(y_test, prob_positivo, n_bins=20)\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1,figsize=(6, 2*3.84))\n",
    "\n",
    "axs[0].plot(media_prob_predicha, fraccion_positivos, \"s-\", label=\"Random Forest\")\n",
    "axs[0].plot([0, 1], [0, 1], \"k:\", label=\"CalibraciÃ³n perfecta\")\n",
    "axs[0].set_ylabel(\"ProporciÃ³n de clasificaciÃ³n correcta\")\n",
    "axs[0].set_xlabel(\"Probabilidad media estimada por el modelo (predict_proba)\")\n",
    "axs[0].set_title('Curva de calibrado (reliability curve)')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].hist(prob_positivo, range=(0, 1), bins=10, density=True, lw=2, alpha = 0.3)\n",
    "axs[1].set_xlabel(\"Probabilidad estimada por el modelo (predict_proba)\")\n",
    "axs[1].set_ylabel(\"Count\")\n",
    "axs[1].set_title('DistribuciÃ³n de las probabilidades predichas por el modelo')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e5cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(path + '/_aux/oc_data.csv') \n",
    "pred = df_pred[['val_pren', 'edad',  'prestamo',  'faltas', 'genero',\n",
    "            'pres_antes',\n",
    "            'ahorros',\n",
    "            'cta_tanda',\n",
    "            'rec_cel',\n",
    "            'tentado',\n",
    "            'dummy_prenda_tipo2',\n",
    "            'dummy_prenda_tipo3',\n",
    "            'dummy_prenda_tipo4',\n",
    "            'dummy_prenda_tipo5',\n",
    "            'dummy_educacion2',\n",
    "            'dummy_educacion3',\n",
    "            'dummy_educacion4',\n",
    "            'dummy_educacion5',\n",
    "            'dummy_plan_gasto2',\n",
    "            'dummy_plan_gasto3']]\n",
    "\n",
    "dict_classifiers = {\n",
    "    \"Logit\": [final_model_logit, LOGIT],\n",
    "    \"SVM\": [final_model_svm, SVM],\n",
    "    \"KNN\": [final_model_knn, KNN],\n",
    "    \"GBC\": [final_model_gbc, GBC],\n",
    "    \"DT\": [final_model_dt, DT],\n",
    "    \"CBC\": [final_model_cbc, CBC],\n",
    "    \"RF\": [final_model_rfc, RFC]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "repay = df_pred[['des_c']]\n",
    "\n",
    "for model in dict_classifiers:\n",
    "    params = dict_classifiers[model][0].get_params()\n",
    "    dict_classifiers[model][1].set_params(**params)\n",
    "    dict_classifiers[model][1].fit(X,y)\n",
    "    print(model,'accuracy :', accuracy_score(y,  dict_classifiers[model][1].predict(X)))\n",
    "    dta = pd.DataFrame(dict_classifiers[model][1].predict_proba(pred))\n",
    "    name0 = 'pr_'+model+'_0'\n",
    "    name1 = 'pr_'+model+'_1'    \n",
    "    dta.rename(columns={0: name0, 1: name1}, inplace=True)\n",
    "    pre = pd.DataFrame(dict_classifiers[model][1].predict(pred))\n",
    "    name = 'pre_'+model\n",
    "    pre.rename(columns={0: name}, inplace=True)\n",
    "    repay = pd.concat([repay, dta, pre], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc81d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "repay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c606eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "repay.to_csv(os.path.join(path + '/_aux/repay_pred.csv') , index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dff792",
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia = permutation_importance(\n",
    "                estimator    = GBC,\n",
    "                X            = X,\n",
    "                y            = y,\n",
    "                n_repeats    = 5,\n",
    "                scoring      = 'f1_weighted',\n",
    "                n_jobs       = multiprocessing.cpu_count() - 1,\n",
    "                random_state = 123\n",
    "             )\n",
    "\n",
    "# Se almacenan los resultados (media y desviaciÃ³n) en un dataframe\n",
    "df_importancia = pd.DataFrame(\n",
    "                    {k: importancia[k] for k in ['importances_mean', 'importances_std']}\n",
    "                 )\n",
    "df_importancia['feature'] = X_train.columns\n",
    "df_importancia.sort_values('importances_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7508ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# GrÃ¡fico\n",
    "fig, ax = plt.subplots(figsize=(5, 6))\n",
    "df_importancia = df_importancia.sort_values('importances_mean', ascending=True)\n",
    "ax.barh(\n",
    "    df_importancia['feature'],\n",
    "    df_importancia['importances_mean'],\n",
    "    xerr=df_importancia['importances_std'],\n",
    "    align='center',\n",
    "    alpha=0\n",
    ")\n",
    "ax.plot(\n",
    "    df_importancia['importances_mean'],\n",
    "    df_importancia['feature'],\n",
    "    marker=\"D\",\n",
    "    linestyle=\"\",\n",
    "    alpha=0.8,\n",
    "    color=\"r\"\n",
    ")\n",
    "ax.set_title('Importancia de los predictores (train)')\n",
    "ax.set_xlabel('Incremento del error tras la permutaciÃ³n');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2194414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
