 \documentclass[oneside,11pt]{article}

\input{preamble.tex}
%%% HELPER CODE FOR DEALING WITH EXTERNAL REFERENCES
\usepackage{xr}
\makeatletter
\newcommand*{\addFileDependency}[1]{
  \typeout{(#1)}
  \@addtofilelist{#1}
  \IfFileExists{#1}{}{\typeout{No file #1.}}
}
\makeatother


\newcommand*{\myexternaldocument}[1]{
    \externaldocument{#1}
    \addFileDependency{#1.tex}
    \addFileDependency{#1.aux}
}

%\myexternaldocument{OA}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% DOCUMENT
\begin{document}


\title{The controlled choice design and private paternalism in pawnshop borrowing\thanks{We want to thank Mauricio Romero and Anett John for advice and encouragement. Ricardo Olivares, Gerardo Melendez, and Alonso de Gortari provided excellent research assistance and Erick Molina helped with formatting. Jose Maria Barrero, Andrei Gomberg, Emilio Gutierrez, David Laibson, Aprajit Mahajan, Matt Rabin, Charlie Sprenger, and seminar participants at ITAM, USC, MSU, and UCSD provided valuable feedback.}}
\author{Craig McIntosh \and Isaac Meza \and Joyce Sadka \and Enrique Seira \and Francis J.\ DiTraglia   \thanks{Seira:  MSU, \url{enrique.seira@gmail.com} (corresponding author); McIntosh:  University of California San Diego, \url{ctmcintosh@ucsd.edu}; Meza: Harvard University, \url{isaacmezalopez@g.harvard.edu}; Sadka: ITAM, \url{jsadka@itam.mx}; DiTraglia: Oxford, \url{francis.ditraglia@economics.ox.ac.uk}} }
\date{This draft:  \today \\[2 cm]}

%\vspace{.5in}


\maketitle
\thispagestyle{empty}
\begin{abstract}

%Many firms provide commitment devices that restrict individuals' choice, but shroud this. Shrouding suggests low demand for commitment. We show that private paternalism is beneficial in the pawnbroker context we study. 

In the context of pawnbroker lending, we show that forcing people into commitment contracts with a regular repayment structure decreases their (fee-including) financial cost by 20\%, increases the likelihood of recovering their pawn by 15\%, and increases the likelihood of repeat business by 20\%.  Using a multi-armed RCT that includes both a voluntary and a forced arm, we illustrate how to point-identify both the Treatment on the Untreated and the Treatment on the Treated.  We find modest selection on gains but nonetheless significant positive benefits of commitment even for those who would not have chosen it.  %The justification for paternalistic commitment in this context appears to be over-optimism; 74\% of clients say they will certainly recover their pawn while in fact only 57\% do so. 



%In the context of pawnbroker lending, we show that forcing people into commitment contracts with financial penalties for not paying on time \textit{decreases} their (fee-including) financial cost by 9.4\%, increases the likelihood of recovering their pawn by 26\%, and increases the likelihood of repeat business by almost 100\%. Using machine learning methods for estimating heterogeneous treatment effects, we find that more than {70}\% clients would reduce their financing cost with the commitment contract, however only 10\% choose it. Those that \textit{don't} choose it are predicted to be the ones who would benefit more. Relying on personal promises instead of fees as commitment triples take-up but has no effects on outcomes.

%and one of the most understudied. In our context more than on half of borrowers default and lose their pawn and whatever they have paid towards recovering it. Compared to the status quo pay-at-anytime 3-month contracts, forcing borrowers to pay monthly and charge a penalty if they didn't --i.e. a commitment contract-- increased recovery of pawn by about 30\% and financial costs by 10\%. However when offered a choice between the two contracts only 10\% took the monthly payment one. A pecuniary commitment seems necessary. In an alternative arm, we made them promise to pay but removed the pecuniary penalty. This increased take up to 31\%, but had zero effect on financing cost or default. The forcing contract may be better than choice for naive present biased consumers.

\end{abstract}

\vspace{.3in}

\textbf{Keywords: } Private paternalism, choice, heterogeneous treatment effects, commitment, overconfidence.

\textbf{JEL codes:} G41, C93, O16, G21

\newpage

\pagenumbering{arabic}
\etocdepthtag.toc{mtchapter}
\etocsettagdepth{mtchapter}{subsection}
\etocsettagdepth{mtappendix}{none}


%NO MORAL HAZARD IN THE CONTRACT SINCE FULLY COLLATERALIZED
%DOUBLE FAILURE: DEMAND LOW, AND DOES NOT WORK BY PEOPLE WHO TAKE IT.
%PENALIZES THEM EVEN MORE ON SOMETHING THEY WERE ALREADY PENALIZED 
%PROPENSITY TO CHOSE.
%PULLING PUNISHMENT FORWARD --CHARGING RIGHT WHEN I MESS UP.
%MAYBE ONLY IMPATIENT AND NAIVE END IN PAWNSHOPS
%1) SELECT A RANDOM SAMPLE OF NEIGHBORHOODS, EXTERNAL VALIDITY, THE ONES THEY GO ARE NAIF AND
%HYPERBOLIC
%2) ASK TO CHOSE AMONG ALL CONTRACTS
%3) CLASSIFY SOPHISTICATION AT BASELINE
%4) HOW TO GET AT SHOCKS.  --BUT DOES NOT SQUARE WITH WHY CHARGING THEM FEES WORKE.
%do shocks vary across strata, predict shocks.
%DEEP BEHAVIORAL PAPER -- CAN WE REALLY PREDICT?



\section{Introduction}

Restrictions of choice are often surreptitiously imposed on consumers. Firms limit their worker's freedom by requiring time-consuming progress reports,  schools impose deadlines and pop quizzes, and loan contracts often require monthly repayment. As pointed out by \cite{Laibson2018}, although these choice-restricting mechanisms may be beneficial to firms and clients, they are often disliked by the latter, and therefore ``shrouded'' by firms, i.e. not advertised but nonetheless embedded in products. \cite{Laibson2018} coins the term ``private paternalism'' for cases when restrictions on the freedom of choice is implemented by a firm in a way that advances a client's interests. 

Making a case for private paternalism is not easy. It involves comparing the causal effect of forcing a certain product characteristic against the effect of letting people choose it. Because choice may be correlated with unobservables, identifying these two effects is challenging in observational studies.  %This is not a straightforward task because choice will be driven by unobservable factors, and to address the question fully 
Moreover, painting a complete picture of the benefits of forcing requires counterfactuals for both choosers and non-choosers alike, since the differential benefit of forcing arises from impacts among those who do not freely choose commitment. While a large behavioral literature has illustrated that allowing borrowers or savers to choose commitment-style products increase savings in an intention-to-treat (ITT) sense \citep{thaler2004save, prina2015banking, brune2016facilitating, callen2019headwaters, Pascaline, Ashraf}, this literature has rarely addressed the benefits of imposing commitment or its differential impacts on those who would not independently choose commitment.  
%\footnote{Selection on gains has such wide acceptance that economists often impose it in their models} (Although the examples above are plausible, substantiating a case for private paternalism is not easy. It involves comparing the causal effect of forcing a certain product characteristic versus the effect of letting people choose on that characteristic. This is not an easy task because a given person wither has or does not have choice, and because choice induces selection, potentially biasing causal estimates. A large behavioral literature has illustrated that allocating borrowers to a commitment-savings product increase savings \citep{thaler2004save, prina2015banking, brune2016facilitating, callen2019headwaters, Pascaline, Ashraf}, but this literature does not show that commitment would not be chosen by those that would benefit from it, that is, that the treatment effect on the untreated (TUT) is positive. 
Indeed, selection on gains has such wide acceptance that economists often impose it as a part of Roy models on topics as diverse as migration \citep{borjas1989economic} and job search \citep{lippman1976economics}.
%, and program evaluation \citep{bjorklund1987estimation}. 
In microfinance, a context close to ours, \citep{Murdoch} claim that there exists positive selection, citing a positive correlation between displaying present biased preferences in surveys and selecting into microfinance as evidence of borrowers' actually demanding the discipline imposed by frequent payments. However, they are unable to show that borrowers indeed benefit or that they indeed positively select based on treatment effects.

%Many people have a difficult time accumulating and retaining capital unless they are provided a structure within which to do so.  The behavioral lens on intertemporal financial services has provided critical insights on this problem, suggesting that saving from cash-in-hand is challenging \citep{Ashraf, Pascaline}, that credit may be preferred to savings as a way of accumulating capital simply because credit repayment contracts provide more structure \cite{Murdoch}, and even that the absence of structured financial contracts may be a key barrier preventing the poor from climbing out of poverty \citep{bertrand2004behavioral, collins2009portfolios}.  A large behavioral literature has illustrated that the addition of commitment-style product features improves the ability to accumulate savings \citep{thaler2004save, prina2015banking, brune2016facilitating, callen2019headwaters} and to retire debt \citep{Bertrand, heidhues2010exploiting}.  As a consequence, credit markets featuring limited-liability loans such as small-business financing or microfinance typically take a highly structured approach to credit contracts with frequent repayments and reminders as a way of inducing repayment.  As pointed out by \cite{Laibson2018}, because many of these forms of commitment may be desirable to principals but not demanded by agents (or by the right agents), these mechanisms are often ‘shrouded’, meaning that commitment is embedded in products in ways that are not advertised to clients as such.

This paper studies the benefits of restricting choice in the context of pawnbroker lending. Pawn loans are one of the oldest, most understudied, and most prevalent forms of borrowing \citep{carter2012pawnshops}. There are more than 11,000 pawn shops across the US, with 30 million clients and \$14 billion yearly revenues (in China it is a \$43 billion industry).\footnote{\url{https://tinyurl.com/ybm56dpe}, \url{https://tinyurl.com/y9zdcgws}, \url{https://tinyurl.com/y59ptdam}.} Our partner pawn lender (henceforth Lender $P$) alone served more than 1 million clients in Mexico in the last 3 years with more than 4 million contracts.\footnote{For comparison there were 2.3 million micro-finance clients in Mexico in 2009 (\cite{Pedroza:2010}).} Pawnshop lending presents an inverted lending case: since these loans are over-capitalized, the lender in the contract stands to gain the most when borrowers default. 

Our partner's standard pawn contract gave 70\% of the value of gold collateral in credit, and charged a monthly interest rate of 7\% for loans of a three-month duration, with a flexible no-reminders contract typical of the industry that can be paid back anytime before the loan comes due at no penalty. This combination of features, and the fact that the gold pawn is highly liquid, means that the lender makes 90\% more profit over three months from a borrower who defaults than one who repays (30\% of collateral value recovered under default, 15.8\% of collateral value paid in interest if loan fully repaid). While an older literature considers the exploitative potential of over-collateralization and underpriced collateral \citep{basu1984implicit}, the implication of such contracts has not been analyzed in the behavioral literature.  %When the lender desires default, the repayment-inducing features of commitment-style repayment contracts become undesirable and there may be incentives for the principal to create contracts with no structure, no reminders, and simple balloon payments. 
To repurpose the language of \cite{Laibson2018}, we suggest that pawn contracts effectively shroud their \textit{lack} of commitment features to induce default in a manner that is not obvious to borrowers. Given that pawnshops, moneylenders, and paycheck lending institutions are likely to face client pools disproportionately made up of impatient and time-inconsistent individuals, the design of such contracts may have serious consequences for the financial lives of the poor.

%clients lose their pawn, and among those that recover it almost all of them pay in the last days, just before the loan elapses.\footnote{In the US default is also high at 15\% (\url{https://tinyurl.com/yc2x5bjf}).}

%In this paper we examine pawn contracts, an understudied form of credit despite their relative ubiquity \citep{carter2012pawnshops}, and a major vehicle through which poor households may dis-accumulate savings.  There are more than 11,000 pawn shops across the US, with 30 million clients and \$14 billion yearly revenues.  In China it is a 43 billion dollar industry.\footnote{\url{https://tinyurl.com/ybm56dpe}, \url{https://tinyurl.com/y9zdcgws}, \url{https://tinyurl.com/y59ptdam}.} Our partner, a Mexican pawn lender (henceforth Lender $P$) alone served more than 1 million clients in the last 3 years with more than 4 million contracts.  

Against this backdrop, we implement a multi-arm randomized control trial covering close to 10,000 pawnshop clients in 6 branches of Lender $P$ in Mexico City, using a design built to test the demand for and impact of alternative payment structures in pawn repayment contracts. Our control arm illustrates the costs of the status quo contract: fully \emph{43\%} of borrowers default and so lose their pawn as well as any payments made towards principal.\footnote{These high default rates are not uncommon, in the US default is also high at 15\% (\url{https://tinyurl.com/yc2x5bjf}).} We then implement a ``commitment choice'' arm, in which borrowers can opt into a structured repayment contract at the time of taking a loan. The structured contract requires borrowers to make three monthly payments rather than one balloon payment at the end, with each monthly payment including the accrued interest at that time as well as a nominal fee of 2\% of that month's payment if that payment is delinquent. This fee serves as a reminder and a means of reinforcing the importance of these interim payments. In addition, we include a ``forced commitment'' arm, in which all borrowers are \emph{required} to repay using the structured monthly contract that is offered on an opt-in basis in the commitment choice arm. 

The combination of voluntary and forced commitment within the RCT allows us to address several key questions. First, do structured repayment contracts lower financial costs for pawnshop borrowers? Second, do borrowers recognize this benefit, demanding commitment in sufficient numbers?  Finally, and most uniquely given the presence of a forced commitment arm, we are able to ask whether the \textit{right} borrowers voluntarily demand commitment. In particular, we use the choice, control, and forced arms to point identify the Treatment on the Treated (TOT) and the Treatment on the Untreated (TUT) effects, along with the average selection on gains (ASG) and average selection bias (ASB). 
	
Our results suggest that commitment is strongly effective in preventing default in pawnshop lending, with the average individual in the forced arm paying financing costs inclusive of fees that are 20\% lower than the control, while default decreases by 6.5 percentage points (15\% of the mean). In terms of Annual Percentage Rates, the financial cost of borrowing is reduced by 34 percentage points. That is, by imposing the structure of commitment it is possible to save borrowers money by charging them fees! These results are robust qualitatively to including transport costs of going to the branch plus losing a day's wage for each visit, using each borrower's subjective value of the pawn rather than the appraised value of the gold, and adjusting for lost liquidity from requiring monthly payments.

The monthly payment contract seems to achieve these cost savings by speeding up payments and by generating an early bifurcation of borrowers into those that will recover the pawn and those that will not.  By inducing borrowers either to fully recover or to default without making any payments it saves money that would otherwise have been paid towards loans that ultimately default, money which is lost to the borrower.  In the treatment group, the first payment occurs 13 days earlier, and the fraction recovering on the first visit is 7.7 percentage points higher. Commitment contracts also decrease the fraction of borrowers who make a payment but ultimately fail to recover their pawn by 7 percentage points.  Treatment effects are concentrated in the intensive margin as treatment does not affect the fraction of clients who pay a positive amount towards pawn recovery. That is, the commitment contract induces people who would otherwise pay something towards recovery but default to instead pay more and faster, making them more likely to recover their pawn at a lower financial cost. 

In spite of a large average treatment effect documenting financial cost savings, only 11\% of borrowers in the choice arm actually choose commitment. If the effect of commitment were homogeneous, this would be enough to conclude that the 89\% who did not choose it would have been financially better off if they had. However, we test and reject the null hypothesis of homogeneous treatment effects using the method of \cite{chernozhukov2018generic}. Can the borrowers who did not choose commitment be those who simply don’t need it? We address this question by sequentially imposing more structure on the problem. 

We start our analysis of heterogeneity by bounding the distribution of treatment effects $Y_{1i}-Y_{0i}$ using the two marginal distributions in the treatment and control arms as in \cite{fan2010sharp}. We find that at least 24\% of individual borrowers benefit from commitment, implying many borrowers did not demand it even though their individual treatment effect is positive. Next, we impose the exclusion restriction that the effect of the contract does not depend on how they got it, that is: choosing a contract has the same treatment effect as being assigned to that contract.\footnote{This is a frequently used assumption even if often implicit. For instance, a significant literature uses schooling compulsory laws to estimate the return of one more year of school, and then often interprets that schooling, in general, has this return.} We show that in this case our 3-armed experiment point identifies the TUT. We then estimate that the financial cost savings of the TUT is large, at \$356 pesos, equivalent to 24 percentage point savings in APR. That is, on average borrowers that did \textit{not} choose the frequent payment contract would have benefited from having that contract.\footnote{We estimate a positive TOT that is larger than the TUT, but it is imprecise--this results from the smaller sample size, given that few chose the monthly payment contract--and the hypothesis of TOT=TUT is rejected only with 13 percent confidence for the APR and 12 percent confidence for default.}  
%We also estimate that those that would not choose if given the opportunity would have lower status-quo outcomes (i.e. the average selection bias is negative). Finally, assuming the exclusion restriction for subsets of observable characteristics splits generated by a causal forest allows us to establish that 86\% of would-be non-choosers would save on financial cost by being assigned to frequent payments. That is, the benefits of imposing a monthly payment are distributed broadly. \hl{TuT benefits are particularly large for XXX CHARACTERISTICS, and TOT benefits for those with XXX.} 
In a final step, we impose a selection-on-observables assumption and use the Causal Random Forest algorithm of \cite{atheygrf} to estimate conditional average treatment effects (both ATEs and TUTs) for the individual borrowers in our experiment.  We estimate that 93\% of the borrowers who did not opt for the commitment contract have positive conditional TUT effects, while only 1\% of those who chose commitment have negative conditional TOT effects.   While targeting commitment products to those that benefit the most is a policy that appears attractive, in this context we find that the usable targeting variables have relatively weak predictive power and hence even the random forest only reduces the overall mis-targeting rate from 8\% (all to Forcing) to 5.5\% (our best-case feasible targeting mechanism).  

%however those most economically vulnerable, and those most overconfident about their probability of repayment, experience larger gains.

%\footnote{As in \cite{Rabin2018} we contrast subjects' \textit{own predictions} of their behavior with their actual behavior, but we do it in a natural setting.}  

%Borrowers assigned to the forced commitment contract are 5 percentage points (100\% of the mean) more likely than the control group to ask for another loan in the future, suggesting that they liked the commitment contract after experiencing it.  However, when offered the choice of commitment, very few borrowers elect to commit voluntarily.  Only 10\% of the choice arm takes up the contract, and none of the core study outcomes are significantly improved by the ability to choose commitment.  

%This is not the first paper to find low demand for commitment, however it is the first we know of that can compare choice versus forcing with a money-metric outcome such as loan repayment. 

%Most importantly, our multi-arm design allows us to show that the \textit{wrong} people choose commitment when offered it.   We illustrate this point in three distinct ways.  First, we use a Random Forest algorithm \citep{atheygrf} to estimate individual-level treatment effects for the forced versus control arm, and show the benefits of forcing to be significantly negatively correlated with the propensity to choose commitment estimated from the choice arm.  93\% of those who did not opt for the commitment contract would have been better off with it, while only 1\% of those who chose commitment would have been better off without it.  Second, a Boosted Classification Algorithm arrives at a similar answer, showing that the borrowers naturally cluster into two groups, one of which is likely to choose commitment and does not benefit from it, and the other the reverse.  Finally, estimating LATEs on compliers and non-compliers alike we show that the estimated treatment effect on non-compliers is larger than the treatment effect on compliers.  That is, those choosing commitment benefit less from commitment than those not choosing it.  Hence our results show clearly that a paternalistic policy forcing borrowers into a more rigid and structured repayment regimen is uniquely beneficial to them.  While this perverse relationship between choice and benefits from commitment echo closely the findings of \cite{Sprenger} we are the first to be able to examine this relationship using a high-stakes, money-metric outcome in a natural field environment.


What explains the persistence of no-commitment contracts so contrary to borrowers’ interests in the real world?  First, we show substantial levels of over-optimism among borrowers. Among borrowers who do not choose it, those with the largest benefits from commitment are the individuals who most systematically over-estimate their own probability of repayment at the time of taking the loan.  The dramatic improvements in borrower income arising from the commitment contract come directly from the pockets of lenders, reinforcing that the pawn industry as a whole has a strong interest in retaining the status quo.


Does learning eventually overcome the low demand for commitment? 
%For learning to happen clients would need to experiment with the frequent payment contract, and this was not the typical contract in the industry. But even if the contract was experienced, borrower may fail to learn or learn only slowly. 
We find that borrowers who are assigned the forced commitment contract are 6.7 percentage points more likely to become repeat costumers than those assigned to the status-quo contract. One potential interpretation of this result is that borrowers who experience the frequent payment contract rationally choose to borrow more later on because of the lower effective financial costs that this contract entails.\footnote{An alternative interpretation is that the monthly payments from the commitment contract sap borrowers liquidity, leading them to take a second loan to pay off the first. This is unlikely because subsequent loans fall outside the 90 day period within which payments for the first loan are due. Moreover, the correlation is also present conditional on having paid down the first loan. Borrowers tend to pledge a different piece for the second loan, so that recovery of the first pawn is also an unlikely explanation.} However, a stronger test of liking the monthly payment contract is whether conditional on coming again, they would choose frequent payments. We test this and we cannot reject that demand is higher after experiencing the monthly payment contract, however sample sizes are small and power for this analysis is correspondingly low.
%While forcing individuals into commitment does not cause them to demand it in subsequent loans, \textcolor{red}{in Table \ref{iv_pf}} we show observational evidence of `learning by not doing’:  individuals offered commitment who elect not to take it and subsequently default \textit{do} learn about the benefits of commitment, demanding commitment loans at higher rates on subsequent pawn contracts when given the choice.  Finally, while we are working with a lender who has a social mission and is interested in understanding how to help borrowers, there is no free lunch.  The dramatic improvements in borrower income arising from the commitment contract come directly from the pockets of lenders, reinforcing that the pawn industry as a whole has a strong interest in retaining the status quo.
Our results suggest that pawn lending markets capture borrower wealth in ways not well summarized by interest rates. By overcollateralizing and then structuring loan contracts in a manner encouraging of default, lenders are able to extract substantial value independent of the interest charged.  Further, the `nudge’ approach generally favored by the behavioral literature (voluntary commitment) does not generate adequate demand in this context. 

%We hesitate to give precise policy recommendations since we don't have good measures of welfare. Even though the monthly payment contract dramatically reduces financial cost, it could potentially generate lower (or higher) anxiety. Moreover, frequent payment requirements may decrease welfare of highly impatient borrowers.\footnote{The paper presents an back of the envelope exercise that suggests annual discount rates of 4000 are necessary to nullify the reductions in financial cost we estimate. \hl{Note also that since the fee for skipping payment is 2\%, the iliquidity imposed by the contract is bounded.}} %Second, given the non-standard nature of the finding, it is likely that we would have to adopt and estimate a particular behavioral model of demand for commitment, which we don't need to do to make the point that TuT is positive.

%we estimate that over 50\% of the borrowers in our study are naïve hyperbolics in the sense that they would benefit from commitment but will not choose it.  While our results are driven by the intersection of overcollateralization and a potential selection of the borrower pool towards myopia and short-term financial thinking, these attributes are likely to be present in many types of pro-poor financial markets where individuals lack the credit histories to be able to leverage short-term credit without collateral. This suggests that regulators of such markets should include what is paid through equilibrium default as part of the financing cost (not done now), and to consider imposing structured lending products that tilt the scales towards allowing borrowers to repay.  While commitment-style repayment contracts decrease effective liquidity by requiring faster repayment of a given loan, the improvement in expected borrower returns are so substantial as to prove welfare improving at all but the most astronomical discount rates.  

Our paper makes a number of contributions to the literature. %First, they suggest consequential ways in which different financial services draw client pools with distinct behavioral biases. 
First, it speaks to microfinance research on the effects of payment frequency. While experiments in microfinance markets have not shown the same benefits from providing a more regularized repayment environment as we find here \citep{Pande}, these experiments differ from ours in two important ways: they are performed on top of highly structured contracts, and they involve borrower pools who may have selected into that type of lending precisely because it provides structure. These differences may explain why \citep{Pande} finds almost no default in the control group, in stark contrast to our results. Second, we provide a deeper analysis of both the take-up and efficacy of voluntary commitment mechanisms. A number of papers have found low demand for commitment as we do (\cite{Ashraf}, \cite{Gine}, \cite{Ted}, \cite{Royer}, \cite{Sprenger}) while others have found more robust demand for commitment (\cite{Kremer},  \cite{Casaburi}, \cite{Alcohol}, \cite{AprajitP&P}, \cite{Pascaline}). Unlike all of these papers, however, we separately point identify and estimate the effects of commitment for borrowers who would and would not choose it. This allows us to conduct a more rigorous and nuanced analysis of private paternalism in our empirical context.

Two other recent papers also shed some light on private paternalism. In the context of food choice, \cite{Sprenger} show that individuals with the most time-inconsistent preferences are actually least likely to demand commitment, suggesting a lack of awareness as to self-control problems. In the context of school choice, \cite{Walters} finds that students who select into more effective schools have smaller treatment effects from attending than those who do not.
Our paper differs from these in both its empirical setting and its methodology.
As far as we are aware, ours is the first experiment to combine control, forced treatment, and treatment choice arms and explain how such a design can be used to point identify TUT effects and a range of other interesting causal parameters under minimal assumptions.
While \cite{fowlie2021default} likewise exploited a three-armed experimental design in their study of the effect of electricity pricing, they identified two TOT effects for different groups of ``treated'' households, whereas we simultaneously identify the TOT and TUT effects defined with respect to a single ``treated'' group of borrowers.
We call our approach the ``Controlled Choice design'' for short.
Other approaches to going beyond local average treatment effects (LATE) from the literature either assume no unobserved selection-on-gains \citep{aronow2013beyond,angrist2013extrapolate} (the ``LATE-and-reweight'' approach) or rely on a combination of instruments with rich support and additional structural assumptions such as additive separability of observed and unobserved determinants of treatment effect heterogeneity \citep{heckman2007econometric, cornelissen2018benefits} (the marginal treatment effects approach).
\cite{Walters} takes the latter approach, combining a distance instrument with additional structural assumptions, obtaining model-based TUT and ATE estimates that differ substantially from those implied by a LATE-and-reweight approach. 
In contrast, we leverage our experimental design to point identify the TUT effect using a binary instrument without the need for a structural model, relying instead on relatively simple exclusion restrictions. This restriction has testable implications that we fail to reject. Rather than assuming away unobserved selection-on-gains, as in the LATE-and-reweight approach, we estimate it directly.
Unlike \cite{Sprenger} we directly identify the TUT, obviating the need to first elicit preferences before testing for negative selection.
In a returns-to-education setting, \cite{oreopoulos2006estimating}, uses a similar direct approach to identify a LATE \emph{nearly} equals a TUT effect: the 1944 Butler Act increased the share of British children who remained in school until age 15 from 43\% to over 90\%. Because 100\% of borrowers in our forced arm are treated, we identify the TUT rather than an approximation to it.


%We illustrate here how experimental design can be used to form a simple test for selection on gains.  

%In contrast to the broader literature on Marginal Treatment Effects \citep{heckman2007econometric}), we exploit simple randomization and an exclusion restriction on choice rather than requiring a continuous instrument that can be used to build a structural model as in \cite{Walters}.  


%achieve identification of the TuT by using parametric model and a distance instrument, which requires the model to be correct and the instrument to be valid. TUT and ATE implied by LATE-and-re-weight differ sharply from his model-based estimates. The method of 

%Methodologically we contribute to the large literature on treatment effect heterogeneity by showing how an experimental design with two forcing arms and one choice arm allows for identification of the TOT, the TUT and other important parameters under minimal assumptions. \cite{aronow2013beyond} and \cite{angrist2013extrapolate} assume no selection on gains to estimate \hl{XXX}. 

%\cite{heckman2007econometric} and \cite{cornelissen2018benefits} require the availability of instrumental variable with rich support, and separability of observed and unobserved determinants of treatment effects.   

The remainder of the paper is structured as follows:  Section \ref{context} provides context and defines our main outcome variables. Section \ref{Design} describes the experiment and data sources, and shows pre-treatment balance across arms. Section \ref{Experiment} provides the standard ITT analysis of the experiment, while Section \ref{Choice} presents our strategy for estimating ToT and TuT effects, and Section \ref{Paternalism} investigates why paternalism functions so well in this context and whether it can be more finely targeted.  Section \ref{conclusion} concludes.






\section{Context} \label{context}

\subsection{Pawnshop borrowing}
    
Pawn loans involve individuals leaving valuable liquid assets, typically jewelry, as collateral in exchange for an immediate cash loan. Collateral is typically larger than the loan, allowing lenders to skip the checking of credit history and give the loan immediately. This makes pawn loans a popular way to get cash to pay for emergencies. In fact, they are one of the most prevalent forms of borrowing. There are more than 11,000 pawn shops across the US, with 30 million clients and \$14 billion yearly revenues.\footnote{\url{https://tinyurl.com/ybm56dpe}, \url{https://tinyurl.com/y9zdcgws}, \url{https://tinyurl.com/y59ptdam}.} Our partner pawn lender alone served more than 1 million clients in the last 3 years with more than 4 million contracts. For comparison there were 2.3 million micro-finance clients across all lenders in Mexico in 2009 \citep{Pedroza:2010}. 

Pawning is also one of the oldest forms of borrowing. Pawn lending existed in antiquity at least since the Roman Empire, and there are records of it in China about 1,500 years ago \citep{PawnShops}. In spite of the high prevalence and long history, pawnshop borrowing has not received much attention in the economics literature. The closest widely studied product is payday loans. In developing countries, however, payday lending is likely small compared to pawnshop lending; the latter is faster and requires less documentation, making it more accessible to informal sector workers who receive their salaries in cash. %According to \cite{Payday} to get a payday loan: ``All that a prospective borrower typically needs is a home address; a valid checking account; a driver’s license and Social Security number; a couple of pay stubs to verify employment; wages and pay dates; and minimum earnings of at least \$1,000 a month''. Although the author meant this list as an instance of low requirements, they would render virtually all poor households in the developing countries ineligible. 

%Lender $P$ was interested in understanding why half of their clients lost their pawn. Default is high in this context  compared to many papers in the microfinance literature.\footnote{\cite{Pande} study of the effect of payment frequency in a context where the rate of default is close to 1\%.} 


As with payday lending, pawnshop lending is controversial. Regulators have concerns with the sophistication of borrowers using it, speculating they may suffer from behavioral and cognitive deficiencies which lead to make sub-optimal choices.\footnote{The US congress has actually banned the payday lending industry from serving active military personnel, and some States in the US have imposed zoning restrictions, interest caps, and restrictions on serial borrowing as consumer protection measures against payday lending \citep{Payday}.} There is some evidence in support of this view for payday borrowers.\footnote{\cite{Bertrand} write that ``Under the view that the people borrowing from payday lenders are making an informed, utility-maximizing choice given the constraints that they face, one would not expect additional information disclosure about the payday product to alter their borrowing behavior'', but to the contrary, they find that simply disclosing how financing costs add up reduced demand by 11\%. \cite{Meltzer} finds that payday loan access leads to increased difficulty paying mortgage, rent and utilities bills.}  Our study reinforces the idea that a lack of sophistication may be an integral part of that way that standard pawn contracts are structured.



\subsection{Pawning Logistics and Contracts}

To study this market, we partnered with one of the largest pawn shops in Mexico, an institution with more than one hundred branches spanning multiple states in Mexico. This lender (whom we refer to as `Lender P') has a simple and typical business model. 

\paragraph{Appraising and lending.} Lender P takes gold jewelry as collateral in exchange for a fraction the value of the piece, in cash. No other collateral and no credit history checks are needed. The transaction takes less than 10 minutes and is conducted at the branch in person between the client and the appraiser (i.e. a teller, see Figure \ref{PawnshopPicture}). The appraiser weighs the gold piece and runs tests on its purity. Based on these she assigns a gold value to the piece, stores it as collateral, and gives 70\% of the gold value of the piece in cash to the client. The borrower signs a 2-page contract with the conditions of the loan and leaves with the cash.

\paragraph{Contract.} Lender P had only one type of contract, henceforth the \textit{status quo} contract. It stipulated that the interest rate was 7\% \textit{per month} compounded daily on the outstanding amount of the loan. The loan had a 90 days term with 15 days' grace period. The client could make payments at the branch at anytime with no penalty for pre-payment. No reminders or interim contact exists between the lender and the borrower. If the client returns to pay the principal plus the accumulated interest within 105 days, she received back her pawn, otherwise the pawnbroker kept the piece \textit{and} any payments made. Before the contract expired, the client had the right to renew for another 3 months by going to the pawnshop, paying the accumulated interest, and signing a new contract with exactly the same terms and same piece as the original one a (26\% of borrowers renew at least once with a given pawn). This contract was standard in the industry.  Pawnshops make money in three ways: by reselling the jewelry left as collateral on defaulted loans, by charging interest on non-defaulted loans, and by keeping the payments made on defaulted loans. 

\paragraph{Borrowers.} The clients that pawned understood these terms well (as we verified in interviews).\footnote{87\% of clients report in our survey that they have pawned before.} These clients have little or no access to other types of loans and they value the convenience of pawn borrowing.  This population of pawn borrowers is economically vulnerable:  30\% of them could not pay either water, electricity \& gas or rent in the past 6 months; 87\% said they are pawning because of an emergency, and only 13\% stated it was to use in a `non-urgent expense'.  When asked why they are pawning this piece, 5\% responded `lost a family member', `a medical emergency' (11\%), or `an urgent expense' (71\%).


\paragraph{Many borrowers lose their pawn.} Our context is also one with high borrower default: 43\% of clients lose their pawn in a time span of 230 days from the date of pawning. One potential explanation for high default is that clients are really just knowingly selling their gold piece through a pawn contract on which they intend to default. This appears unlikely for several reasons: (a) clients can easily sell the gold and obtain a higher amount of instant cash at gold buying stores located close to almost all our pawnshop branches (see Figure \ref{GoldBuyers}), (b) the reported subjective value of the pawn is larger than the loan size for 86\% of clients, (c) among those that lose their pawn, 48\% paid a positive amount towards its recovery and on average paid 42\% of the value of their loan (see Figure \ref{proxy_naive} in Appendix) --- this can only be rationalized if they expected to recover their pawn, and (d) 74\% of borrowers report a 100\% probability of repaying their loan (and 98\% at least a 50\% chance of repaying) in our baseline survey at the time they take the loan.  Note that high default could be detrimental from the lender's point of view, since it may reduce the likelihood that the client becomes a return customer. 
%Lender P was in fact explicitly interested in partnering with us to investigate how to reduce loan default, customer satisfaction, and repeat borrowing.

    
\subsection{Measuring Borrowers Financial Costs} 
\label{costs}
    
Borrowers' financial costs are composed of two main categories: the cost of losing their collateral, and the interest incurred during the life of the loan. For each given loan we observe if the client lost her pawn ($\mathds{1}(\text{Default}_i)$) and when. If the client has renewed her loan several times such that the loan is continuing but has not defaulted, we pursue the strategy of coding default as zero (this approach is conservative in our context in that it does not lead the reduction in repayment time to translate mechanically into a drop in default). In our data 13\% of experimental loans are continuing (i.e. censored) when the data period ends. Regarding interest, the administrative data classifies payments made in three types according to their payment allocation rules: payments to principal $P^c$, payments on generated interests $P^i$, and payments on penalty fees $P^f$. We observe each and every payment made under each category, its amount and date. 

We define a borrower's financial cost as the total monetary outflow --in cash or pawn value-- from the borrower to the lender. This includes all payments the borrower made toward interest and fees, but also the value of the pawn when there is default. When there is no default the borrower gets her pawn back and there is no loss of value for the borrower. Payments towards capital are considered a cost only when the borrower defaults, as she does not get reimbursed for these. Note however that when she does not default payments to capital are not an actual outflow, as they sum up to the value of the loan the lender disbursed in the first place. The formula for financial cost for person $i$ is thus as follows:

\begin{align*}
    \text{Financial Cost}_i =&  \underbrace{\sum_t P^i_{it}}_{\text{Payments to interest}} + \underbrace{\sum_t P^f_{it}}_{\text{Payments of fees}}   \\
    &\quad\qquad + \underbrace{\mathds{1}(\text{Default}_i) \times (\text{Appraised Value}_i}_{\text{Cost of losing pawn}} + \underbrace{\sum_t P^c_{it}}_{\text{Payments to capital}})
\end{align*}

\noindent where $t$ indexes days, and $\mathds{1}(\text{Default}_i)$ is an indicator function for defaulting. Because the period of the loan is only 90 days we do not use discounting in calculating costs.  In robustness checks we show that results are virtually unchanged when applying a wide range of time discounting factors.

We believe the above measure captures financial cost in pesos accurately. However, we will also report results incorporating two costs that are not financial: (i) using the subjective value of the pawn reported by the borrower in place of its appraised gold value, and (ii) adding a measure of travel expenses and the opportunity cost of time, as clients have to go to the branch in order to make payments.

As a second measure of cost we calculate the Annual Percentage Rate (APR) in order to express the cost as a percentage of the loan, per year, inclusive of default costs.\footnote{Loan term takes into account the entire loan period, including extensions of the loan through refinancing.} The standard definition is given in the following formula:


\begin{align*}
    (\text{APR})_i =&\left( 1 + \frac{\frac{\text{Financial Cost}_i}{\text{Appraised Value}_i}}{\text{loan term}_i}\right)^{\text{loan term}_i}-1 
\end{align*}

\vspace{.1in}

Figure \ref{fc_hist}(a) plots a histogram of this financial cost in pesos for all loans in the experiment, distinguishing by whether we observed they defaulted (43\%), recovered their pawn (44\%), or whether they are censored in our data (13\%). The first thing to note is that those that default incur in higher costs; part of this is mechanical as losing their collateral is part of the cost. The second thing to note is that those that are not closed at the end of our sample period have already incurred in substantial financial cost, even though they have not defaulted yet. Panel (b) shows the APR; most of the APR costs come from clients that do not recover their pawn. 
%Of those who renew, 83\% lose the pawn. Figure \ref{fc_hist}(a) suggest that financial cost is significant, even for those that do recover their pawn. Panel (b) normalizes the cost by loan size. It shows that as a percentage of their pawn, most of the cost comes from clients that do not recover their pawn. For them the cost is between 140\% and 250\% of the loan value. %{The difference between panel (a) and (b) arises since clients who lose their pawn tend to be those that pledge cheaper pieces.} 


%We calculate an APR of 218\% on average for the control group.%\footnote{The Annual Percentage Rate (for pawn $j$) is calculated as the internal rate of return $i$ such that $\sum_t \frac{P_{jt}}{(1+i)^t} + \frac{\text{I}(Default \: Pawn_j) \times Pawn \: Value_j}{(1+i)^T} - Pawn \: Value_j = 0$, where $T$ is the date the pawn was lost, and $P_{jt} =P_{jt}^c+P_{jt}^f+P_{jt}^i $ is the sum of all payments.}



\section{Experimental Design} \label{Design}

\subsection{Treatment arms and randomization}

\noindent \textbf{The Commitment Contract.} For the purpose of the experiment we designed a new contract that is identical to the status quo contract except that, informed by the design of micro-lending contracts, it enhances the regularity and salience of payments as a way to encourage repayment \citep{morduch1999microfinance, bauer2012behavioral}.  It has the same interest rate (7\% \textit{per month}) which accumulates daily on outstanding debt, it has the same loan size/collateral ratio (70\%), it has the same loan term (90 days, and a grace period of 15 days), and the gold pawn gets appraised in the same way by the same appraisers. The Commitment contract however requires the client to make regular monthly payments for the duration of the contract, with the principal and interest payments split evenly across the three months of the contract (day 30, 60 and 90 after loan disbursement). The importance of this monthly payment was made salient in the contract and payment receipts (see Figure \ref{PaperSlip}), and by the levying of a nominal fee (2\% of minimum due) on individuals who fell behind in their payments.  The idea that the fee itself is not driving the treatment is reinforced later in the paper where we show financial benefits many times larger than the fee, as well as treatment effects even on those who would fail to recover pawns and hence not pay the fee. Transportation cost to go to the branch to pay is on the same order of magnitude as the fee on average.
%\footnote{%The lender was worried that if the fee was large, forgetting to pay could make the pawn unrecoverable. 
%In contrast with \cite{John} we don't let the clients choose the size of the fee. \cite{John} shows that doing this results in costly choices by (partially) naive present biased consumers. Our fee is much smaller than the median in her experiment. %We also experimented with a contract where there was no pecuniary fee for paying late but where we clients made a personal promise to pay monthly.}
To elicit demand for the monthly payment contract, we include an arm that allows borrowers to opt into this contract if they choose. The existence of both a non-optional ``forcing'' arm, and a choice arm in our design is key to estimate a battery of treatment effects above an average treatment effect under fairly mild assumptions.

%In order to explore lower-cost forms of structure, we also include arms that feature `soft' commitment, asking or requiring individuals to follow the more regular payment structure of the commitment contract but then providing no reminders or repercussions for failing to do so.  A substantial literature documents that people are averse to to breaking their promises, and are willing to incur in monetary losses in trying to keep them. This provides a potentially very attractive way to drive better repayment behavior at low pecuniary cost to clients.  Numerous lab experiments and at least one field experiment on financial services show that such soft commitment can work \citep{Craig}.\footnote{Grameen Bank for instance makes clients recite a promise at each center weekly meeting.The exact promise repeated by clients live is this: ``\textit{We pledge to attend regularly the weekly Center meetings, to utilize our loans for the purpose approved, to save and pay our installments weekly, to use our increased incomes for the benefit of our families, to ensure that other members of our group and Center do likewise and to take collective responsibility if they do not.''}}  The soft treatments mimic the commitment arms as closely as possible without imposing external remainders or pecuniary consequences for failing to meet terms.

\vspace{.2in}
\noindent \textbf{Treatment Arms.} Treatments were randomized at the branch-day level. Each day a computer randomly assigned which types of contracts were on offer that day in the branch, and the IT system would only offer these.  We have 3 different experimental arms\footnote{The experiment included other arms that involved no fee penalties and did not emphasize the structure of payments. These are being analyzed in a separate paper.} 


\begin{enumerate}
    \item \textit{Control} arm: consisted of branch-days offering the status quo contract described in Section \ref{context}, and only this contract. 
    \item \textit{Forced Commitment} arm: consisted of branch-days requiring all borrowers to use the Commitment contract described above.  
    \item \textit{Commitment Choice} arm: consisted of branch-days offering the client \textit{a choice} between the Commitment contract, and the status quo contract.
    %\item \textit{Forced Soft Commitment} arm: consisted of branch-days in which borrowers were asked to sign a non-binding written commitment to pay monthly as in the Commitment contract, but no reminders or fees were imposed if they did not.\footnote{The client was made to sign a paper which said ``I promise to pay every month the corresponding sum of \_\_\_\_\_\_, on the dates \_\_\_\_\_\_, \_\_\_\_\_\_, and \_\_\_\_\_\_. This is \underline{not} a legal document and cannot be used in courts. It is just a \textit{personal promise}. If I do not comply I will not have kept my word''. After signing, the promise was read to the client by the appraiser.}%\footnote{Our setting does not allow us to separate if the client is making a promise to the bank teller or whether she is mentally interpreting this as an internal promise to herself as a goal. We thank Anett John for pointing this out.}
    %\item \textit{Soft Commitment Choice} arm: consisted of branch-days on which the client was given \textit{a choice} between the Soft Commitment and the status quo contract.
\end{enumerate}

We did not allocate an equal number of days across arms, since we were interested in having more power in some of them. The number of branch days allocated to each were 84 to control, 80 to forced commitment, and 93 to choice. See Figure \ref{exp_description} for a CONSORT-style diagram of the study design and recruitment.

%The existence of a choice arm allows us not only to measure if there is demand for such a contract, but who demands it, not only in demographic terms, but in terms of potential treatment effects. One may worry for instance that low sophistication from pawn-loans users could lead to the `wrong' people choosing the structured commitment contract. To examine this issue, we included an arm that assigns all individuals to the commitment contract so that we are able in essence to form three counterfactual outcomes; no commitment, commitment, and the chosen commitment. This design allows us to investigate the repercussions of choice not only for those who \textit{do} choose (as is the case in a standard LATE design), but also the implications of choice for those who \textit{do not} choose. This design is innovative and critical for our purposes, as it enables us to explore whether or not forcing people into a structured payment contract could be more beneficial than allowing choice for a significant fraction of them.


\vspace{.2in}
\noindent \textbf{Randomization.}  Starting September 6, 2012, we implemented the experiment in 6 branches of Lender $P$. The branches were selected by Lender $P$ to be dispersed across Mexico City and have varying sizes. In four of them the experiment ran for 107 days, and in 2 of them we ran it for a shorter time to economize on data collection costs once we realized we would not be constrained by sample size. %Thus we eliminated {the smallest} ones. 
Branches are more than 5 km apart from each other, and there is little substitution among them; only 1\% of consumers appear in more than one of our branches.

Branch personnel did not know which treatment would happen on which day and were blind to the objective of the intervention. They were told that there were 3 different ``types of contract-days'', that the system chose randomly which applied on any given date, and that it could happen for instance that two consecutive dates had the same contract. They were also told that this way of operating was in place in several of Lender P's branches (they did not know which ones), and that it would be in place for several months. Randomizing at the day level limits the problem of contamination arising from clients realizing that other clients get different contracts than theirs. It also limits potential manipulation by appraisers, who in the presence of individual-level randomization could potentially pick their preferred customer from the line or tell them to wait until their desired contract shows up on the screen. Intra-branch day correlation on the probability of default (ICC) is small, at {0.05}, so we lose little power vis-a-vis individual-level randomization.



Some clients pawned more than one time during the duration of the experiment, with 14\% pawning 2 times and 8\% more than 2 times. To have a clean comparison we are considering only the first pawn in the experiment. It is also the case that 30\% of those first pawns involve more than 1 loan, as 2 or more pieces of gold were submitted. We treat each of them as separate loans.


\paragraph{Timeline.} Figure \ref{exp_description} shows the timeline when the experiment happens and also the length of time for which we observe payments. For contracts in the first week, we observe up to 338 subsequent days, while for contracts in the last week we observe up to 235 days. Figure \ref{exp_description} also illustrates the number branch-days per arm, the number of contracts, and the number of surveys. %Not every contract has a survey for several reasons, we have survey information for \hl{XXX\%} of them. There were two reasons: \hl{XXX}.

\paragraph{Explanation.} Since we are interested in measuring the effect of different contract terms on client behavior, it is important that clients understand them. To ensure this, we built two `check-points'.  First, two enumerators were present in each branch for the whole day during the duration of our experiment to explain the contract terms to clients. One of the aspects emphasized was that the frequent payment contract involved the commitment to pay a third of the outstanding amount \underline{each month}, and the nature of the fees associated with the Commitment arm. Figure \ref{ExplanatoryMaterial} translates a piece of the materials we used to explain the contracts. The explanation took about 3-5 minutes and was pursued until the client said she understood the contract terms. Enumerators then asked clients to explain back the contract terms and corrected any misunderstandings. The second check-point was that before the clients signed the contract, the appraiser made them read the ``Contract Terms Summary'' sheet shown in Figure \ref{PaperSlip}. It was a piece of paper given to clients after their piece had been appraised and the size of the loan determined, but before they signed their contract. The appraiser read it and asked the client to sign it as proof of understating. %The sheet clearly indicates that this contract is a monthly payment one (numeral 1), that there is a penalty of 2\% for paying late (numeral 2), and the 3 payment dates (numeral 3). 
%Finally, the bottom of the Figure \ref{PaperSlip} shows the paper slip we used for the promise arms. The clients had to put their name on a slip of paper where they stated they promised to pay monthly.
We are confident the overwhelming majority of clients understood the contracts and that those in the choice arm made informed choices.
%\footnote{That we can systematically predict demand based on consumer characteristics and measured beliefs suggest that take up is not random.}


\subsection{Data}

\paragraph{Administrative data.} The study exploits two types of data: administrative data from the lender, and a short survey we implemented. The administrative data contains a unique identifier for each client, an identifier for the piece she is pawning, and the transactions relating to that piece. These transactions include the value of the item as assessed by the appraiser, the amount of money loaned (70\% of the value), the date of the pawn transaction, and the type of contract for that pawn. Within the period of the loan, we followed each transaction related to that piece in the administrative data: when payments were made and for what amounts, whether there was default (i.e.\ the client lost her pawn), and whether any late-payment fees were imposed. After the experimental loan, we are able to track subsequent behavior and to see whether that borrower took a subsequent loan.  We have this information for all the pawns that occurred in the experiment's 6 branches between August 2, 2012 and August 13, 2013, this includes all the pawns under our experiment but also those that happened 1 month before it started and up to 8 months after it ended. Figure \ref{exp_description} shows the design and timing of the experiment, along with the sample sizes in each arm. The experiment comprises 13,446 pawns, and our administrative data cover a total of 23,974 pawns.

\paragraph{Survey data.} In addition, we had a team of enumerators in each branch collect surveys and clearly explain the contract terms to walk-in clients. The enumerators were inside the branch and asked clients to complete a 5-minute survey \textit{before} going to the teller window to appraise their piece and before treatment status was known to them. The survey was intentionally short to avoid discouraging the potential clients from pawning, but at the same time it aimed to measure the following: demographics, proxies for income/wealth, education, present-biased preferences, experience pawning, if family or friends commonly asked for money, how time consuming and costly it was to come to the branch, the subjective probability of recovering the piece that they intended to pawn, the subjective value of their piece in money terms (how much money they would sell it for), among others. We surveyed 10,437 clients, and the survey response rate was 78\% among clients who took loans.\footnote{Appendix \ref{baseline_survey} transcribes the questionnaire in English.} %\footnote{We also surveyed clients before and after the experiment, so our survey covers a larger sample that we are not using in this paper.}. 


\subsection{Experimental Integrity}
\label{sec:integrity}

\paragraph{Attrition.} There are two main channels through which attrition could complicate the interpretation of our results. The first, and more serious, is the possibility that clients might change their pawning decisions in response to the treatment they encounter in a given branch on the day they enter.  If this occurred it would introduce a self-selection dimension which would still reflect the overall impact of a treatment for the lender's portfolio but would no longer deliver \textit{ceteris paribus} effects of treatments on individual borrowers.  Narrative reports and the way the treatment was implemented make us believe that selection into treatment is unlikely.\footnote{Potential clients did not know that different days could have different contracts. If they asked, appraisers said that whatever was offered on that day was the only available contract for an undetermined length of time. Anecdotally, appraisers told us that they did not think refusals differed across arms, and our enumerators informed us that potential clients rarely left the branch without pawning. Lender P also never complained to us that our different treatments were hurting sales.} If the treatments had induced demand-side selection, we would expect to see that the number of pawns successfully conducted differ in a systematic way across arms.  To test for this, we examine the number of loans given per branch-day, with specific attention to whether the Forced Commitment arm led to a lower number of borrowers per day. The first row of Table \ref{attrition_table} shows there is no difference between the Control and Forced Commitment arm in terms of the number of pawns per branch-day.\footnote{The Choice arm appears to have a somewhat larger number of borrowers than the Control arm (p-value=0.06), but we cannot reject equality with the Forced Commitment arm (p-value=0.41), or across all arms (p-value=0.16).}  The second row makes the same point in a more focused way, given that the surveys were conducted prior to the revelation of treatment status.  In no arm did more than three percent of individuals who responded to the survey go on to refuse loans, and neither these rates nor the rate of survey response are different across arms.  Therefore it appears that the treatments have not induced any endogenous shifts in the composition of borrowers.

A less critical form of attrition would be a differential refusal to answer the survey questions.  The survey was done before treatment status was revealed, and we observe loan outcomes regardless of whether the survey was conducted.  Our core experimental estimates do not use the survey data as covariates, but the Random Forest analysis in Section \ref{Paternalism} is restricted to the subset of borrowers who answered at least some survey questions. The bottom row of Table \ref{attrition_table} shows that the survey response rate is broadly similar across arms (about 77 percent). 
%We can also examine differences in the fraction of borrowers who do respond to the survey and then do not end up taking a loan subsequent to completing the survey, we find that the share is close to 100\% as is the fraction of those 97\% across arms (p-value=0.62).
%\footnote{We also tested if the number of pawns per day for the 6 branches that participated in the experiment was different 1 month before the experiment started or 1 month after the experiment ended, relative to the days the experiment was active. To this end we estimated the regression. We cluster the standard errors by branch.} $Pawns \: per \: day_{jt} = \alpha_j + \gamma f(t) + \beta_b \mathbbm{1}(t \in MB)_{t} +\beta_a \mathbbm{1}(t \in MA)_{t}$, where $\alpha_j$ are branch fixed effects, $f(t)$ is a third degree polynomial in time, $\beta_b$ measures a level effect in the number of pawns per branch a month before the experiment started, and $\beta_a$ a month after. We estimate no difference in the number of pawns, showing that people are not leaving the branch without pawning at larger rates during the experiment ($\beta_a=1.32$, $\beta_b=-0.65$, with p-values 0.11 and 0.83, respectively).  Table \ref{num_pawns_bal} shows the beta coefficients from these regressions, which are nowhere significant.}  Hence while survey response was not universal, there is no evidence that it was differential across arms.


A more subtle form of sample selection could arise if the treatments induce borrowers to re-pawn in different ways, especially given that their treatment status on subsequent loan/days may not be the same as that initially assigned.  To handle this issue our analysis uses only the first loan taken by each individual during the experimental window.  

%\subsection{Connection to the literature}
%Our study connects with two strands of the literature on microfinance. But also to a nascent one that uses RCTs to study to what extent people self-sort to treatments that have larger beneficial treatment effects for them. On the microfinance literature the first paper we could find that used an RCT to evaluate the causal effect of frequent payments in loans is \cite{Pande}. In a group lending rosca context, they note that most contracts involved frequent repayments --even weekly in many instances-- even when this increases transaction costs. They note that clients could benefit from ``the fiscal discipline afforded by the more rigid payments''. Frequency could provide a commitment device for clients, could foster a payment habit, or could generate more trust from social interactions among the group of borrowers. All these potential benefits apply in our context, except those relating to social interactions, as we work with individualized loans.
   
%\subsection{More on implementation} %\label{implementation}

    
\paragraph{Balance.} Table \ref{SS} presents summary statistics for the sample of actual borrowers across arms, and illustrates that randomization worked to achieve balance across the experimental arms. Panel A uses administrative data for the universe of borrowers in each arm, and shows that loan balances and the days on the week on which individuals pawned are comparable across arms. The average loan size is \$2267 MXN (\$130 USD). Panel B of Table \ref{SS} reports summary statistics across arms from our survey data. 73\% of clients are women, with an average age of 43 years; 66\% of them have completed high school or more, and 90\% have pawned before, so that our sample has mostly experienced borrowers. Finally, the subjective probability of recovery is close to 93\% on average, which makes a stark contrast to the actual rate of recovery of 43\%; borrowers are highly overconfident on average. The average subjective value they report for the items they pawn is 4084 MXN, much larger than the average appraised gold value of 3238 MXN. While this could arise either from overconfidence in valuation or from undervaluation by the lender, in any case it is \textit{prima facie} evidence that loss of the pawn should be undesirable relative to the quantity of liquidity leveraged by the asset. 

%Panel C repeats the exercise in Panel B, but now only for those borrowers answered the survey and then went on to take a loan.  Since we have aready shown that the attrition rate of borrowers after completing the survey was very low (3\% on average) it is unsurprising that these two panels are similar.  Overall, we find both the loan attributes and the survey attributes of borrowers to be similar across arms.  The experiment appears to have been successful in generating a balanced sample for analysis.





%Panel A describes variables from the administrative data.  The average number of pawns per day per branch is 34. Only 42\% of clients recover their pawn. Even those that recover their pawn tend to pay it back at the last moment, with only 40\% paying before the 90th day.



\section{Average Treatment Effects} \label{Experiment}

We begin by estimating average treatment effects of assignment to the Forced commitment and the Choice arms, relative to those assigned to the Control arm. As we explain below, only about 11\% of those in the choice arm chose the monthly payment option (Figure \ref{determinants_choose} shows coefficient plots for the characteristics that determine choosing commitment in the Choice arm).

%\subsection{Average Treatment Effects}

\paragraph{Specification.} Table \ref{main_impact_table} presents estimates and standard errors from a standard pooled experimental regression 
\begin{equation} \label{basic_reg}
    y_{ij} = \alpha + \beta^F T_{i}^F + \beta^C T_{i}^C + \gamma X_{ij} + \epsilon_{ij}
\end{equation}
where $i$ indexes client, $j$ indexes branch, $T_{i}^F$ and $T_{i}^C$ are indicator variables for receiving the Forced or Choice arms, $X_{ij}$ are branch and day-of-week fixed effects. Standard errors are clustered at the branch-day level, the unit of treatment assignment\footnote{A minority of clients pawned on more than one day during the experiment: 15\% pawned on two distinct days, and 7.5\% on three or more days. To avoid contamination from earlier treatments to which these individuals were exposed, we restrict our sample to each client's \emph{first visit}. Note that a client may pawn multiple items her first visit. We include these as separate observations. Because our standard errors are clustered at the branch-day level, they automatically account for any dependence in error terms arising from multiple pawns by the same client on her first visit.}.
Given perfect compliance in the former, the coefficients $\beta^F$ is the ATE of the Forced arm and $\beta^C$ is the ITT of the Choice arm on the outcome variable $y_{ij}$.
%\footnote{Note that $\beta^C$ can be viewed in two ways: as the the ATE of \emph{offering clients a choice} between the status quo and commitment contract or as the intent-to-treat effect of the commitment contract \emph{itself}. Here we adopt the former interpretation; below we use the latter to consider the relevance of selection-on-gains.}
Our two primary outcome variables are financial cost in pesos and Annual Percentage Rate (APR), as defined in Section \ref{costs}. 
Results for these outcomes appear in columns (1) and (6) of Table \ref{main_impact_table}.
The remaining columns decompose the financial cost and APR outcomes into their components: interest payments (col 2), payment towards any fees incurred (col 3), payments toward the principal (col 4). Column 5 shows the value of lost pawn conditional on losing it.  In column 6 the dependent variable is a dummy indicating default.  Finally, column 7 rescales financial cost as a function of loan size to estimate causal effects on incurred APR.\footnote{As we explained above, loans can be extended for an additional 3 months by paying the interest owed and restarting the loan under the same treatment conditions. This means that some loans extend for more than 3 months. We consider the entire flow of cost from the duration of our sample.}  





\paragraph{Results.} The results are stark. The Forced Commitment arm yields large and significant decreases in the cost of loans to clients, as measured either by financial cost or APR. Despite causing an increase in fees, the Forced arm leads to a decrease of 379 pesos in the costs of borrowing (out of a group mean of 1851 in the status quo), equivalent to 20\% reduction as a fraction of mean cost. These cost savings arise from a 6.5 percentage point (pp) decrease in the probability of default (out of a baseline mean of 44pp,  implying cost savings of 254 pesos), and also from lower interest payments, since as we will document the treatment is effective at speeding up payments, with the benefit that the interest rate applies to a smaller principal. This translates into a large reduction in APR. A credit product that has an effective average APR of 184\% in the status quo arm (inclusive of default) is reduced to a cost of 150\% through the imposition of a more regularized payment structure.  

In contrast, to the impressive effectiveness of the Forced commitment arm, the Choice arm fails to deliver significant changes in any measure, with the exception of an increase in fees, for which we are highly powered since this outcome is zero for every control observation. Giving borrowers the choice of contract did not decrease financial cost, whereas forcing them into a structured payment contract dramatically reduced it. As we explore later in the paper, the null effect of the Choice arm arises because few people had demand for it, with 89\% choosing the less effective status-quo contract.

\paragraph{Intermediate outcomes.} To shed light on the mechanisms behind the ATEs discussed above, Table \ref{mechanisms} shows how treatment affects a number of intermediate outcomes. One can group the types of intermediate outcomes into two categories: measures of the speed of pawn recovery, and measures of the decision of when to default. While the first payment for borrowers in the status-quo contract occurs on average only on day 82 (on a 90 days contract), borrowers in the forced commitment arm start paying 13.8 days earlier on average (col 1). Not only do they start paying earlier, the first payment is also 7.9\% larger (col 2), and a larger fraction of 7.9\% actually pay in full and recover their pawn in the first payment , compared to 30\% in the status quo contract (col 3). The resolution of the loan (either by payment or default) is shortened by 27.9 days (col 4), and conditional on recovery (an endogenous control) by 17.9 days (col 5).

A very undesirable outcome from the borrower's perspective is to pay towards the loan without paying in full, i.e. defaulting on the loan. In this case, they lose both the collateral and any payments made toward recovery. One could be concerned that by encouraging them to pay monthly, more borrowers could end up in this dire scenario in the Forced commitment contract. Column 6 shows this is not the case. On the contrary,  7 percentage points fewer borrowers end up in this situation, compared to 12 percent in the status quo contract. Conditional on defaulting those assigned to the Forced commitment contract have paid 3.9\% less of their loan (col 7), and 14 percentage higher proportion of borrowers pay zero conditional on defaulting, an outcome analogous to selling their pawn (col 8). One interpretation of these results is that the Forced commitment contract forces borrowers to think earlier about whether they will indeed be able to eventually recover their pawn, and separates borrowers into those ``selling'' their pawn and those recovering it, reducing the share of undecided borrowers that end up paying interest and end up losing the pawn anyway. This mechanism may also help to explain why the Forced commitment contract does not increase the number of visits to the branch to pay (col 10): those recovering their pawn visit more, but those defaulting have 0.19 fewer visits (col 11). Figure \ref{hist_payments} plots the histogram of the timing of payments in each arm, and shows that the commitment does appear to bind in that it generates a highly regular pattern of payments at 30, 60, and 90 days after the loan is taken. Finally, observe that Column 9 shows that treatment effects are concentrated in the intensive margin as treatment does not affect the fraction of clients who pay a positive amount towards pawn recovery.

\paragraph{Other costs.} We have shown that forcing borrowers to take the monthly payment contract significantly reduces financial cost. Although the paper focuses on financial cost, we consider three additional costs here. First, we include the cost of going to the branch. This includes the self-reported transport cost (most use public transport), as well as the opportunity cost of time. To err on the conservative side, we subtract a whole day's minimum wage the day of the visit, instead of just the wage corresponding to a couple of hours. Second, we consider a rough proxy of the value of liquidity they lose by paying earlier. To do this we add the interest costs on to the payments in the Forcing and recompute treatment effects with these payments compounding daily (as if they had to borrow in order to make the more rapid payments). Thirdly, so far we have valued the collateral at the gold value appraised by the lender, but the piece may be worth more to the borrower than its gold value.  For many of them the pawned jewelry has sentimental value. This is reflected in the subjective valuation they reported in the survey which is 87\% higher on average. Our third extra cost considers this higher value.

Table \ref{table_robustness_fc} shows results. Panel A reports financial cost in pesos, while Panel B shows APR. Columns (1) and (6) replicate our previous results for comparability. Columns (2) and (7) of Table \ref{table_robustness_fc} use the subjective value of the pawn reported by the borrower rather than its appraised value. Columns (3) and (8) adjust for self-reported transport costs per visit plus an entire day's wage, both multiplied by the number of visits that each individual made.\footnote{For clients who did not complete the individual survey, we adjust using the mean self-reported transport cost among respondents of the respective branch.} Columns (4) and (9) adjust to consider the liquidity cost. Finally columns (5) and (10) include all three changes together. The main takeaway from the table is that results are quite robust to including a much expanded measure of costs. 


%Although adding a whole day's wage almost certainly exaggerates the travel costs associated with commitment contracts, we still find that forced commitment reduces both financial costs and APR. Columns (4) and (9) adjust for both travel costs and use the subjective rather than appraised value of the pawn. Finally, columns (5) and (10) remove saved interest payments from the calculation of the benefits. The rationale is that forcing borrowers to pay earlier reduces their liquidity, and they may need to borrow. We assume they borrow at the same interest rate. Thus considering other loans, they may not be paying less interest. The exercises in Table \ref{table_robustness_fc} show that results are quite robust to the inclusion and exclusion of components of benefits and costs.

%Figure \label{fc_discount_rates} shows the effects of each of these adjustments on the estimate of financial cost and APR, and illustrates that even when we make all of these adjustment simultaneously the Forced arm generates benefits of 0.11 standard deviations, significant at the 95\% level.  Forced commitment lowers financial costs even when we incorporate multiple subjective dimensions of the loan.    



\paragraph{Repeat Pawns.}
%Another way to push the analysis towards a consideration of borrower welfare is the conjecture that if clients exposed to the installment contract like it, they will be more likely to come back vis-a-vis those that got status quo contract.\footnote{\cite{Laibson2018} hypothesizes that consumers use ``experienced utility'' as a guide to make future purchases in this way.} This is indeed what we find in the data.  We consider this outcome in Table \ref{repeat_loans}. We can first ask whether the individual ever takes a loan after the initial study loan, an analysis which is simply experimental.  
Table \ref{repeat_loans} explores the effects of treatment on future pawning behavior.
Column (1) shows that participants assigned to the the forced arm are 6.7\% more likely to be repeat clients later. %Those in the choice arm are 4\% more likely to pawn again and is not statistically distinct from zero. 
While this appears to be \emph{prima facie} evidence of greater satisfaction among borrowers in the forced arm, the interpretation is complicated by the fact that monthly payments may themselves trigger more borrowing to pay them. This is unlikely to be the case given that the effect on re-pawning comes after 90 days (during the period of contract demanded payments) and not before  (see columns 2 and 3). Column 4 only considers new loans which use different collateral from that of the initial one. We do this to foreclose the explanation that those in the Forced arm repeat more because they are more likely to have collateral, as they recover the collateral of the first loan more often.  Column 5 focuses on the (endogenous) subsample of those recovering their pawn in both arms of the experiment. This means that both have the pawn to re-pawn and also that the liquidity demands from the monthly contract are not longer binding as the contract has been closed. We find that the difference between the Forcing contract and the status quo is even larger in this subsample, with the former having 11pp higher likelihood of being a repeat client during our sample period.

%clients assigned to the forced commitment arm were more likely to recover their pawn, allowing them to re-pawn the same item in the future.  We can explore this possibility in a number of ways.   First, we can (endogenously) split the sample according to whether the individual defaulted on the experimental loan; here we find that the increase in subsequent borrowing is restricted to those who repaid the first one.   Next, we can examine whether the probability that participants take another loan using \emph{different} collateral from the first. While the difference is not statistically significant, we find that the Forced arm elevates the probability of re-pawning with new collateral.   We can also separately examine the probability of taking a new loan after the contract period of the original experimental loan (column 5) or before it (column 6). Here we find that the increase in subsequent pawning comes \emph{later}, significantly increasing the time to the subsequent loan (column 7). All of this evidence suggests that the effect on subsequent demand is `real' and not an artifact of improved retention of the collateral, consistent with \cite{Alcohol}'s conjecture that demand for commitment increases with experience with it. However, it remains possible that the additional demand for subsequent pawning comes from the fact that forcing earlier payments effectively reduces the credit available during the contract, and thus that clients may pawn again to compensate for the smaller loan. We are skeptical about this interpretation for several reasons. %First, typically the emergencies that trigger a pawn are short lived (e.g. needing to go to the hospital), and it is unclear why clients in the frequent payment arm wait for several months to re-pawn -- there is no effect of the monthly payment contract on repeat pawning in the first 30 or 60 days of the contract, (see Figure \ref{reincidence_before} in Appendix). First,  there are many alternative lenders in this market, and if they did not like frequent payments why do they come back to Lender $P$ for another loan? Second, the fee itself is mostly symbolic (2\% of 1/3 of the value of the loan) and so it is likely that if there were real financial costs to making an intermediate payment it would simply be skipped and the fee incurred.  We also implemented an exit survey which clients filled when recovering their piece. Unfortunately it had low response rate (7\%), and we take its results with a grain of salt; however in this survey 63\% of clients said they liked the frequent payment contract more than the status-quo one, and that it allowed them to avoid unnecessary expenses. Finally and most importantly, the treatment effects on re-pawning are entirely confined to the period after the original loan term and so there is no obvious link between intermediate liquidity and demand for new credit.  
%Third, we find larger effects of repeat buying for clients that experienced larger treatment effects, which the alternative explanation cannot explain. Fourth, the effect is present if we condition on clients that recovered their pawn (so it's not driven by pawn recovery). Finally, we were able to obtain observational data for all Lender $P$'s branches for the period January 2016 to May 2020, during which Lender $P$ expanded the new frequent payment contract. Using an instrumental variable strategy that exploits the expansion and availability of the frequent payment contract across branches, we show that being exposed to the frequent payment contract leads to an increase of 50 percentage points in the likelihood that in the subsequent pawn the frequent payment contract is chosen when both the status-quo one and the frequent payment contract are available (see \ref{appendix_b}). This choice cannot be explained by the need of another loan, since it is about \textit{which specific type} of loan the clients chooses conditional on getting one.

%An additional empirical issue generated by repeat pawning is the question of how to handle the treatment status of those who take multiple loans within the experiment.  38\% of borrowers take more than one loan within the study period, and 19\% are assigned multiple treatment statuses on their different loans.  The issue of sequential endogenous treatments has been extensively studied in the context of school lotteries, where the convention is to use the treatment status from the first exposure \citep{cullen2006effect, abdulkadirouglu2011accountability}.\footnote{That context provides a particularly severe version of the endogenous re-entry problem because only the losers from initial lotteries re-enter subsequent ones.  Our selection problem is less draconian, but still potentially relevant since we do find treatment effects on pace of repayment and of pawning again.}  While our main impact tables simply use the assigned treatment status for every loan, in Table \ref{multiple_loans} we provide two straightforward robustness checks for the influence of this problem.  Columns 1-2 repeat the main analysis of financial cost and APR using the baseline approach from our main results, including dummies for the order of pawns for an individual, essentially making the identification within-order.  Columns 3-4 drop all loans other than the first, and Columns 5-6 pursue the ITT strategy of always assigning the first treatment status to all subsequent pawns. The core treatment effects are robust to any of these ways of handling repeat pawning, and the effect on the APR is actually larger when we consider first loans only.  Hence endogenous re-entry to the experiment does not appear to be driving our results.   




\paragraph{Censoring of Loan Completion}
The window of time during which we were able to observe borrower behavior was limited in each branch, meaning that there were loans that we do not see completed (particularly those pawns that were rolled over for one or two further 90-day spells).  Overall, 13\% of all experimental loans are censored, meaning that they neither default nor repay within the observation window.  In the prior analysis we handle this issue by using outcomes such as `did not default' which are defined even when we do not observe the completion of the loan, and only considering costs that we observe directly.  We have also showed, however, that one effect of the forcing arm is to accelerate repayment, meaning that it is less likely for loans in this arm to be censored.  This issue is illustrated in Figure \ref{survival_graph}, which shows the CDF of loan completion (either default or recovery in Panel (a)) and loan recovery (Panel (b)) by the number of days since first pawn.  Two features of these graphs are salient for our analysis.  The first is the extent to which loan outcomes are observed more quickly in the forcing arm.  This is primarily due to the the substantially higher rate of repayment of Forced Commitment loans at 120 days (15 pp higher than the other arms).  The second is the very low rate at which loans are recovered in any arm after 120 days.  In the 180 day window after the second rollover period we see a further 10 percent of loans repaid in all arms, but these loans are largely dormant, suggesting that many of the censored loans will in fact be defaulted upon.

The confluence of censoring and a treatment effect on censoring is problematic from an experimental point of view.  The approach taken so far is a conservative one in that it inherently assumes that all of the loans outstanding at the end of the observation window will be repaid, making it so that the acceleration of payment observed in the Forced arm does not translate mechanically into the treatments decreasing default.  Given the centrality of this issue to the observed costs, we now delve into it more detail.  One way of considering the effect that this issue could have on our results is to make extreme assumptions about the outcome of these loans in the treatment and control so as to bound the possible influence of censoring.  In Table \ref{bounding_censoring} we compare the Forced and Control arms, making the bracketing assumptions about repayment on censored loans.  Panel A assumes all censored loans are repaid, and Panel D that all default.  Panel B provides the lower bound for the treatment effect by assuming censored control loans are always repaid and treatment loans never are, and Panel C the upper bound by making the reverse assumption.  Comfortingly, even with these extreme assumptions the significance on the main treatment effects never flips and treatment effects on financial cost and interests payments remain negative and significant in all scenarios.  So there appears to be no scope for the censoring issue to overturn our main results. 

Finally, Panel E of this table conducts a logit prediction model that uses all of the available information on loans that were completed to predict the outcome of loans that were not.  This is a best guess of the outcome on censored loans.  Using this prediction, we replicate the main experimental results and find that the treatment effect on financial cost increases from -378 (main results) to -525 (censored loans predicted), and the APR from -34\% to -62\%.  Hence, while the censoring issue does have a substantial influence on the magnitude of our estimated treatment effects, these  checks confirm that a) the core results are robust to censoring, and b) the headline approach that we take to the issue is conservative and is likely understating the true magnitude of impacts.





\section{Choice and Heterogeneous Treatment Effects}
\label{Choice}

The results from Section \ref{Experiment} show that commitment \emph{works}: clients who were assigned to the forced commitment arm experienced substantially lower financial costs on average.
In spite of this, given the opportunity, only 11\% of borrowers chose commitment. 
If the effect of commitment were homogeneous, this would be enough to conclude that the 89\% who did not choose it would have been financially better-off if they had.
In a world of heterogeneous treatment effects, however, low demand for commitment could still be consistent with borrowers adhering to a standard model of rational choice. 
The borrowers who did not choose commitment could simply be those who don't need it. 
Indeed, we find strong evidence that the effect of forced commitment varies substantially across individuals in our experiment: \ref{append:chernozhukov} tests and rejects the null hypothesis of homogeneous treatment effects, following the methodology of \cite{chernozhukov2018generic}.
So the question remains: do the 89\% who do not choose commitment know something about their personal situations that we as researchers do not, or are most people in the choice arm making a costly mistake? 
In this section we present of econometric exercises that shed light on this question, leveraging unique features of our experimental design. 
Among other results, we show that commitment lowers average financial costs even for the subset of borrowers who would \emph{not} choose to commit voluntarily.
To simplify the exposition in this and all sections that follow, we re-define all outcome variables so that \emph{beneficial} treatment effects are \emph{positive}. Using this convention, a positive treatment effect of commitment on financial cost, for example, reflects the average cost \emph{savings} caused by commitment.

\subsection{Bounding the Distribution of Individual Treatment Effects}
\label{sec:bounds}
If we knew the distribution of individual treatment effects, it would be easy assess how many individuals would win and lose under a policy of universal forced commitment, along with the magnitude of any individual harm. 
Because we can never simultaneously observe the same borrower in both the control and commitment arms, however, the distribution of individual treatment effects cannot be point identified.
It can, however, be bounded.
We begin our exploration of heterogeneous treatment effects by computing assumption-free bounds on the share of individuals who benefit from forced commitment. 

Let $Y_{i0}$ be borrower $i$'s potential outcome under the control condition, $Y_{i1}$ be her potential outcome under forced commitment, and $\Delta_i \equiv Y_{i0} - Y_{i1}$.
Because it randomly assigns borrowers to the control and forced arms, our experimental design point identifies the marginal distributions of $Y_{i0}$ and $Y_{i1}$, call them $F_0$ and $F_1$.
Now, define the functions $\underline{F}$ and $\overline{F}$ as follows:
\[
\underline{F}(\delta) \equiv \max \left\{0, \sup_y F_1(y) - F_0(y - \delta)  \right\}, \quad
\overline{F}(\delta) \equiv 1 + \min \left\{0, \inf_y F_1(y) - F_0(y-\delta) \right\}.
\]
Since $F_0$ and $F_1$ are point identified, so are $\underline{F}$ and $\overline{F}$.
\cite{fan2010sharp} show that the sharp (best possible) pointwise bounds for $F_\Delta$ are given by $\underline{F}(\delta) \leq F_\Delta(\delta) \leq \overline{F}(\delta)$.
These bounds are simple to compute, and can be surprisingly informative. 
Here we use them to bound the fraction of borrowers who benefit from forced commitment. 
Given the way that we have defined our outcome variables, this is the share of borrowers whose treatment effect is positive, i.e.\ $\mathbb{P}(\Delta_i > 0) = 1 - F_\Delta(0)$. 
To construct the sharp bounds for this quantity, we simply substitute $\delta = 0$ into the preceding equations and estimate $F_0$ and $F_1$ using their empirical analogues constructed from the forced commitment and forced no-commitment arms of the experiment.

Figure \ref{fan_park_bounds} plots the sharp bounds for $F_{\delta}$ based on the APR outcome defined above in Section \ref{costs}. Our point estimates of $\underline{F}(0)$ and $\overline{F}_0$ are .03 and .76 respectively, with associated 95\% confidence intervals of [0.027, 0.040] and [0.73, 0.78], which says that at least 24\% of individual borrowers benefit from commitment (and at most 97\%).\footnote{Confidence intervals are constructed using the asymptotic distribution for the bounds. See \cite{fan2010sharp} for details.}

The bounds we have just described are constructed by considering all possible joint distributions of $Y_0$ and $Y_1$ that are compatible with the observed marginal distributions $F_1$ and $F_0$. 
With stronger assumptions, it is possible to say more.
One such assumption is \emph{rank invariance}, which posits that a person's rank in the distribution of $Y_0$ equals her rank in the distribution of $Y_1$.
While strong, this assumption or variants of it has appeared in a number of settings in the literature, e.g.\ \cite{chernozhukov2005iv}. 
Under rank invariance, the distribution of treatment effects is point identified and given by 
\[
F_\Delta(\delta) = \int_0^1 \mathbbm{1}\{ F_1^{-1}(u) - F_0^{-1}(u)\leq \delta\}\,\mathrm{d}u 
\]
where $F_1^{-1}$ and $F_0^{-1}$ are the quantile functions of $Y_1$ and $Y_0$. See figure \ref{te_rankinvariance} in Appendix \ref{App_FOSD}.
As we show in Appendix \ref{App_FOSD}, $Y_1$ first-order stochastically dominates $Y_0$ in our experiment: every quantile of the distribution of financial cost savings under forced commitment is higher than the corresponding quantile under the control condition, and the same is true for the APR outcome.
Since this implies that $F^{-1}_1(u) - F^{-1}_0(u)$ is always positive, rank invariance yields an extremely stark conclusion: all borrowers benefit from forced commitment. 
%\todo[inline]{@Everyone: do we want to plot the distribution of treatment effects under rank invariance and say something more about it? Or just add a snappy sentence to conclude this subsection?}



%An alternative way of presenting the \cite{fan2010sharp} bounds is in terms of quantiles of the distribution of $\Delta$. Let $0 < q < 1$, and define $Q_0, Q_1, Q$ to be the quantile functions corresponding to $F_0, F_1$ and $F_\Delta$.\footnote{In other words, $Q_0(q) \equiv \inf \{x | F(x) \geq q\}$ and so on.} Then the sharp bound for $Q_\Delta(q)$ is given by $\underline{Q}(q) \leq Q(q) \leq \overline{Q}(q)$ where
%\[
%\overline{Q}(q) \equiv \inf_{u \in [q,1]} [Q_1(u) - Q_0(u - q)], \quad
%\underline{Q}(q) \equiv \sup_{u\in [0,q]} [Q_1(u) - Q_0(1 + u - q)]
%\]
%By substituting $q = 0.11$, these expressions allow us to bound the 11th percentile of the distribution of $\Delta$. Under a stylized Roy model in which borrowers with the largest (negative) treatment effects choose commitment, $Q(0.11)$ equals the treatment effect for the borrower at the margin of indifference between choosing commitment. 
%Our point estimates for the lower and upper bounds $\underline{Q}(0.11)$ and $\overline{Q}(0.11)$ are \hl{XXXX} and \hl{XXXX} with corresponding 95\% confidence intervals \hl{XXXX} and \hl{XXXX}.\footnote{Again, confidence intervals are constructed using \hl{XXXX} bootstrap as describe in \cite{fan2010sharp}.}
%%\todo[inline]{Issac: add the interval for $Q(0.11)$. Again, this needs to be without covariates and we need to be careful about the sign convention for our effects. Maybe we don't need a second figure with the confidence bands for the whole quantile function. Frank: add a sentence or two discussing the results. Presumably the aforementioned quantile is indeed negative and fairly large.}
%Both ways of presenting the bounds yield the same conclusion: at least some borrowers who would benefit from commitment \emph{do not choose it} when offered. 


\subsection{Potential Outcomes and Exclusion}
\label{sec:potentialOutcomes}

Our assumption-free bounds from the preceding section show that more than 24\% of borrowers would benefit from a policy of forced commitment. 
Intuitively, this seems to suggest that some of the 89\% of borrowers in the choice arm who did \emph{not} choose commitment would have faced lower borrowing costs if they had.
Making this intuition precise, however, requires a careful consideration of the relationship between choice and heterogeneous treatment effects. 
To this end, we now provide a full definition of the potential outcomes in our empirical setting, and introduce a pair of assumptions that will allow us to go beyond the assumption-free bounds from above.

Let $Z_i \in \{0, 1, 2\}$ denote the treatment arm to which to participant $i$ was assigned: $Z_i = 0$ denotes the forced no-commitment arm, $Z_i = 1$ denotes the forced commitment arm, and $Z_i = 2$ denotes the choice arm. 
Now let $D_i$ be the treatment that participant $i$ actually \emph{received}, where $D_i = 0$ denotes no-commitment and $D_i = 1$ denotes commitment. 
We assume perfect compliance in the $Z_i = 0$ and $Z_i = 1$ arms.\footnote{For more discussion on this point, see Section \ref{sec:integrity} above.}
It is only in the $Z_i = 2$ arm that participants are free to choose between alternative contracts. 
Let $C_i \in \{0, 1 \}$ denote a participant's ``choice type.'' If $C_i = 1$ then participant $i$ \emph{would choose commitment}, given the option; if $C_i = 0$ she would not. 
As shorthand, we call borrowers with $C_i = 1$ ``choosers'' and those with $C_i = 0$ ``non-choosers.''
Whereas a participant's choice type $C_i$ is only observed if she is allocated to the choice arm ($Z_i = 2$), her treatment $D_i$ and experimental arm $Z_i$ are always observed. 
Given the design of our experiment, these quantities are related by
\begin{equation}
D_i = \mathbbm{1}(Z_i \neq 2) Z_i + \mathbbm{1}(Z_i = 2) C_i.
\label{eq:potentialTreatments}
\end{equation}

We maintain the stable unit treatment value assumption (SUTVA) throughout. 
This means that borrower $i$'s outcomes depend only on her \emph{own} values of $Z_i$ and $D_i$, not those of any other person in the experiment. 
Under this assumption, a fully general model for the potential outcomes in our experiment would take the form $Y_i(d, z)$ for $d\in \{0,1\}$ and $z \in \{0, 1, 2\}$, allowing participant $i$'s potential outcome to depend \emph{both} on the treatment she actually receives, $D_i$, and the experimental arm to which she is assigned, $Z_i$. 
This model is too general, however, to point identify meaningful causal effects. 
For this reason, we consider two exclusion restrictions.

Before stating these restrictions, we first define some additional notation.
Because our experimental design implies that any borrower with with $Z_i = 0$ has $D_i = 0$, we abbreviate the potential outcome $Y_i(d=0,z=0)$ as $Y_{i0}$. 
Similarly, since any borrower with $Z_i = 1$ has $D_i = 1$, we abbreviate $Y_i(d=1,z=1)$ as $Y_{i1}$. 
This is in keeping with our notation from section \ref{sec:bounds} above.
Using this notation, our first exclusion restriction is given by
\begin{equation}
Y_i(d=0,z=2) = Y_i(d=0,z=0) \equiv Y_{i0}.
\label{eq:exclusion0}
\end{equation}
Equation \ref{eq:exclusion0} only restricts the potential outcomes of non-choosers,  individuals with $C_i = 0$, because they are the only borrowers for whom $D_i = 0$ when $Z_i = 2$.
In words, this condition assumes that every non-chooser experiences the same potential outcome regardless of whether she is assigned to the choice arm or the control arm.
Similarly, our second exclusion restriction is given by
\begin{equation}
Y_i(d=1,z=2) = Y_i(d=1,z=1)\equiv Y_{i1}.
\label{eq:exclusion1}
\end{equation}
Equation \ref{eq:exclusion1} only restricts the potential outcomes of choosers, individuals with $C_i =1$, because they are the only borrowers for whom $D_i = 1$ when $Z_i = 2$.
In words, this condition assumes that every chooser experiences the same potential outcome regardless of whether she is assigned to the treatment arm or the choice arm.

Mathematically \eqref{eq:exclusion0} and \eqref{eq:exclusion1} have the same structure as the standard LATE exclusion restriction that $Y_i(d,z)$ depends only on $d$, not on $z$. 
Substantively, however, they are slightly different, given that there is no explicit reference to the ``chosen'' versus ``forced'' treatment distinction in the usual LATE setup.\footnote{For related discussion, see \cite{chamberlain2011bayesian} who uses an assumption similar to our exclusion restrictions to develop a theory of optimal treatment choice for an individual who has access to data from an RCT.} 
In essence, \eqref{eq:exclusion0} and \eqref{eq:exclusion1} assume that being assigned a particular treatment has the same result as choosing it for yourself, provided that you are assigned the same treatment that you \emph{would have chosen}. 
If the mere fact of having been given a choice has a direct effect on outcomes, one or both of our exclusion restrictions will be violated.
One can imagine situations in which this might be the case.
For example, even someone who would have voluntarily chosen to undergo drug rehabilitation, given the choice, might respond differently when coerced.
In our empirical setting, however, both \eqref{eq:exclusion0} and \eqref{eq:exclusion1} are plausible. 
Moreover, each has testable implications that we fail to reject.
For details, see \ref{append:exclusion}
%\todo[inline]{@Frank, do we need to say a bit more about these testable implications or is it too technical? (Enrique)}

Under the exclusion restrictions from \eqref{eq:exclusion0} and \eqref{eq:exclusion1}, each participant's observed outcome $Y_i$ is related to her potential outcomes $(Y_{i0}, Y_{i1})$ according to  
\begin{equation}
    Y_i = \mathbbm{1}(Z_i =0) Y_{i0} + \mathbbm{1}(Z_i = 1)  Y_{i1}  + \mathbbm{1}(Z_i = 2) \left[(1 - C_i) Y_{i0} + C_i Y_{i1} \right].
\label{eq:potentialOutcomes}
\end{equation}
Equation \ref{eq:potentialOutcomes} is the key to understanding the results that follows. 
As noted above, by randomly assigning $Z_i=0$ and $Z_i = 1$ our experiment identifies the marginal distributions of $Y_{i0}$ and $Y_{i1}$ in the population as a whole. 
By randomly assigning $Z_i=2$, it likewise point identifies the share of choosers ($C_i = 1$), the distribution of $Y_{i1}$ for choosers, and the distribution of $Y_{i0}$ for non-choosers ($C_i = 0$).
Because $Z_i$ is assigned independently of pre-treatment covariates $X_i$, our design also identifies the corresponding \emph{conditional} distributions of $Y_{i0}$ and $Y_{i1}$ given $X_i$. 
%These distributions are the ingredients that we use below to explore the importance of paternalism. 


%The fact that the Forced Commitment contract lowers financial costs for almost all clients, together with the fact that only 11\% choose it must mean that many consumers are choosing contracts with higher financial costs for themselves. We now use several different techniques to shed further light on the idea that the `wrong' people are choosing commitment.  

%Our core impacts show that forced commitment is uniquely effective, a result that can only arise if those who would not have freely chosen commitment benefit from it.  We now delve more deeply into this result.

%\subsection{Treatment Effect Heterogeneity}



%Defenders of choice make another subtler point: that even if take up of the commitment-fee contract is low, the sole fact of \textit{having} choice could potentially change behavior or welfare (\cite{Dalboetal:2010}, \cite{Sjostrometal:2018}, \cite{Tlaxcala}).

%In spite of broadly distributed benefits of the Forced Commitment commitment contract we documented above, 90\% of clients chose \textit{not} to have it, preferring the status-quo contract. As explained above we are fairly confident this was not because a lack of understanding of the contracts. 

%\vspace{.1in}
%\noindent What can explain this low demand? In the spirit of \cite{Blumenstock} we try to differentiate between explanations. One explanation could be risk. Even if the fee forcing contract generates cost savings on average, clients with risk averse preferences may not demand it if they perceive higher risk from it.   Alternatively, even risk-neutral agents may not demand it if the cost of lost flexibility is high or if they have high temporal discount rates and prefer to pay later. %If clients, for instance, face large and frequent income shocks which make it hard to repay monthly.\footnote{We don't observe income shocks in our data, making is hard to quantify how important they are. 91\% of those in the Forced Commitment arm incurred a fee, which suggests that shocks are not uncommon.} 
%Although the evidence that follows undermines several explanations, the tests we can conduct given the data are not sharp enough to leave a single explanation standing. Section \ref{model} lays our a simple theory (namely present bias with partial naivete) which fits all the 6 main findings of the paper. Given its parsimony and explanatory power, we submit that it is the most suitable explanation for our results.


%Following two  paragraphs moved from old 'behavioral' choice section towards end of paper
%\vspace{.2in}
%\subsection{The effect of choice on pawn recovery and financial cost} \label{effect_choice}



%Figure \ref{main_te} represents the  effect sizes (in standard deviations) of the two main study arms for three outcomes:  default, the financial cost of the loan, and the effective interest rate paid to acquire the borrowed capital.  The Forced arm is significant for all three outcomes, with very substantial treatment effects in magnitudes for default and APR, and the commitment arm is never significant.\footnote{The slight increase in APR for the Choice arm seen in this picture arises from the fact that the APR calculation has the arm-specific loan size in the denominator, and the loans in the Choice arm turn out to be slightly smaller (although statistically equal) on average than the Control.}    In other words, voluntary commitment is ineffective but the use of forced commitment saves the average borrower an amount of money almost twice the APR of a normal US credit card loan.  



%Although we have shown that Forced Commitment reduces financial cost and increases pawn recovery, this does not imply that welfare increases. Clients could have disutility from the stress of having monthly installments for instance. 
%We don't need to make the strong claim of welfare for the purposes of this paper. The financing cost results are striking enough. But we 


%The panel labeled Forced Commitment in Figure \ref{reincidence} presents results of estimating equation (\ref{basic_reg}) with the dependent variable being a dummy for the client being a repeat customer. We define a client as a repeat customer if, after experiencing at least 75 days of the respective treatment arm, she came back and pawned a \textit{different} piece.\footnote{Results are robust to using number of days experiencing the contract larger than 75. We know it is a different piece from it having a different weight/value.}  The leftmost coefficient shows that the causal effect of the Forced Commitment contract on repeat pawning is an increase of 5 percentage points in the probability of being a repeat customer, this is twice the repeat purchasing happening in the status quo group. This effect is not explained by clients recovering their first pawn with higher probability in the Forced Commitment contract and re-pawning this same one since we make sure it is another piece; besides only 16\% recover their piece in the fist 75 days in the fee forcing contract. Experience with the frequent payment contract seems to be necessary as there is no effect of the monthly payment contract on repeat pawning in the first 30 or 60 days of the contract (see Figure \ref{reincidence_before} in the Appendix).

%\hl{The second coefficient from the left focuses on the subsample who are predicted would have a treatment effect on financial cost savings above the median} treatment effect in their first pawn.\footnote{Since this is predicted using \cite{atheygrf} based on pre-determined covariates for treatment and control clients it is valid to split the sample this way.} It shows that for these clients the likelihood of coming back is twice as large. That is, those that benefit more from the Forced Commitment contract are more likely to repeat compare to their control group. The remaining coefficients of the ``Forced Commitment'' panel condition on endogenous outcomes and should be interpreted with care. The \hl{third} coefficient from the left restricts the sample to those that had not recovered their pawn in the first 75 days in both groups and finds similar results. The \hl{fourth} coefficient conditions on clients who recovered their pawn of the experiment, again on in both arms. Results from these two endogenous samples are similar to those for the whole sample.

%The fourth coefficient \footnote{The second and third estimate must be interpreted with care as we are conditioning on a variable that may be affected by treatment. We view these 2 coefficients as suggestive correlations only. The fourth coefficient does not have that problem as it conditions on clients that by their pre-determined covariates are predicted to have above the median treatment effects (in both arms).} 

%The coefficient on repeat pawning is just as big when we focus only 2nd pawns happening after the first was recovered (third coefficient ``fnr'').  This is consistent with \cite{Laibson2018}'s conjecture that clients could be making decisions based on experienced utility.\footnote{The third coefficient conditions on the subsample that did recover their first pawn in both arms and finds a coefficient of 4pp. This is not a causal estimate as recovery is influenced by treatment, but we found it telling that the differences were similar to the causal estimate for the full sample.}


\subsection{The ``Controlled Choice'' Design}
\label{sec:randchoice}

%Above we used outcome data from the forced arms ($Z_i\neq 2$) along with the commitment take-up rate in the choice arm ($Z_i = 2$) to argue that at least some of the \hl{89\%} of participants who did \emph{not} choose commitment would have been better off if they had. 
%By additionally examining \emph{outcome data} in the choice arm, it is possible to say more. 
We now show how our experimental design, henceforth the ``controlled choice design,'' combined with the exclusion restrictions from \eqref{eq:exclusion0} and \eqref{eq:exclusion1} can be used to point identify a number of interesting and economically-relevant causal quantities without the need for additional structural restrictions.
First we identify the treatment on the treated (TOT) and treatment on the untreated (TUT) effects, defined as follows:
\[
\text{TOT} \equiv \mathbbm{E}(Y_{i1} - Y_{i0} | C_i = 1), \quad
\text{TUT} \equiv \mathbbm{E}(Y_{i1} - Y_{i0} | C_i = 0).
\]
%The TuT and TOT effects are particularly interesting for understanding the importance of paternalism. 
If the TUT is positive, this means that those who did not choose commitment would have experienced better outcomes, \emph{on average}, if they had. 
In a canonical Roy model, the TOT should exceed both the TUT and average treatment effect (ATE).
If the TOT is statistically distinguishable from and substantially larger than the TUT, this provides empirical support for the relevance of selection-on-gains in real-world decision-making.
Because our design identifies all three quantities (as shown in Appendix \ref{append:randchoice}), it allows us to test this implication directly and to calculate the average selection on gains (ASG):
\[
\text{ASG} \equiv \mathbbm{E}[Y_{i1} - Y_{i0}|C_i = 1] - \mathbb{E}[Y_{i1} - Y_{i0} | C_i = 0] = \text{TOT} - \text{TUT}.
\]
The controlled choice design also identifies both the average selection bias (ASB) and the average selection on levels (ASL). 
\[
\text{ASB} \equiv \mathbbm{E}[Y_{i0}|C_i = 1] - \mathbbm{E}[Y_{i0}|C_i = 0], \quad 
\text{ASL} \equiv \mathbbm{E}[Y_{i1}|C_i = 1] - \mathbbm{E}[Y_{i1}|C_i = 0].
\]
A companion STATA package accompanying this paper provides estimators of the TOT, TUT, ASG, ASB, and ASL, along with cluster-robust standard errors for each, and a test for the validity of the exclusion restriction following \cite{huber_mellace} \footnote{See Appendix \ref{append:randchoice} for more details.}.

A number of recent papers compare estimates of the TOT and TUT to better understand who selects into treatment and why, e.g.\ \cite{cornelissen2018benefits} and \cite{Walters}. 
This line of work relies, at least to some extent, upon structural modeling assumptions to extrapolate from the reduced-form quantities that are identified by the data alone to more interesting, and economically relevant, causal parameters.\footnote{While the marginal treatment effects (MTE) approach \citep{heckman2007econometric} can in principle be used to identify the TOT and TUT without parametric restrictions, doing so requires an instrumental variable $Z$ with sufficiently rich support that the probability of treatment take-up given $Z$ varies continuously between zero and one. In practice, instrumental variables are usually discrete and, even when continuous, typically have a more modest effect on take-up.} 
An alternative approach aims to avoid structural assumptions by calculating conditional local average treatment effects (LATE) given observed covariates $X$ and re-weighting them according to the distribution of covariates in some population of interest to yield, for example, an average treatment effect \citep{aronow2013beyond,angrist2013extrapolate}. 
%For example, one might re-weight using the distribution of $X$ in the population as a whole, rather than the sub-population of compliers, to extrapolate from LATE to ATE. 
But there is no free lunch: this ``LATE-and-reweight'' approach relies upon assumptions of its own, most crucially the assumption that there is \emph{no selection-on-gains} conditional on $X$, i.e.\ that the conditional LATE equals the conditional ATE. 
In contrast to both approaches, the controlled choice design uses exogenous experimental variation to point identify the ATE, TOT, and TUT without ruling out unobserved selection-on-gains or relying on additional structural modeling assumptions.
Figure \ref{tot_tut_graph} provides graphical intuition for our identification approach; derivations appear in \ref{append:randchoice}

The key insight can be read directly from \eqref{eq:potentialTreatments} and \eqref{eq:potentialOutcomes}. 
Viewing $Z_i$ as an instrumental variable, the controlled choice design can be interpreted as a \emph{pair} of RCTs, each subject to one-sided non-compliance.
The first of these compares $Z_i=0$ to $Z_i = 2$. For each individual with $Z_i = 0$ we have $D_i = 0$ and observe $Y_{i0}$. For those with $Z_i = 2$ we have $D_i = C_i$ and observe $(1 - C_i) Y_{i0} + C_i Y_{i1}$. This is identical to a ``randomized encouragement'' design in which treatment is only available to those who are encouraged: $Z_i = 2$. Under this interpretation, those with $C_i = 1$ are ``the compliers'' and it follows that 
\begin{equation}
\frac{\mathbbm{E}(Y_i|Z_i=2) - \mathbbm{E}(Y_i|Z_i =0)}{\mathbbm{E}(D_i|Z_i=2)-\mathbbm{E}(D_i|Z_i=0)} = 
\frac{\mathbbm{E}(Y_i|Z_i=2) - \mathbbm{E}(Y_i|Z_i =0)}{\mathbbm{E}(D_i|Z_i=2)} = \mathbbm{E}(Y_{i1} - Y_{i0}|C_i = 1)
\label{eq:TOT}
\end{equation}
since $\mathbbm{E}(D_i|Z_i=0)=0$ by \eqref{eq:potentialTreatments}. 
A closely related argument can be used to construct a Wald estimand that identifies the TUT. Here we consider $Z_i = 1$ to be the ``encouragement'' and compare the outcomes for these individuals to those with $Z_i = 2$. If $Z_i = 1$ then $D_i = 1$ and we observe $Y_{i1}$.
If instead $Z_i = 2$ then $D_i = C_i$ and we observe $(1 - C_i) Y_{i0} + C_i Y_{i1}$. Again, we can view this as an experiment with one-sided non-compliance, but now the situation is reversed. Everyone with $Z_i = 1$ is treated, but some people with $Z_i = 2$ are ``always-takers'' who obtain the treatment ($D_i = 1$) despite having been allocated to the ``control'' arm $Z_i=2$. Under this interpretation, the ``compliers'' are those with $C_i = 0$: when $Z_i=1$ they take the treatment, and when $Z_i=2$, they do not. Thus, 
\begin{equation}
\frac{\mathbbm{E}(Y_i|Z_i=1) - \mathbbm{E}(Y_i|Z_i =2)}{\mathbbm{E}(D_i|Z_i=1)-\mathbbm{E}(D_i|Z_i=2)} = 
\frac{\mathbbm{E}(Y_i|Z_i=1) - \mathbbm{E}(Y_i|Z_i =2)}{1 - \mathbbm{E}(D_i|Z_i=2)} = \mathbbm{E}(Y_{i1} - Y_{i0} | C_i = 0)
\label{eq:TUT}
\end{equation}
since $\mathbbm{E}(D_i|Z_i = 1)= 1$ by \eqref{eq:potentialTreatments}. Equations \eqref{eq:TOT} and \eqref{eq:TUT} are useful for understanding why the controlled choice design identifies the TOT and TUT, but they are less convenient for estimation and inference. 
In \ref{append:randchoice}, we show that
\begin{align}
\label{eq:TOTreg}
Y_i &= \mathbbm{E}(Y_{i0}) + (\text{ATE}) \mathbbm{1}(Z_i = 1) + (\text{TOT}) \left[\mathbbm{1}(Z_i = 2) \times D_i\right] + U_i \\
\label{eq:TUTreg}
Y_i &= \mathbbm{E}(Y_{i1}) + (\text{ATE}) \left[ -\mathbbm{1}(Z_i = 0)\right] + (\text{TUT}) \left[ -\mathbbm{1}(Z_i = 2) \times (1 - D_i)\right] + V_i 
\end{align}
where $\mathbbm{E}(U_i|Z_i) = \mathbbm{E}(V_i|Z_i) = 0$.
It follows that a pair of just-identified, linear instrumental variables regressions can be used to estimate and carry out inference for the ATE, TOT, and TUT. To identify the ATE and TOT, run IV on \eqref{eq:TOTreg} with instruments $\mathbbm{1}(Z_i = 1)$ and $\mathbbm{1}(Z_i=2)$. An F-test based on this regression can then be used to test the restriction $\text{ATE} = \text{TOT}$, and the usual IV output can be used to carry out inference for the TOT. Similarly, to identify the ATE and TUT run IV on \ref{eq:TUTreg} with instruments $\mathbbm{1}(Z_i = 0)$ and $\mathbbm{1}(Z_i = 2)$. An F-test based on this regression can then be used to test the restriction $\text{ATE} = \text{TUT}$, and the usual IV output can be used to carry out inference for the TUT. 

Because they identify both the TOT and TUT, \eqref{eq:TOTreg} and \eqref{eq:TUTreg} also identify the average selection on gains: $\text{ASG} = \text{TOT} - \text{TUT}$.
Carrying out inference for this quantity is a bit more involved, because $\text{ASG}$ is a difference of coefficients from two separate IV regressions. 
In \ref{append:randchoice} we show how to use the residuals from \eqref{eq:TUTreg} and \eqref{eq:TOTreg} to carry out cluster-robust inference for $\text{ASG}$, a procedure that is automated in our companion STATA package.
As mentioned above, the controlled choice design also identifies the average selection bias (ASB) and average selection on levels (ASL).
In particular,
\begin{align}
\label{eq:ASB}
    \text{ASB} &\equiv \mathbbm{E}(Y_{i0}|C_i=1) - \mathbbm{E}(Y_{i0}|C_i = 0) = \frac{\mathbbm{E}(Y|Z=0) - \mathbbm{E}(Y|Z=2,D=0)}{\mathbbm{E}(D|Z=2)}\\
    \label{eq:ASL}
    \text{ASL} &\equiv \mathbbm{E}(Y_{i1}|C_i = 1) - \mathbbm{E}(Y_{i1}|C_i=0) = \frac{\mathbbm{E}(Y|Z=2,D=1) - \mathbbm{E}(Y|Z=1)}{1 - \mathbbm{E}(D|Z=2)}
\end{align}
as shown in \ref{append:randchoice}
For purposes of inference, both the ASB and ASL can be re-written as the difference of coefficients from a pair of just-identified linear IV regressions.
For details, along with a description of how our companion STATA package carries out cluster-robust inference for these quantities, see \ref{append:randchoice}

%\todo[inline]{Possibly add some discussion here of Craig's idea: using the controlled choice design to study ``targeting''}

%A unique feature of our design is the randomized assignment to treatment (forced commitment), control (forced no-commitment), and choice of treatment. 

%This structure allows us to observe the average value of both the treated and untreated potential outcomes, as well as the selection into treatment that would occur under choice.  A starting point for how to exploit this structure is to apply the logic usually used to estimate the Treatment on the Treated (ToT) to also recover the Treatment on the Untreated (TUT).  This approach assumes nothing about the decision to choose (other than random sampling generating counterfactual compliance rates that would have been the same in every arm), but imposes three exclusion restriction-style assumptions typical of Local Average Treatment Effect (LATE) analysis.  Namely, a) the typical assumption that an individual not choosing the treatment has the same potential outcome as one not offered it, then b) the mirror image assumption for the Forcing arm that an individual forced to take Commitment has the same potential outcome as an individual freely choosing it, and c) no spillovers from chooser to non-choosers in the choice arm.\footnote{\hl{For robustness we also try a Manski-type monotone IV approach with similar results.}}


%More formally, let $Z_i$ be the observed, randomly assigned experimental allocation, where $Z_i=0$ denotes the control arm, $Z_i=1$ denotes the Forced arm, and $Z_i=2$ is the Choice arm.  Let $C_i$ be the choice type; $C_i=0$ when individual $i$ does not choose commitment and $C_i=1$ when chooses commitment, observed in the Choice arm and latent in the other two arms.  A fraction $p$ of individuals chooses the treatment in the Choice arm.  Finally, $D_i = Z_i\times \mathds{1}(Z_i\neq 2) + C_i\times \mathds{1}(Z_i=2)$ is the observed treatment indicator, and $Y(d,z)$ is the potential outcome function for $d=0,1$, and $z=0,1,2$.


%To test the difference between gains for choosers versus gains from non-choosers we need to identify $\mathbb{E}[Y_1-Y_0\;|\;C=1]$ (the Treatment on the Treated), and $\mathbb{E}[Y_1-Y_0\;|\;C=0]$ (the Treatment on the Untreated).   The observed outcome in the Choice arm is the weighted average of the treated and untreated outcomes; $p \times\mathbb{E}[Y_1\;|\;C=1] + (1-p)\times\mathbb{E}[Y_0\;|\;C=0]$.  Given assumptions a) and c) above we can recover the ToT from the difference between the Choice and Control arms as is standard, and then symmetrically we can invoke b) and c) to recover the TUT from the difference between the Forced and Choice arms as follows:

%\begin{align*}
%ToT \equiv \mathbb{E}[Y_1 - Y_0 \;\mid\; C=1]  &=   \frac{\mathbb{E}[Y \;\mid\; Z=2] - \mathbb{E}[Y \;\mid\; Z=0]}{p} \\
%TuT \equiv \mathbb{E}[Y_1 - Y_0 \;\mid \;C=0]  &=  \frac{\mathbb{E}[Y \;\mid\; Z=1] - \mathbb{E}[Y \;\mid\; Z=2]}{(1-p)} 
%\end{align*}


%This estimate of the ToT is the standard one that would result from instrumenting for compliance with the offering of treatment as in \cite{angrist1996identification}.  The TuT is the analogous estimator, which could be recovered in a regression pooling the forced and choice arms and instrumenting for \textit{not} complying with being assigned to the choice arm (for a more formal development, see the appendix).  The advantage of representing the estimands via division of the relevant ITT by the compliance (non-compliance) rate is that it allows us to estimate all the necessary terms from the single pooled regression Equation \ref{basic_reg}, from which the significance levels for the ToT, the TuT, and the difference between them can all be estimated as single-equation F-tests:


%\[ToT = \frac{\beta^C}{p}; \qquad\quad TuT = \frac{(\beta^F - \beta^C)}{(1-p)}; \qquad\quad (ToT-TuT) = \frac{\beta^C}{p}- \frac{(\beta^F - \beta^C)}{(1-p)}. \]

Table \ref{tot_tut} calculates the causal quantities described above--TOT, TUT, ASG, ASB, and ASL--for our experimental data, along with robust standard errors for each. 
For purposes of comparison, the table also presents the ATE results from Section \ref{Experiment} above (row 1), along with the corresponding average potential outcomes $\mathbbm{E}[Y_0]$ and $\mathbbm{E}[Y_1]$ (rows 4--5).
The columns of the table correspond to different outcome variables, defined as in Section \ref{costs} above.
For all four outcome definitions, the TUT effect is positive, statistically and economically significant, and comparable in magnitude to the ATE.
In other words: commitment is \emph{beneficial}, on average, to the people who \emph{would not choose it}, and these benefits are large.
The estimated TOT effects are positive and larger still.
Although we cannot quite reject the null hypothesis that the TUT and TOT effects are equal--our power is limited because of the low take-up rate of commitment in the choice arm--the pattern of coefficients is consistent with some degree of selection-on-gains.
Commitment is more beneficial to people who are willing to choose it than it is to people who are not.
For the APR benefit and (1 - Default) outcomes, we have sufficient precision to conclude that the average selection bias (ASB) is large and \emph{negative}.
This means that borrowers who choose commitment would have faced a \emph{higher} APR and probability of default under the status quo contract than borrowers who do not choose commitment. 
Overall, Table \ref{tot_tut} suggests that commitment works and the ``right people'' choose to commit: those who are most likely to benefit from it and those whose outcomes are most adverse under the status quo. At the same time, \emph{not enough} people choose to commit: the commitment contract is beneficial on average even to those who would \emph{not} choose it voluntarily. Below we explore possible explanations for this result.



%Given that the ITT results for the Choice arm imply an insignificant worsening of outcomes relative to the control, our estimates of the Treatment on the Treated in the first row of the bottom panel show negative results that are larger in absolute magnitude (multiplied by ~9, the inverse of the compliance rate) and similarly insignificant.  The Treatment on the Untreated (TuT), conversely, is strongly positive across the board, and indicates a significant improvement for all outcomes (here ITTs are effectively multiplied by 1.12, the inverse of the non-compliance rate).  Most novel is the ability to form a test of the difference between the ToT and the TuT, which is conducted in the bottom rows of the table.  We provide four different ways of estimating p-values for this comparison; the standard clustered estimates motivated by the experimental design, normal and percentile bootstraps, and randomization inference.  The differences between treatment effects for compliers and non-compliers are of borderline significance in some of the unadjusted specifications, but are not significant once adjusted.\footnote{It is worth noting that the statistical power of these estimands is driven by the compliance rate; given our low overall compliance we are better powered to measure the TuT than the ToT, and the power for the difference between the two would be highest with a compliance rate of 50\%.}   Because of the large standard errors on the ToT coming from the low compliance rate in the Choice arm we are unable to state with statistical confidence that the TuT is higher than the ToT, but the TuT is strongly positive while the ToT is weakly negative, and so in both relative and absolute terms the choices being made are `wrong' relative to the potential outcomes.




\section{The Case for Paternalism}
\label{Paternalism}

\subsection{Why does paternalism work in this context?}
\label{why_paternalism}

The behavioral literature has highlighted voluntary commitment as an attractive way of allowing the ``right'' people to self-select. A discussion of compulsory commitment is necessarily paternalistic, and by its nature focuses on impacts among those who would not have selected commitment voluntarily. Viewed through the lens of rational choice theory, it is unsurprising that we estimate $\text{TOT}>\text{TUT}$. The argument for compulsory treatment, however, centers on the more surprising result that $\text{TUT}>0$.  We now investigate several potential explanations for this result.
For simplicity, we focus on causal effects for the APR outcome throughout this section.

We conduct an exploratory analysis that examines four potential explanations for the positive $\text{TOT}$:  the need to learn, time discounting, present bias, and overconfidence.  To explore the last two dimensions we will use survey data for which our response rate was 78\%.  Appendix \ref{app:survey_data} demonstrates that the subsample on whom we have survey data appears to be representative in terms of loan outcomes.   


\paragraph{Learning.} A first explanation involves learning. Our experiment introduced a new contract into an environment that had not previously featured commitment; perhaps clients required experience to understand its benefits. Given the strongly positive impact of forcing, this explanation would suggest that clients who were forced once would subsequently choose commitment if given the chance to do so. 
A subset of 16\% clients from our sample returned to pawn again on another day before the end of the experiment. Whereas all of the analyses from above restrict attention to the first day on which a given individual pawned, Table \ref{learning_table} presents information about participants' \emph{immediate subsequent} pawning behavior.\footnote{In other words, for borrowers who returned to pawn again more than once, this analysis considers only their first repeat pawn.} Column (1) considers the 228 clients who returned (only a second time) to pawn again at a day/branch that was randomly assigned to the choice arm. Each of the two rows in this column presents a difference of mean commitment take-up rates, and associated standard error. The first row compares those who were \emph{initially} assigned to forced commitment against those where were assigned to control; the second row compares those who were initially assigned to the choice commitment arm to those who were assigned to the other two arms. In each case, there is no statistically discernible difference in the rates of commitment take-up. Granted, this is a selected sample because the decision to pawn again is potentially endogenous to the initial treatment allocation. For this reason, Column (2) considers the full sample of 4436 borrowers by re-defining the outcome variable to be an indicator for returning to pawn again at a branch/day when commitment was offered \emph{and} choosing commitment. This composite outcome variable is not subject to the sample selection problem (although it is directly driven by the decision to repeat borrow). The comparison in the two rows remains the same: forced commitment versus control in row one and choice commitment versus forced arms in row two. Again, there is no statistically discernible difference in commitment take-up rates in either row. While these exercises cannot completely exclude the possibility that learning plays a role, they provide no indication that the lack of voluntary compliance is simply a matter of inexperience with commitment.


%a subset of 228 clients from our experiment who were exposed to the experiment in one round and then returned to take another loan at a branch where the choice of commitment was offered.  Table \ref{learning_table} shows the results of this analysis.   The first column uses only the (endogenous) sample that took multiple loans, and the second column uses the whole experimental sample and defines the outcome as ``returned and chose commitment''.  While the first column is under-powered, the point estimate is actually negative.  The estimate in the second column is pushed upwards by the positive effect of Forcing on repeat borrowing shown in Table \ref{repeat_loans}, and yet the estimate here is very close to zero.  Hence the window available to us on learning provides little comfort that the lack of voluntary compliance is simply a matter of inexperience with commitment.

%Some people self-select into returning for another loan (endogenous). The people who return are randomized into the same three arms as before. Note that we have *not* used their second visits in any other data analysis so far, so this new data. For the self-selected sub-sample, we estimate the difference in commitment take-up across people who were initially assigned to forced commitment versus control: first row and first column. This is zero. The second row in the first column restricts attention to people who were initially assigned to either the choice or control arms, endogenously returned, and were exogenously assigned to choice a second time. We compare the commitment take-up rates the second time around across people who were initially assigned to choice versus those who were initially assigned to the status quo

%Second column defines an outcome that equals one if and only if you *both* return *and* choose commitment the second time around. (Note that this requires you to have been randomly assigned to choice the second time.) The first row compares people who were assigned at random to commitment the first time around against those who were assigned to control. The second row compares those who were offered a choice the first time around to those who were forced into the status quo contract

\paragraph{Time discounting.} Discounting is a second potential explanation for our results.  Our estimated decrease in the financial cost of credit from above ignores discounting, but commitment involves incurring up-front costs (early payment) in return for delayed benefits (a higher probability of recovering one's pawn).  Highly impatient individuals might therefore rationally choose the \emph{status quo} contract, despite the benefits that commitment yields in terms of raw (undiscounted) returns. To investigate this explanation we calculate the net present value (NPV) of the financial cost $\text{TUT}$ effect under different hypothetical discount rates, given the timing of repayment and pawn recovery. Figure \ref{fc_discount_rates} presents the results of this exercise. 
The solid line gives the TUT effect adjusted for a specified annual discount rate, while the shaded regions gives the associated 95\% \& 90\% confidence interval.
We see that non-choosers continue to experience significant decreases in NPV financial costs up to annual discount rates of 4,000\%, and the NPV remains positive, although not significant, at 10,000\% discount rates.  As such, discounting is unlikely to explain why those who benefit, on average, from commitment fail to choose it when offered. 



\paragraph{Present bias.} If the benefits of commitment among non-choosers cannot be explained by standard models of rational choice, the canonical behavioral story would center on time inconsistency.  While commitment is useful to anyone with hyperbolic time preferences, only those who are sophisticated--i.e.\ aware that they are hyperbolic discounters--will demand it.  A large share of ``na\"ive'' hyperbolics in the population--borrowers who are unaware that they are hyperbolic discounters--could therefore drive a large and positive $\text{TUT}$.  Our baseline survey included standard questions about discount rates between today and a month in the future versus discount rates between three and four months in the future.
This allows us to classify borrowers who display more impatience over immediate delays as present biased. This measure of financial hyperbolicity is widely used in survey research, although it is not without problems.\footnote{Our measure is dichotomous, and it is not incentivized. Recent empirical work has shown the superiority of more elaborate measures such as ``convex time budgets'' \citep{andreoni2015measuring} while questioning the interpretation of measures of hyperbolicity that are not based on consumption \citep{andreoni2012estimating, cohen2020measuring}, suggesting that real effort tasks provide a better measure \citep{augenblick2015working}.  Given that we had only a few minutes to interview real pawnshop clients prior to a commercial transaction, our simple measure was a necessary compromise.}   

If we could perfectly measure present bias, we could divide the sample into three groups: sophisticated hyperbolics (who chose commitment), time-consistent non-choosers (for whom forcing will not be effective), and na\"{i}ve hyperbolic non-choosers (who will benefit from forced commitment). If present bias fully explains the low take-up rate of voluntary commitment, we should find that the TUT for present biased borrowers is positive while the TUT for all other borrowers is not.
This is because TUT effects already restrict attention to borrowers who would not choose commitment.
Within this group, a comparison of present-biased borrowers against everyone else is a comparison of na\"{i}ve hyperbolics against time-consistent non-choosers.
The right panel of Figure \ref{tut_beh_partition} carries out a feasible version of this exercise using our survey measure of present bias.
The overall TUT estimate for all borrowers who answered our present-bias survey questions is given in blue, along with a 95\% confidence interval.
The corresponding TUT estimate and confidence interval for present-biased borrowers is given in green; results for all other borrowers are shown in red.
By the law of iterated expectations, the blue overall estimate must lie between the green and red sub-group estimates.
In fact, all three estimates are positive and similar in magnitude, although imprecisely estimated given the extent of survey non-response for these questions.
Taking our survey measure of hyperbolicity at face value, we find no indication that present-bias explains our positive estimated TUT. 

%\todo[inline]{There are two exercises, and we'll do each one in the same way: present bias and sure confidence. In each case, there's a binary indicator that creates two groups. We want to know if this grouping can ``explain'' the positive TUT. At minimum, should see that effect is concentrated on those with the indicator equal to one. Never totally convincing since there could be an unobserved characteristic that is correlated with our indicator variable. If we had a clean hyperbolicity story, we'd have four strata: rational, time inconsistent and naive, time inconsistent and sophisticated, and a fourth group that chooses commitment despite being time consistent. If time inconsistency is the whole story, the negative TUT should be entirely concentrated on the naive types. In other words, they should have a large positive TUT but everyone else should but everyone else should have something close to zero or negative. In terms of decomposing the TUT, we're already restricting attention to people who would not choose. So when we're looking at the TUT we really only have two of these strata: rational types who are not hyperbolic and don't choose commitment, and types who are hyperbolic and don't choose commitment (naives). So $C=0,X=1$ is naive and $C=0,X=0$ is rational. Should find positive effect for $C=0,X=1$ and zero or negative for $C=0,X=0$. To be clear: the point is that we assume by choosing or not choosing commitment, you reveal whether you are sophisticated or not, given that we know your $X$. First thing we could ask is, among non-choosers how many are ``rational'' versus how many are naive. These are the two probabilities in Eq 12. Second compare the treatment effects. Can do the same thing for sure confidence with a slight caveat that it's harder to use the language ``naive'' or ``rational'' here, but we can still think about it in a similar kind of way as long as we're careful with the language.}

\paragraph{Sure confidence.} While 72\% of survey respondents believe they have a 100\% chance of recovering their pawn, in reality only 48\% will go on to do so.  
This suggests a borrower pool characterized by over-optimism.
Incorrect expectations about recovery probabilities could explain low take-up if individuals who \emph{believe} that they are certain to repay choose, rationally given their incorrect beliefs, to forgo the costs associated with commitment that are designed to induce repayment. 
We now explore whether over-optimistic expectations of recovery probability can explain our positive overall TUT estimate.
To do this, we carry out an analysis that is analogous to our present bias exercise from the preceding paragraph, comparing the overall TUT estimate to estimates computed for two sub-groups.
Here, however, the groups are defined by a binary variable that we call ``sure-confidence.''
This measure equals one for any individuals who say at the time of borrowing that they have a 100\% probability of recovering their pawn, zero otherwise.
The right panel of Figure \ref{tut_beh_partition} presents the results for this exercise.
The overall TUT estimate for all borrowers who answered our sure-confidence survey questions is given in blue, along with a 95\% confidence interval.
The corresponding TUT estimate and confidence interval for sure-confident borrowers is given in green; results for all other borrowers are shown in red.
As above, the blue overall estimate must lie between the green and red sub-group estimates by the law of iterated expectations.
In contrast to our results for present bias, shown in the left panel of Figure \ref{tut_beh_partition}, we estimate a higher TUT effect for sure-confident borrowers compared to all other borrowers and a negative, although insignificant, effect for borrowers who are not sure-confident.

As discussed above, our measure of hyperbolicity is based on un-incentivized responses in a short survey and so is likely to be noisy; nonetheless we see no evidence here that it drives the forcing effect.  Rather, the analysis from Figure \ref{tut_beh_partition} suggests that the effectiveness of paternalism in our experiment may be driven by a group of \emph{overconfident} borrowers who, heedless of the risk of default, fail to choose commitment despite benefiting substantially when they are forced to commit. 

%Figure \ref{tut_beh_partition} shows the relative contributions of present bias and sure-confidence for the $\text{TUT}$.  In each figure the orange bar represents the contribution from those who do not possess the attribute, and the blue bar from those that do.  We see that the forcing effect is localized mostly to those who are \textit{not} time inconsistent, contradicting naive hyperbolicity as the justification for paternalism.  Instead, we see sure-confidence being a category that completely isolates the $\text{TUT}$, suggesting that forcing works for those who do not consider repayment structure because they don't think they need it. 

If the attribute of ``sure confidence'' proves so important in explaining the positive TUT, what are its determinants? In Figure \ref{determinants_sure} we plot the coefficient estimates from a regression that predicts sure confidence with a battery of individual-level characteristics.  Older males are more likely to be sure-confident, as are those with more education.  Taken at face value, the sure-confident also appear to face less financial stress, to have less trouble paying bills, and to be more frequently relied upon financially by family members.  Viewed through a behavioral lens, however, it is also possible that the type of person who is over-confident in their ability to repay a loan also maintains fictions in other domains of their financial life, providing answers to the baseline survey questions that exaggerate their degree of economic security. In any case it appears that sure confidence may be difficult to predict with easily-observed and objective demographic criteria, a point to which we return below.


\subsection{Analyzing Choice versus Paternalism Using Causal Forests} \label{sec:RF}


\paragraph{Causal forests.} 
On average, the commitment contract benefits both those who would choose it and those who would not.
In Section \ref{sec:bounds}, we briefly went \emph{beyond} average effects by presenting bounds on the distribution of individual treatment effects.
Because they made no assumptions beyond random assignment, these bounds were relatively wide.
Adding the assumption of rank invariance yielded a distribution of treatment effects that was bounded below by zero, implying that \emph{everyone} would benefit from treatment and hence that there would be \emph{no losers} from paternalism.
Rank invariance, however, is an extremely strong assumption.
In this section, we explore a middle way between the two extremes, by considering conditional average treatment effects and conditional TOT and TUT effects, given our survey measures (note that this approach also imposes the exclusion restriction within each leaf of the tree).
This exercise provides more fine-grained information about treatment effect heterogeneity.
Among other things, it will potentially allow us to identify groups of borrowers who are on average \emph{harmed} by commitment.
Under the stronger assumption that our observed survey measures capture the main sources of treatment effect heterogeneity, this exercise will allow us to approximate individual-level counterfactuals, to consider whether particular borrowers made ``mistakes'' in their choice of contract. 

To estimate conditional average treatment effects given administrative and survey data, we use the function \texttt{causal\_forest()} of the \texttt{grf} R package; to estimate conditional TOT and TUT effects we use the function \texttt{instrumental\_forest()} function from the same package.
In each case, we use the default parameter values from the \texttt{grf} package with one exception: we increase the number of trees from the default value of 2000 to 5000.
The functions \texttt{causal\_forest()} and \texttt{instrumental\_forest()} implement special cases of the ``generalized random forest'' methods of \cite{atheygrf}.
In broad strokes, these functions combine a large number of regression trees that recursively partition the covariate space to estimate conditional average effects.
Figure \ref{causal_tree1} illustrates the partition that emerges from one of the trees in our causal forest implementation.
The trees are ``honest'' in that observations used to determine the optimal partition are not used to estimate effects, and vice-versa.
While closely related to more familiar ``regression-tree'' random forests, the generalized random forest approach explicitly targets the parameter of interest--a conditional ATE or IV estimand--when choosing the optimal covariate partition.\footnote{For more details, see \cite{atheygrf} and the \texttt{grf} documentation: \url{https://grf-labs.github.io/grf/}.} 
When constructing our random forest estimates of heterogeneous treatment effects, we use observations for all borrowers who answered at least \emph{part} of the intake survey.
We impute the median response for the missing values, while also including an indicator whether the variable originally had a missing value.\footnote{Results are similar if we manually include interactions between the original/imputed variable and an indicator for missingness. This is as expected, given that tree-based methods by their nature ``automatically'' consider interactions of arbitrary orders.}

Figure \ref{heterogeneous_effects} plots densities of the estimated conditional ATE, TOT, and TUT effects from the generalized random forest models described above.
In each case, the outcome variable is APR benefit, i.e.\ the reduction in APR from a commitment contract.
As we see from the figure, the conditional average effects are overwhelmingly positive. 
The TUT density is particularly interesting for the question of paternalism since, as emphasized above, it presents conditional average effects for borrowers who would not voluntarily choose commitment.
Only 13\% of our estimated conditional TUTs are negative, with a 95\% confidence interval of [11\%, 17\%].\footnote{The generalized random forest approach of \cite{atheygrf} produces conditional average effect estimators that are asymptotically normal, and includes methods for computing correct standard errors. These methods are relatively straightforward because the trees are ``honest'' in that observations used to determine splits in the recursive partitioning algorithm are not used for causal effect estimation and vice-versa. Our inferences in this section are carried out by ``bootstrapping the limit experiment,'' i.e.\ simulating from the normal limit distributions using the estimated standard errors.} 
To be clear, this is a probability statement about conditional average effects over the distribution of \emph{covariates}.
In particular, we estimate that   
\[
\int \mathbbm{1}\{\mathbb{E}[Y_1 - Y_0| X = \mathbf{x}, C = 0] > 0\} \, f(\mathbf{x}|C=0) \, \mathrm{d}\mathbf{x} 
\]
is approximately 0.13.
The share of non-choosers with a positive conditional \emph{average} treatment effects need not equal the share with a positive \emph{individual} effects, i.e.\ $\mathbbm{P}(Y_1 > Y_0| C = 0)$.
But the more treatment effect heterogeneity that $X_i$ explains, the closer these two values become.
Figure \ref{heterogeneous_effects} strengthens our argument, introduced in section \ref{Choice}, that not enough borrowers choose commitment. 

Under the assumption that our instrumental forest estimates capture the main sources of treatment effect heterogeneity, we can use them to assess whether particular borrowers in the choice arm made ``mistakes'' in their decision to accept or refuse the commitment contract, in terms of predicted financial costs of the loan.
To do this we use the same information that is depicted in Figure \ref{heterogeneous_effects}, but present it in a different way.
For each non-chooser in the choice arm, we use our instrumental forest from above to estimate the conditional TUT effect, given her observed covariates.
Of course conditional average effects need not equal individual treatment effects, and our APR outcome may not capture all of the costs and benefits that are relevant for individual borrowers' decisions.
To account for this, we define a ``mistake'' for a non-chooser to be a conditional TUT estimate that significantly exceeds some large and positive APR threshold, e.g.\ 25\%. 
At any such threshold, we can calculate the percentage of non-choosers in the choice arm who made a ``mistake'' by not choosing commitment.   
(If treatment it beneficial, it should be chosen.)
The results of this exercise can be read off from the green curve in Figure \ref{choose_wrong}.
Defining $F_{\text{TUT}}(\delta)$ to be the CDF corresponding to the density of conditional TUT estimates from Figure \ref{heterogeneous_effects}, the green curve in Figure \ref{choose_wrong} is merely $[1 - F_{\text{TUT}}(\delta)] \times 100\%$.
In other words, the green curve gives the percentage of non-choosers who made a ``mistake'' when mistakes are defined at a particular APR threshold.
The green shaded region gives associated 95\% pointwise confidence bounds.

For choosers we follow an analogous approach, defining a ``mistake'' as a \emph{negative} conditional TOT effect that exceeds a particular APR threshold.
(If treatment is harmful, it should not be chosen.)
The results for choosers can be read from the the red curve in Figure \ref{choose_wrong}.
If $F_{\text{TOT}}(\delta)$ denotes the CDF corresponding to the density of conditional TOT estimates from Figure \ref{heterogeneous_effects}, then the red curve is merely $F_{\text{TOT}}(-\delta) \times 100\%$.
In other words, the red curve gives the percentage of choosers who made a ``mistake'' when mistakes are defined at a particular APR threshold.
The red shaded region gives associated 95\% pointwise confidence bounds.
Note that we use a \emph{positive} APR threshold to denote a mistake for both choosers and non-choosers. 
This ensures that bigger mistakes are always to the \emph{right} of smaller mistakes for both the green and red curves.
The blue curve in Figure \ref{choose_wrong} gives the \emph{overall} percentage of borrowers in the choice arm who made a ``mistake'' at a particular APR threshold.
This total is computed by taking a weighted average of the green (non-choosers) and red (choosers) curves, with weights equal to their shares in the choice arm.\footnote{The blue curve is very similar to the green curve because 89\% of borrowers in the choice arm are non-choosers.}

The results in Figure \ref{choose_wrong} suggest that a large fraction of non-choosers made mistakes by not choosing commitment.
Even at an APR threshold as large as 25\%, we estimate that more than half of them should have chosen commitment in order to lower financial costs.
In contrast, relatively few choosers appear to have made mistakes by choosing commitment.
This now allows us to make a stronger statement in favor of paternalism; not only does forced commitment generate large benefits on average, but it also benefits the vast majority of borrowers \emph{who would be coerced} under a policy of forced commitment.


%As we increase the threshold on the size of the mistake necessary to be classified as having made the wrong choice, by definition the share of mistakes in both groups falls.

%Among choosers, only 18\% would have had superior outcomes had they not complied, whereas among non-choosers almost 80\% made a mistake according to this definition.  Because this arm is comprised of 89\% non-choosers, the overall rate of mistake in the arm was around 68\%.  

%benefit is the case that forcing commitment generates large benefits on average, but it is also generating benefits for almost 90\% of the forced population.



%\todo[inline]{ 
%Can read this from red curve (and error bars) in Figure \ref{choose_wrong}, simply $F(-x)$ for the conditional TOT. Comment on results. Relatively few negative conditional TOT estimates: around 20\% with wide confidence bounds. Again say APR threshold of 25\%. Then say something like 8\% to 27\% \hl{???} mistakes. 
%Blue curve: combine to understand mistakes overall across choosers and non-choosers. Weighted average of red (TOT/chooser) and green (TUT/non-chooser) with weights corresponding to shares of each type. Very similar to green curve since 89\% are non-choosers and we estimate that relatively few choosers had a negative conditional average treatment effect.}


%These impacts allow us to think about whether individuals made ``mistakes'' in their choices.  
%Specifically, for each client in the choice arm we want to know how much cost savings would she have gained had she chosen the opposite contract. 
%We do this in two steps.  
%First, we use  \cite{atheygrf}'s generalized random forests methodology to estimate the impact of the forced commitment arm relative to the control (forced status quo) at the individual level.  
%The method generates a partition of the space of characteristics $X$, where each element of the partition is a leaf, and each leaf contains treatment and control clients with similar characteristics $x \in X$ which are used to calculate unbiased treatment effects for that leaf. 
%The optimal partition is that which minimizes expected mean squared error of treatment effects predictions out-of-sample. 
%The tree is ``honest'' in that uses one sub-sample to build the trees that make up the random forest and another one to estimate treatment effects within those trees.
%\cite{atheygrf} show that their treatment effects are asymptotically normal, which allows us to construct confidence intervals for our treatment estimate in each leaf. 
%This method gives us the average causal effect on financing cost of getting the forced commitment contract instead of the status quo contract for a client $i$ with characteristics $x_i$; call it $TE^{F}_{i}(x_i)$.\footnote{Figure \ref{causal_tree1} and ??? provide an illustration of the splits (leaves) that emerge from our implementation of the RF. \todo[inline]{I think we should list in a footnote which are the `wide' variables we are using.}}  

%\paragraph{Personalized benefit results.} Using the test provided by \cite{chernozhukov2018generic}, we reject the null of homogeneity in treatment effects and so begin our analysis of heterogeneity confident that it exists. Figure \ref{heterogeneous_effects} illustrates the substantial impact of the forced commitment arm on APR, financial cost and other outcomes. More than 90\% of the individuals have APR saving effects, and even in the upper bound confidence interval more than half of individuals benefit.  

%\paragraph{Estimates of financial cost `mistakes'.} In a second step we predict treatment effects for clients \textit{in the Choice arm} using the partition into leaves and the treatment effect from step 1, that is client $j$ is imputed the treatment effect of the leaf corresponding to her characteristics $x_j$. We call this counterfactual treatment effect $\widehat{TE}^{F}_{j}(x_j)$. This is precisely the counterfactual we wanted, because it lets us relate observed individual choices with estimated individual-level treatment effects.\footnote{This extrapolation of the treatment effects assumes that choice itself --conditional on a given contract-- does not affect behavior (note the evidence in the prior section suggesting this is the case).   Although the extrapolation is to another population, by randomization it is a statistically identical population with common support.} Armed with this, we say that a client made a ``mistake'' if either she chose the status quo contract and her $\widehat{TE}^{F}_{i}$ is negative (i.e. more cost saving from the Forced contract), or if she chose the Commitment contract and $\widehat{TE}^{F}_{i}$ is positive, (i.e.  financial costs are larger for the Commitment contract). When a client made a choice mistake, we say that its money-metric values is the absolute value of $|\widehat{TE}^{F}_{i}|$. 


%Using the forcing arms and extrapolating to the choice arms.
%Then, we predict these treatment effects for everybody in the choice arm using characteristics $x_i$. Let $\widehat{TE}^{fee}_{i}$ be the predicted financial cost savings for person $i$ of choosing the Forced Commitment contract rather than the status quo one, divided by the size of her loan (i.e. the negative value of the predicted treatment effect on financial cost for person $i$). $\widehat{TE}^{sq}_{i}$ is the analogous for the status quo contract. We define the choice of person $i$ to be a ``mistake'' if 

%\begin{equation}
% \{ i \; \text{chose} \; sq \; \text{and} \; \;  \widehat{TE}^{fee}_{i}>\widehat{TE}^{sq}_{i} + z \} \; \text{or} \; \{ i \; \text{chose} \; fee \; \text{and} \; \;  \widehat{TE}^{fee}_{i}<\widehat{TE}^{sq}_{i} - z \}
%\end{equation}

%Since the prediction of the treatment effect is an estimate and has noise, we do two things. First, we normalize $\widehat{TE}^{F}_{i}$ by the value of the loan of person $i$ and introduce a threshold parameter $z$ and say that a choice is a ``mistake'' if the alternative contract would generate greater than $z$ in savings. We vary this threshold from 0\% to 15\% of the value of the loan. Second, we take into account uncertainty in estimation of treatment effects and report results using the extremes of the 95\% confidence interval bounds for $\widehat{TE}^{F}_{i}$.

%Figure \ref{choose_wrong}(a) plots on the Y axis the fraction of clients that made a choice ``mistake'' and on the X axis the threshold $z$. When $z=0$, we calculate that about 82\% of clients in the Choice arm chose contracts that induced \textit{higher} financial cost. Most mistakes are failures to choose the fee-commitment contract ({97}\%), while only {4}\% of those who chose the fee-commitment contract would have been better in the status-quo one. The average mistake in pesos is \$250. %(90\% confidence interval [140,390]). 


%However, the fraction of non-choosers making a mistake remains almost 20\% even at the highest threshold used (\$80 pesos), and panel b shows the \textcolor{red}{Complete this when understand figure}.  Panel C conducts a related but distinct exercise, showing the fraction of the entire control sample who would do better if assigned to the Forced arm; using the smallest threshold this fraction is over 95\%, showing that in this context there is an almost across-the board welfare benefit arising from this arm.  Since the only potential financial cost of the forced arm arises from individuals who would be induced to partially repay but then default anyways, this result suggests that very few such borrowers exist.

%Panel C of this figure replicates this exercise for the forced commitment arm, with the difference being that the relevant treatment effect to match is now the ATE of the forced commitment arm.  This allows us to identify the winners and losers from paternalism in a nuanced manner, since members of groups with CATEs$<$0 are hurt and everyone else is helped.  Because the ATE$>$TUT, this exercise results in an even larger fraction of individuals benefiting from commitment; here we find that fully 91\% of individuals are better off being forced into commitment than staying in the control. .



\subsection{Can we target paternalism?}


%\todo[inline]{@Frank: note that we for the wide forest we use everyone who answered at least one survey question in the random forests. We have dummies for missingness of any of the predictors. We then take this as ground truth. For the narrow forest, we restrict to the sample for which we don't have missing values. Under certain assumptions, this ``controls'' for selection into the survey. Need to think a bit more about the interpretation here: it's slightly tricky. Question of external validity? Imagine another sample with the same pattern of non-response, then there's probably no concern. I think the issue here relates to whether the covariates that are missing for us would be missing in the hypothetical targeting exercise. It's a question of ``could we have targeted'' versus ``could you target'' in a setting where you have administrative data for everybody?}

Despite having shown such a large majority of individuals benefit from paternalism, it is still natural to ask whether we are able to target commitment in such a manner as to only force it upon those who benefit. For a financial firm to engage in this type of targeting under real-world circumstances, we must impose several constraints on the targeting rule.  First, it will in general not be possible to use the numerous subjective and unverifiable questions we asked in the baseline survey as inputs to the rule because the answers to these questions can be manipulated by the clients, and would likely change when they become incentivized. This leaves us with only a few objective covariates that could be used to target: age, gender, HS education or above, desired loan size, and whether that individual has ever pawned before. 
We call these the ``narrow'' covariate set below, to contrast with the full set of survey variables, which we call the ``wide'' covariate set.
Secondly, it will not be attractive for a commercial firm to ask individuals whether they want to voluntarily accept commitment and then to force upon those who say no against their will. So the choice variable itself cannot be used to target other than in a voluntary program. 
For this reason, the relevant causal effect for this exercise is the conditional average treatment effect (ATE) rather than the conditional TUT or TOT as considered above.
As shown in Figure \ref{fig:CATEsurvival}, an estimated 92\% of borrowers, with a 95\% confidence interval of [89\%, 94\%] have a positive conditional ATE as estimated from the causal forest from section \ref{sec:RF} above.
In the remainder of this section we ask how accurately it is possible to identify these borrowers. 

\paragraph{Narrow inputs targeting.} To  consider targeting effectiveness we must begin from an individual-specific ground truth, which we take from our estimated conditional average treatment effects (CATEs) $\widehat{\text{ATE}}(X_i)$ from the causal forest described in Section \ref{sec:RF},  which used the ``wide'' set of covariates (wide RF) and data for all borrowers who replied to at least part of the intake survey. We then analyze how well we can predict the losers from paternalism using the ``narrow'' set of non-manipulable covariates listed above (narrow RF) for the same subset of borrowers.
Figure \ref{wide_narrow_forests} shows the relationship between the CATEs estimated from the RF using the ``wide'' and ``narrow'' covariate sets.  It is visually obvious from this figure that we generate substantially less heterogeneity when using the narrow covariate set, although we still reject the null hypothesis of no treatment effect heterogeneity, following the approach of \cite{chernozhukov2018generic}.\footnote{See \ref{append:chernozhukov} for details of this method.}

\paragraph{Targeting assessment.} 

To more directly investigate our ability to target commitment, we use two different methods to predict who should be assigned to the commitment arm. In each, we estimate a classification model using the ``narrow'' set of covariates to predict whether the CATE from the wide random forest model is positive. The first method uses a simple logistic regression, while the second uses a random forest classification model.\footnote{We use the STATA package \textit{rforest} and use the default parameters for the estimation. For further detail see \cite{rforest_stata}.} Each of these methods yields an estimated probability of a positive CATE, allowing us to rank borrowers from highest to lowest probability. Since 92\% of borrowers have a positive CATE as estimated from the wide random forest model from above, we consider a decision rule that assigns a borrower to forced commitment if her estimated probability is in the top 92\% of the sample.
%The first of these is the narrow RF displayed above paired with the decision rule which assigns clients to forcing commitment if the estimated CATE from the narrow covariate set is positive. 
%In the second approach we estimate a logistic regression model with an outcome variable equal to one if the ``wide'' model CATE is positive, zero otherwise. 
%The explanatory variables are the covariates from the ``narrow'' model. We assign a borrower to commitment if \hl{the probability that her CATE is positive is estimated to be above 0.5}.
Figure \ref{targeting_rules} compares the in-sample performance of these targeting rules against a policy of universal forced commitment. The plot presents the estimated proportion of borrowers who benefit from a particular treatment assignment rule, along with associated 95\% confidence bands, where ``benefit'' is defined as having a conditional average treatment effect above a particular threshold. As above, we take the conditional average effects from the ``wide'' causal forest as ground truth for the purposes of this exercise. 
Because this is an in-sample exercise, the logistic and random forest classification rules have an unfair advantage: there is no adjustment for overfitting.
In spite of this, their performance is quite unimpressive relative to a policy of universal forced commitment.
The fraction of the whole sample incorrectly targeted when moving from universal forced commitment to targeting based on the narrow RF falls only from 8.07\% to 5.49\%. The logit targeting rule actually makes things marginally worse. 
Table \ref{hit_miss_rule} shows error rates for six possible assignment rules: assigning all borrowers to control, all to treatment (Forcing), the optimal (infeasible) assignment, narrow RF targeting, logit targeting, and we evaluate ex-post the voluntary choice.  While the narrow RF correctly assigns roughly half of those who do not benefit from commitment to control, it also incorrectly allocates 3.7\% of the sample that would have gained from treatment to control. As such, it only improves the correct targeting rate by about a half of a percentage point on net relative to universal Forcing. The logit assignment rule is less successful at predicting benefits and harms, with a higher share of borrowers incorrectly assigned to both treatment and control. 
%In particular it makes many Type II errors, resulting in a net targeting performance that is actually worse than universal forcing. 
The underlying cause of the weak performance of targeting is that the attribute that predicts gains from forcing (being sure confident and not choosing the commitment) is largely behavioral and not easily predicted with basic covariates, as seen in Figure \ref{tut_beh_partition}. Self-targeting through choice proves to be little better than assigning everyone to the control condition, given the low take-up rate and the presence of both Type I and Type II errors in the choice arm. Fully 79\% of individuals in the Choice arm made a ``mistake'', weighting the error rates among choosers and non-choosers by their relative frequency in the Choice arm. The takeaway is that given low take-up, the large fraction of the sample benefiting from commitment, and the weak predictive power of the narrow covariates, in this case universal paternalism appears to be an attractive contract. 

%Given the poor explanatory power of the narrow covariates, as shown in Figure \ref{wide_narrow_forests}, it is unsurprising to see that the information gain from using these variables is small; 

%This latter results is driven by the confluence of the poor explanatory power of the narrow variables, as shown in Figure \ref{wide_narrow_forests}, with the fact that the logit matches the correct sample fraction of ones, therefore making numerous Type \hl{II} errors \hl{(Should it be Type I?)} in an environment where commitment is beneficial for most. 








%OLD SECTION 6 TEXT:

%Moving more deeply into heterogeneity in treatment effects, we can try to understand the gains or losses from forcing at the individual level.  To investigate this, we first use completely flexible non-parametric bounds, then add structure on to the individual heterogeneity via a random forest estimation, and finally we consider the optimal targeting of forced compliance.

%As shown above in Section \ref{experiment}, the ATE of the commitment contract from the forced arm is positive and significant, both economically and statistically.  But this is only an average effect: a positive ATE is still consistent with negative individual treatment effects for some borrowers. 

%Unless she is a strict utilitarian, any policymaker who is considering outlawing the \emph{status quo} contract in favor of the commitment contract needs to consider the extent and magnitude of harm that such a paternalistic policy will cause to \emph{individual} borrowers. Our TUT and ToT results from Section \ref{sec:randchoice} partially address this concern. In particular, our TuT estimates show that even those borrowers on whom a policy of paternalism would impose a binding constraint stand to benefit, on average, from commitment. Again, however, this is only an average effect: a positive TuT is perfectly consistent with negative treatment effects for \emph{some} of the untreated. This section takes a closer look at treatment effect heterogeneity, to better understand the gains and losses from a policy of forced commitment at the individual. First, we explore heterogeneity in the average effects reported in Sections \ref{experiment} and \ref{sec:randchoice} using random forests. Then we consider the problem of optimal targeting: how accurately can we determine which kinds of borrowers would benefit from commitment, based on their observed characteristics?

%Now talk about paternalism. First, are people learning? Is it the case that people who have borrowed more in the past are less overconfident? Do people who were randomized into forced commitment later decide to choose commitment? Finally: how to target and who would be hurt if we instituted paternalism? The relevant counterfactual here it the TuT, since this is the causal effect of forcing the people who wouldn't choose voluntarily. Break down by covariates. Do we see any interesting patterns? 





%\subsubsection{Random Forest Bounds on Treatment Effects}


%\todo[inline]{Frank/Issac: need to discuss confidence interval construction for the mistakes exercise. I'm not 100\% sure about it. There's question of what we can actually infer from the random forest exercise. We can't learn the distribution of treatment effects within a ``bin'' but we can learn the ATE in the bin along with its standard error, and we can treat that as approximately normal. Another issue concerns whether we do or do not use the observed outcomes for the people in the choice arm. At present we're not using this. But you might say that we should. This would entail predicting their \emph{counterfactual} outcome. What I mean here is that $\text{ATE}(X)$ is what you would use to assign someone to a particular treatment, given that you have observed their $X$. But what we have is a little different. We observe both their $X$ and either $Y_1$ or $Y_0$. I think there's an interesting question here about whether we're interested in something \emph{ex ante} or \emph{ex post}. It relates to the issue of ``mistakes.'' We should discuss briefly as a group so Frank \& Issac can make the appropriate adjustments if needed.}

%\todo[inline]{Issac: add in the picture for the ToT/TuT version of the ``mistakes'' exercise \& histograms of treatment effects by groups. We already have the histogram in figure 15 for the ATE. Is it possible to say something about the covariates of the choosers for whom we estimate a negative ToT?}

%\todo[inline]{Frank draft: The first exercise looks at ``mistakes.'' These are defined by predicting treatment effects for the people in the \emph{choice} arm using their covariates. If the treatment effect is positive and they don't choose treatment, this is a mistake. If the treatment effect is negative and they choose treatment this is a mistake. There are two ways of carrying out this exercise. The first way assumes that, conditional on $X$, there is no selection on gains. This version uses a model of heterogeneous treatment effects estimated using only people from the forced arms to create predicted ATEs for people in the choice arm. The second version calculates ToT and TuT versions of the same thing, but this involves using data from the choice arm, so it's less efficient because sample-splitting is required so we have to discard some people from the choice arm when calculating ``mistakes.'' Issac implements this with 5 partitions of 20/80, repeating five times and averaging over the result. Comparing the results of the two versions we find something interesting. For the non-choosers, the results are similar in both versions. Lots of mistakes and pretty big. For the choosers, we find very little evidence of mistakes using the ATE version and much more using the ToT version. What does this mean? It suggests some form of perverse selection on gains. These must be people who think commitment will help them but it actually hurts them. Question: what are their covariates like? What kind of people are they? This gets to Craig's question about who is hurt in each treatment regime. There aren't very many choosers (only 11\%) and something between 15 and 35\%, depending on the threshold, of them are ``hurt'' according to our model. So quantitatively it's not many people. What about with the ATE: what fraction of people \emph{overall} do we predict are hurt by the treatment? (We bounded it above, but now we have a model.) Seems like this is around 1-2\%.} 

%To more directly interrogate self-selection in this context, we would like to be able to relate \textit{individual} choices over commitment to the \textit{individual} counterfactual outcomes that borrowers would have realized in different states of nature.  To achieve this, we can use the honest causal forest method to impute borrower-specific treatment effects of the assignment to Commitment, and then map this estimate to the choices individuals make in the Choice arm.



\begin{comment}
\subsection{Marginal Treatment Effects}
As described above, our experimental design point identifies the ATE, TUT, and TOT without the need to carry out a marginal treatment effects (MTE) analysis that would rely, to some extent, on structural assumptions or shape restrictions. Nonetheless, researchers who are interested in learning more about essential heterogeneity can combine our design with an MTE approach.
\todo[inline]{Need to flesh out a bit more, but in short: (1) can extend the results of Mogstad et al (2017) to use our ATE, TUT, and TOT as additional inequality restrictions that constrain partial identification bounds for MTEs; (2) Could allow more flexibility in the approach of Carneiro et al (2011) by recovering $\mu_0(x)$ and $\mu_1(x)$ from the forced arm. This permits richer forms of observed heterogeneity than the linear specification that is typically used in applied MTE papers. One could also combine (1) and (2) or use (1) as a specification test for (2).}




    
\subsection{Relating Choice Probabilities to Benefits}

   
The previous exercise consisted of extrapolating treatment effects from the no-choice arms to the Choice arm. Here we do the reverse. First, we estimate a flexible model of take-up of the commitment-fee contract \textit{in the Choice arm} using gradient boosting classification\footnote{Results are robust to other classification methods like Random Forest, SVM, etc.} and obtain for a client with characteristics $x_i$ a calibrated probability $P(x_i)$ of choosing the commitment contract. We then use this model to predict the counterfactual probability of a client with characteristics $x_j$ choosing the Commitment contract in the Forced arm if she had been given the choice, what we call $\widehat{P(x_j)}$.\footnote{Our gradient boosting take-up model has a good out-of-sample fit with an out-of-sample AUC of \colorbox{yellow}{0.85}. (accuracy 97\% in-sample and 90\% out-of-sample)} Now, armed with this propensity score in the Forced arm, we can ask whether people with larger Random Forest-estimated individual treatment effects (i.e. more cost savings) would have been more likely to choose it, as we would expect from a Roy model of treatment selection. 



We can represent the relationship between the HTEs from commitment and propensity scores in several ways.  Most straightforward is Figure \ref{HTE_vs_propensity}, which plots the individually-estimated treatment effect from Forced versus Control treatments on the Y-axis, and the predicted probability of choosing commitment on the x-axis.  The HTEs are very strongly downward-sloping over the part of the distribution that has heterogeneity in predicted propensities, the opposite of what we would expect from Roy-type selection.  The sample with the lowest propensity of choosing commitment has a smoothed benefit of roughly twice those with a .2 change of choosing, measured both in terms of benefit/cost and in terms of probability of repayment.  Hence the very large heterogeneous treatment effects are almost completely localized to the individuals who have the very lowest probability to select commitment.


Second, we can turn the continuous propensity score into a binary predicted choice, such that the proportion of choosers matches the observed data, and then compute cumulative distribution functions of the heterogeneous conditional average treatment effects we estimated using the Causal Random Forest. Figure \ref{benefit_vs_choice_cdf} shows there is a first order stochastic dominance in treatment effects between the two predicted categories. This means those more likely to demand commitment are also those that had smaller benefits from commitment.

Finally, a completely different approach to relating choice to HTEs arrives at a similar conclusion.  We attempt to characterize the class that benefits more from commitment using a finite mixture model with two latent types. After estimation of this FMM, we find that the class more benefited from being forced is negatively correlated with demand for commitment (see Figure \ref{fmm_hte} in the appendix). We identify this class with the naive individuals, since choice is the core divider, and this class is predicted to default more (see Table \ref{fmm_table} in the appendix). This exercise emphasizes how important choice is as a segregator.

Hence, we pursue several quite different techniques and all arrive at the same result.  All of the treatment heterogeneity is found among individuals who did receive the Commitment contract, whether chosen or forced.  Whether we exploit the point-identification of LATEs for compliers and non-compliers enabled by the Forcing arm, use HTEs to examine the `mistakes' made by choosers versus non-choosers in the Choice arm, estimate propensities and relate these to HTEs in the Forced arm, or use a non-parametric finite mixture model, the overall story is the same:  the wrong people are choosing commitment.

These findings suggest that forcing clients into commitment contacts may reduce financial cost for the overwhelming majority of clients. 
%Figure \ref{choose_wrong}(c) calculates what fraction of clients would be made better off if we forced them into the fee-commitment contract. We find that 85\% would be better off (using $z=0$), and they would on average have savings of 250MXN. 
This conclusion is in line with a recent paper by \cite{John}. In a savings context, she finds that when commitment is on the menu a majority of subjects wrongly choose too little commitment and fail to reach their savings goals. It is also in line with \cite{Sprenger} who show that the more naive about their present bias are the ones who demand less commitment.\footnote{This result is also similar to \cite{Walters}, who finds that students that select into more effective schools are the ones with smaller treatment effects from attending.  That paper uses distance to school as an instrumental variable for choice, while we use randomization to choice vs no-choice groups as our empirical strategy.}

\end{comment}



    
\section{Conclusion} \label{conclusion}

\cite{Laibson2018} discusses the idea of ``veiled paternalism'', whereby principals embed forms of commitment into their products but mask this fact from consumers who may need but do not desire commitment. In the context of pawnbroking, over-collateralization means that lenders stand to make more money from unreliable borrowers than those who repay.  The fact that a simple change to contract terms results in a substantial financial saving for borrowers implies that the pawn contract involves ``veiled non-paternalism'':   features that lead to high borrower costs are embedded in non-obvious ways.  Potentially due to the nature of the borrower pool, voluntary commitment choice does not result in substantial improvements in borrower returns; a mandated reform to the contract induced significant cost savings for the overall group of clients.  

We are able to arrive at a nuanced set of conclusions about the relationship between take-up and heterogeneity in returns due to a novel experimental setup, the ``Controlled Choice'' design.  This three-armed experiment, featuring a control group, an arm with borrower choice, and an arm with compulsory treatment, allows us to point-identify the impact of the treatment on those who would naturally choose it as well as those who only experience commitment when forced.  While we find evidence of selection on gains (as would be expected from standard economic models) there remain substantial benefits of treatment even for non-choosers.  Given that the rate of voluntary commitment in our sample is only 11\%, in order to achieve widespread benefits in this context compulsory commitment may be necessary. In the Forced arm the APR (inclusive of the cost of default) falls from 184\% to 150\%, and the fraction of borrowers defaulting on loans drops by 6.5 pp, or 15\%. Clients appear to prefer the forced commitment after they have experienced it, in that assignment to this arm increases the fraction of individuals who return to pawn again.

Why do borrowers leave such substantial returns on the table? Our investigation of treatment effect heterogeneity suggests that over-optimism is the characteristic most strongly associated with benefiting from the intervention and yet not choosing it.  Overall the borrower pool overestimates their own probability of repayment by more than 50\%, and we find that the positive TUT is almost entirely confined to borrowers who report that they are certain to repay. The takeaway is that inefficiently low demand for tools to remediate default is strongest among those who incorrectly believe that they have no chance of defaulting.  More standard explanations such as discounting, learning, or time inconsistency find little support in our data.  Importantly, we find that not only are the benefits of commitment close to universal, but the determinants that might allow us to target it more finely are primarily behavioral and hence not easily predicted in an fast incentive-compatible manner by lenders.  Even a sophisticated machine learning-based exercise is only able to decrease the fraction of borrowers mis-targeted by about 2.5 percentage points relative to simply assigning everyone to commitment (from 8\% to 5.5\%), and a logit-based targeting rule actually does slightly worse than universal commitment.  

This result has immediate policy implications.  Pawnshops, along with other over-collateralized credit products such as payday lending, exist in an environment where the bank may desire customers to lose their collateral on the loan. Given the high prevalence of the use of this form of credit by low-income households, this has an obviously detrimental effect on the dynamics of asset accumulation among the poor.  Given that the specific items being pawned (such crucifixes and family jewelry) may have sentimental, non-pecuniary meaning to households, the efficiency implications of these contract terms may be even larger (as evidenced by the fact that borrowers' subjective value of their own pawns was 26\% higher than the appraised collateral value).   With a now well-established toolkit of regular small payments and incentives delivering vanishingly small default rates in microfinance, regulators in the banking sector may fruitfully investigate the possibility of requiring pawnbrokers to embed features of commitment and regularity into their repayment structures in more consistent ways.   If employed at scale in a competitive lending sector this could redistribute welfare from those who would have repaid (whose interest rates must now rise to cover lower returns from collateral seizure) towards those who would only repay in the presence of commitment. In a setting of lender market power however, some redistribution from lenders to borrowers could occur.

Where banks have no incentive to engage in veiled paternalism and customers display inefficiently low demand for it, financial policy regulation may prove an attractive option.  An important question for future research will be the extent to which borrowers are able to learn about the benefits of commitment over time, making it so that temporary, lighter-touch policies could achieve lasting benefits for borrowers.  Pawning with commitment may provide an important mechanism to preserve flexible credit access while allowing more poor borrowers to retain their assets.






%In a pawnshop borrowing context, we study whether forcing borrowers into frequent payment commitment contracts reduces their borrowing costs, compared to a contract that does not provide commitment to pay monthly. Even though we are charging them fees,  borrowing costs under forced commitment are actually reduced by 9.4\%, and pawnrecovery is 26\% higher. Moreover they themselves seem to like this contract, as they are twice as likely to come back and pawn again when they are assigned to forced commitment. That is, commitment matters and it seems beneficial. 

%We examine treatment heterogeneity using a range of methods, from bounds that make no assumptions, exploiting a mild exclusion restrictions and the innovative controlled choice design to gain point identification of TUT and TOT, and invoking seletion on observables to estimate treatment effects at the person level. We find that a large majority of clients benefit from the commitment contract, but that when given choice between the commitment and the status quo contract only 10\% choose the former one and thus forgo important financial benefits. We also find that overconfident clients experience larger treatment effect cost savings from the commitment contract but at the same time have smaller demand for it. (\hl{Is it true that they have smaller demand? Which Figure shows this? If so we should say this above and not only in the conclusion})
%A simple model shows that present bias with naivete parsimoniously explains all findings. 
%The analysis suggests that it is possible in our context to advance an individual's financial  by restricting her freedom of choice ---although we caution that our outcome measure focuses on financing cost and is not a comprehensive measure of welfare. %These results spurred --although we cannot show they caused-- Lender $P$ to offer frequent payment contacts, although Lender $P$ was uncomfortable forcing these contracts on clients. They hoped that clients would eventually learn which contract was better for them.

%Methodologically, to our knowledge this is the first paper in economics that uses machine learning methods and a combination of choice and forcing arms to estimate personalized counterfactual treatment gains to ask whether treatment takeup is positively selected on benefits, a hypothesis we reject.

%Pawnshop borrowing may attract particularly unsophisticated clients and freedom of choice may fare better in other contexts. Choice may also fare better with other contracts besides the fee-commitment one we used. We experimented with a ``softer'' commitment contract in the form of a personal promise, and found that although this soft commitment contract  elicited more interest, it did not cause changes in behavior. 

%Our results suggest several avenues for future research. First, it would be useful to tease out the roles played by naivete about self control problems and biased expectations about income shocks in driving low demand for commitment. Second, one could ask whether other types of contracts %---for instance those that provide some insurance against shocks---  
%induce larger demand and better performance than the ones we tried. Third, testing and quantifying of there is selection to pawnshop lenders based on unsophistication could be important for regulators. Fourth, collecting broader measures of welfare to use as outcomes --e.g. subjective well being and consumption-- would help to make broader claims about welfare than we can make in this paper. Finally, one would like to know which interventions could de-bias consumers, or whether learning alone would do the work.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%BIBLIOGRAPHY


\clearpage
\bibliographystyle{authordate1}
%\bibliographystyle{amsalpha}
%\bibliographystyle{AER}

\bibliography{References}



%\FloatBarrier
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\singlespacing

\section{Tables}

\begin{table}[H]
\caption{Limited and balanced attrition}
\label{attrition_table}
\begin{center}
\scriptsize{\input{./Tables/Attrition.tex}}
\end{center}
 \scriptsize Each row in this table 
 corresponds to a regression, where the level of observation is the individual loan originated. The dependent variables of these regressions are displayed in the first column. Each dependent variable is regressed in a multivariate OLS regression against the experimental arms indicators (control, forced commitment, choice). The table reports the coefficients on each of these indicators, as well as the p-value an F-test of the null hypothesis of equality of the three coefficients. The dependent variables are: the number of pawns-loans originated per day per branch, a variable indicating whether a person who answered the baseline survey (before knowing contract terms) ended up pawning, and an indicator of whether the person that obtained the loan answered the baseline survey. By design we had the choice arm be larger.
%\textit{Do file: } \texttt{ss\_att.do}
\end{table}

\newpage
\begin{table}[H]
\caption{Summary statistics and Balance}
\label{SS}
\begin{center}
\scriptsize{\input{./Tables/SS.tex}}
\end{center}

%\textit{Do file: } \texttt{ss\_att.do}
\end{table}
\vspace{-.3in}
\scriptsize {
\noindent This table has two panels. Panel A uses administrative data at the loan level, while Panel B uses survey data. Each row in this table corresponds to a regression, where the level of observation is the individual loan originated. The dependent variables of these regressions are displayed in the first column. Each dependent variable is regressed in a multivariate OLS regression against the experimental arms indicators (control, forced commitment, choice). The table reports the coefficients on each of these indicators, as well as the p-value an F-test of the null hypothesis of equality of the three coefficients. The admin data was a very limited set of pre-determined variables. The dependent variables in Panel A are the loan amount in pesos, and an indicator for whether the day of the loan origination was a weekday (as opposed to weekend). The dependent variables in Panel B from the survey (see the questions in Table \ref{baseline_survey}. Subjective value of the pawn (how much would the client be willing to sell it for (Q3), an indicator for having trouble paying bills in the last 6-months (Q28), present bias (constructed from questions Q10 and Q29 in the standard way as in \cite{Ashraf}), an indicator for whether they make expenses budget for the month ahead of time. The subjective probability of recovery was elicited a la Manski (from 0 to 100 what is the probability that you will recoup your pawn), pawned before is a dummy=1 if the client declares to have pawned before (although not necessarily with Lender $P$) age is in year, +High-school is a dummy that indicates if the client has completed high school. 
}



\newpage

\vspace{.2in}

\begin{table}[H]
\caption{Effects on Financial Cost}
\label{main_impact_table}
\begin{center}
\scriptsize{\input{./Tables/decomposition_main_te.tex}}
\end{center}
\scriptsize This table shows the treatment effects for our core pecuniary outcomes. Each column is a different regression for different outcomes on an indicator for the forced and choice arms, following specification in equation \ref{basic_reg}. Columns (1) \& (7) analyze our core financial cost measures, while the rest of the columns decompose these into finer components as follows:

\begin{align*}
    \underbrace{\text{Financial Cost}_i}_{(1)} =&  \underbrace{\sum_t P^i_{it}}_{\underset{(2)}{\text{Payments to interests}}}  +\underbrace{\sum_t P^f_{it}}_{\underset{(3)}{\text{Payments of fees}}} + \underbrace{\overbrace{\mathds{1}(\text{Default}_i)}^{(6)}\times (\text{Appraised Value}_i}_{\underset{(5)}{\text{Cost of losing pawn}}} + \underbrace{\sum_t P^c_{it}}_{\underset{(4)}{\text{Payments to capital}}})
\end{align*}

A few borrowers take more than one loan on the first day they appear in an experimental branch.  These are treated as different observations. Table \ref{multiple_loans} shows our results are similar when dealing with the multiplicity of loans per borrower. Each regression includes branch and day-of-week FE. Standard errors are clustered at the branch-day level. 

%\textit{Do file: } \texttt{decomposition\_main\_te.do}
\end{table}



\newpage
\begin{landscape}
\begin{table}[H]
\caption{Effects on intermediate outcomes}
\label{mechanisms}
\begin{center}
\resizebox{1.30\textwidth}{!}{
\scriptsize{\input{./Tables/mechanism.tex}}
}
\end{center}

%\textit{Do file: } \texttt{mechanisms.do}
\end{table}

\scriptsize {
\noindent This table explores treatment effects in ``intermediate variables''. Each column represents regression output for different dependent variables following equation (\ref{basic_reg}). Panel A focuses on variables related to the speed of payment. While Panel B focuses on variables related to default, and Panel C related to visits. The outcome variables are as follows:  number of days elapsed between origination and first payment (col 1); percentage of the loan paid in the first payment (col 2); probability of recovery in the first visit (col 3); loan duration is the number of days the borrower took to payoff her loan for those that recover, the number of days until default for those that default, and the maximum number of days we observe them in the sample for those that have not recovered or defaulted (col 4); loan duration conditional on recovery; an indicator for paying a positive amount towards recovery but nonetheless losing the pawn (col 6); the percentage or the loan paid, conditional on defaulting --`wasted payments' (col 7). Column 8 uses the phrase `selling the pawn' for a dummy variable indicating the borrower did not pay any amount towards recovery and lost the pawn. Moreover, (col 9) shows that treatment effects are concentrated in the intensive margin as treatment does not affect the fraction of clients who pay a positive amount towards pawn recovery. The dependent variable in column 10 is the number of day-visits to the branch (measured by the existence of transactions that day associated with our particular pawn), while column 11 conditions on borrowers that lost the pawn. Each regression includes branch and day-of-week FE. Standard errors are clustered at the branch-day level.}
%In sum, we find that the Forced commitment contract clients pays 13.8 days earlier in average, during this first visit, clients pay 7.7\% more of the loan amount, with a 8\% increase probability of recovery. Moreover, the forced commitment contract reduces the probability of defaulting and making a positive payment by 7\%, thus another channel for savings is that treatment helps avoid making payments toward recovery but defaulting.}

\vspace{3ex}

\end{landscape}




\begin{table}[H]
\caption{Effects on more comprehensive cost measures}
\label{table_robustness_fc}
\begin{center}
\scriptsize{\input{./Tables/fc_robustness.tex}}
\end{center}
 \scriptsize 
 This table augments the measure of financial cost presented in Table \ref{main_impact_table} with measures of transaction costs, subjective costs, and adjustments for liquidity costs. Column 1 replicates the result of column 1 of Table \ref{main_impact_table} to ease comparability. Column 2 uses the subjective value of the pawn instead of the assessed gold value. Column 3 uses the cost from column 1 but adds to it the self-reported transport cost (most use public transport, imputing missing values with the average) as well as a whole day's minimum wage as a proxy for lost time. Column 4 ignores the `liquidity' cost in the financial cost formula by subtracting the interest of 7\% per month for each peso paid. Column 5 applies all these extra costs at the same time. Columns 6 to 10 apply the analogous changes to the APR formula. Each regression includes branch and day-of-week FE. Standard errors are clustered at the branch-day level.


%\textit{Do file: } \texttt{fc\_robustness.do}
\end{table}





\cleardoublepage


%\begin{landscape}

\begin{table}[H]
\caption{Effects on Repeat Pawning}
\label{repeat_loans}
\begin{center}
\scriptsize{\input{./Tables/repeat_loans.tex}}
\end{center}
 \scriptsize
This table estimates the specification of equation \ref{basic_reg} but at the level of the borrower (not the loan). Each column represents a regression with a different outcome variable. In column 1, the dependent variable indicates, for each borrower in the experiment, whether he/she pawned again after the first loan in the experiment (up to the end period of our data set 338 days after the experiment began). Column 2 is analogous, but only pawning after 90 days of the first loan is considered. Column 3 instead considers pawning before 90 days. Column 4 is analogous to column 1 but focuses on the pawning of a gold piece that is different from the one in the first experimental loan. Column 5 is analogous to column 1, but conditioning on the sample that recovered the first loan. Each regression includes branch and day-of-week FE. Standard errors are clustered at the branch-day level.
%\textit{Do file: } \texttt{repeat\_loans.do}
\end{table}
%\end{landscape}

\cleardoublepage

\begin{table}[H]
\caption{Treatment on the Treated (TOT), Treatment on the Untreated (TUT), Selection-on-gains (TOT - TUT), Average Selection Bias (ASB), and Average Selection Bias, calculated using the results from Section \ref{sec:randchoice}.}
\label{tot_tut}
\begin{center}
\scriptsize{\input{./Tables/tot_tut.tex}}
\end{center}
\scriptsize
This table presents results computed using the derivations from Section \ref{sec:randchoice} and \ref{append:randchoice}. 
Each column corresponds to an outcome variable: APR in column (1), financial cost in column (2), an indicator for \emph{not} defaulting in column (3), and an indicator for \emph{not} refinancing in column (4). 
The APR and financial cost outcomes have been multiplied by $-1$ so that a positive causal effect \emph{benefits} the borrower in each of the four columns.
The top panel presents treatment on the treated (TOT) and treatment on the untreated (TUT) effect estimates, with standard errors clustered at the branch-day level.
The average treatment effect (ATE) results from Section \ref{Experiment} are presented for purposes of comparison, along with average treated and untreated potential outcomes.
The middle panel presents estimates of the average selection on gains $(\text{TOT} - \text{TUT})$, along with the average selection bias (ASB) and the average selection on levels (ASL), again with standard errors clustered at the branch-day level.
See Appendix \ref{subsec:inference} for more details on how we compute standard errors for the middle panel.
The bottom panel present sample sizes, and p-values for a number of null hypothesis tests of treatment effect heterogeneity. 
%\textit{Do file: } \texttt{tot\_tut.do}
\end{table}

\begin{table}[H]
\caption{Type I \& II errors using targeting narrow rules}
\label{hit_miss_rule}
\begin{center}
\resizebox{0.95\textwidth}{!}{
\small{\input{./Tables/hit_miss_rule.tex}}
}
\end{center}
\scriptsize This table reports error rates for six different rules for allocating individuals to commitment. The first row allocates all borrowers to control. Taking the conditional ATE estimates from the ``wide'' causal forest, described in Section \ref{sec:RF} as ground truth, this results in 87\% of individuals losing by not receiving commitment. The second row assigns all borrowers to forced commitment, yielding error rates that are the exact mirror image of those from the first row.  The third row considers the infeasible optimum in which each borrower is allocated the ``correct'' treatment, treating the estimate from the ``wide'' causal forest as ground truth. The fourth and fifth rows assign borrowers to commitment based on a classification model that uses the narrow covariate set to predict an indicator for whether the ``wide'' random forest CATE estimate is positive. Row four uses a random forest classification model while row five uses a simple logistic regression model. In each of these rows, the assignment rule ranks borrowers from highest to lowest by their estimated probability of having a positive CATE. The 91\% of borrowers with the highest estimated probabilities are assigned to treatment, matching the overall rate of positive CATE estimates from the ``wide'' RF model. The sixth row gives the percentage of miss-classification that would follow from the observed choice. 
%assigns the commitment contract to all borrowers with a positive conditional ATE estimate from the ``narrow'' RF. The fifth row uses a logistic regression to estimate the probability that a given borrower has a positive conditional ATE, assigning commitment to those with an estimated \hl{probability greater than 0.5}.

\end{table} 

\vspace{.3in}

%\begin{table}[H]
%\caption{Overconfidence: Take-up and Treatment Effects}
%\label{oc_reg}
%\begin{center}
%\scriptsize{\input{./Tables/oc_reg.tex}}
%\end{center}
% \footnotesize This table shows the parameter estimates of $y_i = \alpha + \beta \: OC_i + Z_i'\gamma + \epsilon_i$, where $OC_i:=\mathbbm{1}(P^s_i-\widehat{P_i(X_i)}>0)$ is an indicator for the subjective probability of recovery being larger than the predicted one. In columns 1-4 $y_i$ is a dummy for whether the client $i$ chose to have the commitment contract in the respective choice arm, and in columns 5 and 6 $y_i$ is the heterogeneous treatment effect for financial cost (in pesos) estimated by comparing the Forced Commitment vs status quo arms in Section \ref{TE_fee-forcing}. Columns 1 and 3 are estimated for the promise-choice arm, while columns 2 and 4 are estimated for the Commitment Choice arm. The low number of observations results from  our use of  covariates for $\widehat{P(x)}$ and in $Z$ in the regression, given that some of them are missing.
%\textit{Do file: } \texttt{oc.do}
%\end{table}


%\begin{table}[H]
%\caption{Overconfidence: Take-up and Treatment Effects}
%\label{oc_reg}
%\begin{center}
%\scriptsize{\input{./Tables/oc_reg_dec.tex}}
%\end{center}
% \footnotesize This table shows the parameter estimates of $y_i = \alpha + \beta \: OC_i + Z_i'\gamma + \epsilon_i$, where $OC_i:=\mathbbm{1}(P^s_i-\widehat{P_i(X_i)}>0)$ is an indicator for the subjective probability of recovery being larger than the predicted one. In columns 1-4 $y_i$ is a dummy for whether the client $i$ chose to have the commitment contract in the respective choice arm, and in columns 5 and 6 $y_i$ is the heterogeneous treatment effect for financial cost (in pesos) estimated by comparing the Forced Commitment vs status quo arms in Section \ref{TE_fee-forcing}. Columns 1 and 3 are estimated for the promise-choice arm, while columns 2 and 4 are estimated for the Commitment Choice arm. The low number of observations results from  our use of  covariates for $\widehat{P(x)}$ and in $Z$ in the regression, given that some of them are missing.
%\textit{Do file: } \texttt{oc.do}
%\end{table}







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Figures}




\vspace{.2in}
\begin{figure}[H]
     \caption{Financial cost}
    \label{fc_hist}
    \begin{center}
    \begin{subfigure}{.45\textwidth}
      \caption{In pesos MXN}
        \centering
        \includegraphics[width=\textwidth]{Figuras/hist_fc.pdf}
    \end{subfigure}
     \begin{subfigure}{0.45\textwidth}
    \caption{Effective APR}
       \centering
      \includegraphics[width=\textwidth]{Figuras/hist_apr.pdf}
    \end{subfigure}
    \end{center}
         \scriptsize
         Panel (a) presents a histogram of financial cost (defined as in Section \ref{costs}) for the control group. The figure plots separately the financial cost separately for borrowers who lose the pawn (blue) and those that recover it (transparent).  Panel (b) is analogous but displays the APR.  %Given that the loan lasts close to 90 days, bringing payments to present value makes little difference. 
       
      %\footnotesize{ } \textit{Do file: }  \texttt{hist\_fc.do}
\end{figure}




\begin{figure}[H]
     \caption{Experiment description}
    \label{exp_description}
\begin{center}
\begin{subfigure}{\textwidth}
        \includegraphics[width=\textwidth]{Figuras/consort.pdf}
    \end{subfigure}
  \end{center}
    \scriptsize 
    
%\textit{Do file: }  \texttt{ss\_att.do}
\end{figure}


\begin{figure}[H]
     \caption{Contract Terms Summary}
    \label{PaperSlip}
    \begin{center}
    %\begin{subfigure}{0.65\textwidth}
    %\caption{Receipt for client}
     %   \centering
        \includegraphics[width=0.65\textwidth]{Figuras/TicketLenderP.png}
    %\end{subfigure}
    
    %\vspace{3ex}
    %\begin{subfigure}{0.65\textwidth}
    %\caption{Personal promise signed by client}
     %   \centering
    %    \includegraphics[width=\textwidth]{Figuras/Personal Promise2.png}
    %\end{subfigure}
    \end{center}
    \scriptsize
        We show a sample receipt that was given to clients that got assigned to the fee-forcing contract (the font and format were changed to protect Lender's P identity). We want to highlight the salience of some items. First the title clearly indicated which contract the client has (arrow 1). Second, in the case of the fee contract it clearly indicates that there is a fee for paying late equivalent to 2\% of the value of the monthly payment (arrow 2). Third, there is a calendar for payments clearly specifying the dates and amounts to pay each month. %The bottom panel of the figure shows a ``promise slip'', the paper that those who were assigned (or chose) to the monthly payment with promise had to sign to make the promise salient. It emphasizes that the client is giving his word, and that the promise is not a legal document.
\end{figure}





\begin{figure}[H]
     \caption{Explanatory Material}
    \label{ExplanatoryMaterial}
    \begin{center}
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figuras/micas.pdf}
    \end{subfigure}
    \end{center}
    \scriptsize
        This is a (translated) sample information slide shown to clients. The real ones were twice the size of this figure and were laminated. Different ones were shown for each treatment arm.
\end{figure}







\cleardoublepage







\cleardoublepage


\begin{comment}

\begin{figure}[H]
     \caption{TOT \& TUT as LATE}
    \label{tot_tut_graph}
    \begin{center}
    \begin{subfigure}{0.9\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figuras/tot_tut_apr.eps}
    \end{subfigure}
    \end{center}
    \scriptsize
   \hl{REPLACE THIS ONE WITH THE ONE IN THE PRESENTATION}
     %\textit{Do file: }  \texttt{tot\_tut\_graph.do}
\end{figure}
\end{comment}

\vspace{.3in}
\begin{figure}[H]
    \caption{Fan \& Park bounds for benefit in APR\%}
    \label{fan_park_bounds}
    \begin{center}
    \begin{subfigure}{0.75\textwidth}
        \caption{APR}
        \centering
        \includegraphics[width=\textwidth]{Figuras/fan_park_bounds_apr.pdf}
    \end{subfigure}
    \end{center}
        \scriptsize
    This figure depicts the \cite{fan2010sharp} bounds on the distribution $F_\Delta$ of individual treatment effects $\Delta \equiv (Y_1 - Y_0)$, described in Section \ref{sec:bounds}, for the APR outcome.
    The dark red curve and light red shaded region give the estimated upper bound function $\overline{F}$ for $F_\Delta$ and associated (pointwise) 95\% confidence interval. 
    The dark blue curve and light blue shaded region give the estimated lower bound function $\underline{F}$ for $F_\Delta$ and associated (pointwise) 95\% confidence interval.
    Confidence intervals are computed using the asymptotic distribution for the bounds. See \cite{fan2010sharp} for details.
    The bounds are pointwise sharp: at any specified value of $\delta$ the bounds $\underline{F}(\delta) \leq F_\Delta(\delta) \leq \overline{F}(\delta)$ cannot be improved without imposing additional assumptions.
    Evaluating the bounds at $\delta = 0$, we see that between 24\% and 97\% of borrowers have a positive individual treatment effect.
    This is greater than the share of borrowers who chose commitment: 11\%.
%\textit{Do file: } \texttt{fan\_park\_bnds.do}       
\end{figure}




\begin{figure}[H]
\caption{The Controlled Choice Design}
    \label{tot_tut_graph}
    \begin{center}
        \centering
        \includegraphics[width=1.0\textwidth]{Figuras/tot_tut_intuition.png}
    \end{center}
    \scriptsize
    This figure provides graphical intuition for the way in which the controlled choice design from Section point identifies both the treatment on the treated (TOT) and treatment on the untreated (TUT) effects, as discussed in Section \ref{sec:randchoice} and \ref{append:randchoice}. 
    The gray shaded regions denote borrowers with a commitment contract; the white shaded regions denote borrowers with a status quo contract.
    A comparison of means across control and forcing arms identifies the ATE of forcing  commitment.
    The TOT and TUT effects of commitment are identified as follows.
    In the choice arm, anyone with a commitment contract is a chooser; in the control and forcing arms, we do not know who is a chooser and who is not.
    Because borrowers are randomly assigned to experimental treatment arms, however, the share of choosers will be the same, on average, across experimental arms.
    This is depicted using dashed vertical lines in the control and forcing arms.
    This overall share of choosers and non-choosers is point identified from the choice arm.
    Now, the difference of mean outcomes across the choice and control arms gives the intent-to-treat effect of offering choice.
    Under the exclusion restriction that moving non-choosers between the choice and forcing arms does not change their outcomes, this comparison ``nets out'' the non-choosers.
    Hence, the ITT of offering choice equals the TOT multiplied by the share of choosers. 
    Similarly, under the exclusion restriction that moving choosers between the choice and forcing arm does not affect their outcomes, the difference of means across the forcing and choice arms ``nets out'' the choosers and hence equals the TUT multiplied by the share of non-choosers.
    

     %\textit{Do file: }  \texttt{tot\_tut\_graph.do}
\end{figure}   







\begin{figure}[H]
    \caption{Partition of TUT by behavioral variables.}
    \label{tut_beh_partition}
    \begin{center}
        \centering
        \includegraphics[width=0.75\textwidth]{Figuras/tut_beh_partition.pdf} 
    \end{center}
     \scriptsize  Each panel in this figure shows how the estimated treatment on the untreated (TUT) effect varies with a binary survey variable $X_i$. In the left panel (P.B.), $X_i = 1$ if borrower $i$ is ``present-biased'' based on her responses to the time preference questions from our survey. In the right panel (Sure-confidence) $X_i = 1$ if  borrower $i$ reported that she was certain to recover her pawn, zero otherwise. Each panel depicts three estimates and associated 95\% confidence bands: the overall TUT (blue), the TUT for borrowers with $X = 1$ (green), and the TUT for borrowers with $X = 0$ (red). By the law of iterated expectations, the overall TUT in each panel must lie between the group-specific TUTs. The overall TUT is slightly different in each panel, because some borrowers only completed part of the survey. In each panel, we present results for the full set of borrowers who answered the survey question or questions needed to determine $X_i$. From the left panel, we see that TUT does not appear to vary with present bias. In contrast, the right panel suggests that the positive and significant overall TUT is driven by individuals who are ``sure-confident,'' i.e.\ borrowers who report that they are certain to recover their pawn.
     %to be largely concentrated relevant survey question  according to her survey responses two binary performs a partition of the Treatment on the Untreated (FC), estimating the share of the effect that arises within each of two binary categories.  The top bars examine present bias (individuals are more impatient over one-month time horizon than they are between three and four months).  The bottom bars examine sure confidence (individual reports 100\% probability of repaying at time of taking loan).  Blue bar is the component arising from those without the trait, orange bar from those with the trait. 
      %\footnotesize{ \textit{Do file: }  \texttt{partition_tut.do}

\end{figure}







\begin{figure}[H]
     \caption{Heterogeneous Treatment Effects}
    \label{heterogeneous_effects}
    \begin{center}
     \begin{subfigure}{0.55\textwidth}
    \caption{ToT}
       \centering
      \includegraphics[width=\textwidth]{Figuras/he_dist_tau_hat_tot.pdf}
    \end{subfigure}
    \begin{subfigure}{0.55\textwidth}
    \caption{TuT}
       \centering
      \includegraphics[width=\textwidth]{Figuras/he_dist_tau_hat_tut.pdf}
    \end{subfigure} 
       \begin{subfigure}{.55\textwidth}
      \caption{ATE}
        \centering
        \includegraphics[width=\textwidth]{Figuras/he_dist_tau_hat_eff.pdf}
    \end{subfigure} 
      
          
    \end{center}
         \scriptsize
     This Figure plots the densities of treatment on the untreated effects (TUT), treatment on the treated (TOT) effects, and conditional average treatment effects (ATE) based on the instrumental and causal forest models from Section \ref{sec:RF}.
  %\footnotesize{ } \textit{Do file: }  \texttt{cate_dist.do}
\end{figure}


\begin{figure}[H]
    \caption{``Mistakes'' in the choice arm}
    \label{choose_wrong}
   % \begin{center}
   %     \begin{subfigure}{0.45\textwidth}
   %     \caption{``Mistakes'' in choice arm}
        \centering
        \includegraphics[width=0.75\textwidth]{Figuras/line_cw_apr_tot_tut.pdf}
  %  \end{subfigure}
  %      \begin{subfigure}{0.45\textwidth}
  %      \caption{\% with positive CATE from forced commitment}
  %      \centering
  %      \includegraphics[width=\textwidth]{Figuras/line_better_forceall_apr_te_cf.pdf}
        
  %  \end{subfigure}
    
  %  \end{center}
        %\scriptsize
        %In Panel (a) we estimate what the treatment effect of the commitment contract \textit{would have been} for all subjects in the choice arm if they had been forced into the fee-commitment contract. To do this we proceed in two steps. First, we estimate treatment effects in the forcing arm by comparing the Forced Commitment arm against the status quo arm. We let these effects be heterogeneous as a function of our $x$'s using \cite{atheygrf}'s methodology of causal forests. Second, we extrapolate these treatment effects based on the choice arm using the same $x$'s. Once we have personalized counterfactual treatment effects in the choice arm we calculate what fraction of subjects in the choice arm incurred in financial costs that are  $> z$\% than if they had chosen the opposite contract of what they actually chose, were $z$\% is defined as a fraction of the loan. $z$\% is a level of tolerance we can vary and we plot it in the X-axis. The left Y-axis measures the fraction of subjects that would have been better by a margin of $z$\% if they changed their choice, and the right Y-axis measures the amount of money ``left on the table''. We use bootstrap to tighten the confidence intervals (CIs). \cite{atheygrf}'s heterogeneous treatment effect using GRF is asymptotically normal. We compute the HTE ($\mu$) together with standard errors ($\sigma$) . For every pledge, we draw a random effect from a normal distribution with parameters ($\mu$,$\sigma^2$), and compute via bootstrap the percentage that choose wrong, along normal-approximation CIs (results are robust if we use instead percentile CIs or bias-corrected CIs) . This allows us to estimate a distribution for the upper and lower bound CIs, which we then use to obtain a 95\% CI. Panel (b) is analogous to Panel (a) except that it does the exercise separately for clients we classified as overconfident ($OC_i:=\mathbbm{1}(P^s_i-\widehat{P_i(X_i)}>0))$ and those we classified as not overconfident. Panel (c) simulates what percentage would be better by at least $z$ if we forced everybody of those in the Commitment Choice arm into the fee-commitment contract.
        % Panel (d) asks whether it is the case that people with larger causal benefits from the Forced Commitment contract would be more likely to select that contract. To do this we proceed in two steps as well. First we estimate a flexible model of take-up of the fee commitment contract \textit{in the choice arm} using random forests, and from this model obtain a probability $P(x_i)$ of choosing the Forced Commitment contract for a client with characteristics $x_i$. We extrapolate this model to clients in the Forced Commitment arm to estimate what would they have chosen if we had given them choice. 
        % Figure (d) plots $\widehat{P(x_i)}$ in the X-axis using a binscatter that splits the X-axis in 100 percentile bins. The Y-axis plots the heterogeneous treatment effects of the fee forcing contract on the probability of losing the pawns (more negative means then more likely to recover it), averaged for the respective x-axis bin. Positive assortative selection would mean a negative relationship: those who benefit more by treatment and lose the pawn less are \emph{less} likely to choose it.  Using all bins we estimate a slope of zero in the relationship. Using the 80 right most points, we estimate a \textit{positive} relationship.
        %\textit{Do file: }  \texttt{choose\_wrong\_quant\_wrong.do, choose\_wrong\_quant\_wrong\_decomposition.do}
\end{figure}


This figure presents conditional average TUT and TOT effects for the APR outcome from Figure \ref{heterogeneous_effects} in an alternative manner, to consider the fraction of borrowers in the choice arm who made ``mistakes'' in their decision to accept or refuse the commitment contract. A ``mistake'' for a non-chooser is defined as a positive conditional TUT effect that significantly exceeds a specified threshold APR value. The green curve equals $[1 - F_{\text{TUT}}(\delta)]\times 100\%$, where $F_{\text{TUT}}$ is the CDF corresponding to density of conditional TUT effects from Figure \ref{heterogeneous_effects}, computed using the instrumental forest approach from \cite{atheygrf}. Evaluated at any positive value on the horizontal axis, it gives the fraction of non-choosers in the choice arm who made a ``mistake'' by not choosing commitment. The green shaded region gives associated 95\% pointwise confidence bands. 
Analogously, a ``mistake'' for a chooser is defined as a negative conditional TOT effect that exceeds a specified threshold APR value. The red curve equals $F_{\text{TOT}}(-\delta)$ where $F_{\text{TOT}}$ is the CDF corresponding to the density of conditional TOT effects from Figure \ref{heterogeneous_effects}. 
The red shaded region gives associated 95\% pointwise confidence bands.
For both the red and green curves, we define the APR threshold so that larger mistakes are to the \emph{right} of smaller mistakes.
This allows us to construct the overall fraction of mistakes in the choice arm, the blue curve, as a weighted average of the green and red curves.
The weights equal the share of choosers and non-choosers in the choice arm.

%\todo[inline]{Panel (a). Green line: survival function computed using estimated TUT of non-choosers in the choice arm. Red line: $F(-x)$ where $F$ is the CDF of individual TOT estimates for the choosers in the choice arm. Blue curve is the weighted average of the green and red with weights equal to the share of choosers versus non-choosers in the choice arm. Panel (b) is the survival function for the ATE computed for who? We think it's for the choice arm. (Shouldn't make a difference because of randomization and fairly large sample sizes.) Confidence bands are computed how? Use asymptotic normality and variance for each ``cell''}


\cleardoublepage

\begin{figure}[H]
    \centering
  \caption{Cumulative Distribution Function of Conditional ATE Estimates}
  \includegraphics[width=0.75\textwidth]{Figuras/line_better_forceall_apr_te_cf.pdf} 
    \label{fig:CATEsurvival}
\end{figure}
 
This figure shows the share of borrowers who benefit from forced commitment, where ``benefit'' is defined as having an estimated conditional average treatment effect (ATE) above a specified threshold value. Results are based on the causal forest model from Section \ref{sec:RF}. The solid line equals $1 - F_\text{ATE}(\delta)$ where $F_\text{ATE}(\delta)$ denotes the CDF corresponding to the density of conditional ATE estimates from Figure \ref{heterogeneous_effects}. The blue shaded regions are associated 95\% confidence intervals. We estimate that at least 91\% of borrowers have a positive conditional ATE. 


  
\cleardoublepage

\begin{figure}[H]
    \caption{Conditional ATEs from ``wide'' and ``narrow'' covariate sets}
    \label{wide_narrow_forests}
    \begin{center}
    \begin{subfigure}{0.75\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figuras/scatter_hist_wide_narrow.pdf}
    \end{subfigure}
    \end{center}
      \scriptsize  This figure plots the relationship between the causal forest conditional ATE estimates from Section \ref{sec:RF} that use the ``wide'' set of covariates (all intake survey responses) and those based on a restricted ``narrow'' set of covariates (age, gender, HS education, and previous borrowing). The scatterplot graphs one estimate versus the other, with the ``wide'' covariate set on the horizontal axis and the ``narrow'' set on the vertical axis. The density plots on each axis show the estimated marginal distribution of conditional ATEs under each covariate set. The density for the ``wide'' covariate set is considerably more dispersed, as the causal forest based on this set of covariates captures considerably more treatment effect heterogeneity.

%\textit{Do file: } \texttt{wide_narrow_forests.do}       
\end{figure}


\begin{figure}[H]
    \caption{Targeting rules}
    \label{targeting_rules}
    \begin{center}
    \begin{subfigure}{0.75\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figuras/wide_narrow_rule.pdf}
    \end{subfigure}
    \end{center}
      \scriptsize   This figure plots the percentage of borrowers who would benefit from a program in which commitment is targeted using the ``narrow'' covariate set (age, gender, HS education, and previous borrowing). In this exercise ``benefit'' is defined to mean having a conditional ATE above a particular threshold, taking the estimated conditional effects from the ``wide'' causal forest as ground truth. The plot compares the estimated percentage of borrowers who benefit, along with associated 95\% confidence bands, for three targeting rules: universal forced commitment in blue, targeting based on a random forest classification model in green, and targeting based on the logit model in red. For each of the classification models, the outcome variable is an indicator for whether the CATE estimate from the ``wide'' random forest model is positive. Each of the classification models produces an estimated probability of a positive CATE. For each, the assignment rule ranks borrowers by this estimated probability, and assigns the highest 92\% to forced commitment, to match the overall percentage of borrowers with positive estimated CATEs from the ``wide'' random forest model. Because this is an in-sample exercise, it overstates the actual performance of logit and RF-based targeting. 
      %, the top \hl{XXX\%} of Both targeted Both of the targeted assignment rules are assigned by a the ``narrow'' causal forest in green, and targeting based on the logit model in red. The causal forest rule assigns a borrower to commitment if her estimated conditional ATE from the ``narrow'' covariate set is positive; the logistic regression rule assigns her to commitment if the estimated probability that her conditional effect is positive is greater than 0.5. 
      %\todo[inline]{@Issac: Have I described this correctly? Also, is this an out-of-sample exercise. In other words, are we using a holdout sample to make these comparisons?}

      %This figure plots the (reversed) cumulative densities of the estimated benefits from the casual forest for three different rules.  The blue line plots the HTEs from the `wide' random forest for the Forcing arm, which we take as the ground truth for actual impacts.  The green line plots HTEs if we first target individuals using the variables in the `narrow' forest, and only assign individuals to commitment if they are on a leaf whose predicted forcing benefit is positive.  The red line uses a logit regression to predict which individuals benefit from treatment, and assigns all individuals to the arm predicted to be best for them.

\end{figure}





    
% \begin{figure}[H]
%     \caption{Negative selection on treatment effects}
%     \label{benefit_vs_choice_cdf}
%     \begin{center}
%     \begin{subfigure}{0.475\textwidth}
%         \caption{APR benefit}
%         \centering
%         \includegraphics[width=\textwidth]{Figuras/cdf_predchoose_tau_apr.pdf}
%     \end{subfigure}
%     \begin{subfigure}{0.475\textwidth}
%         \caption{Repayment}
%         \centering
%         \includegraphics[width=\textwidth]{Figuras/cdf_predchoose_tau_des.pdf}
%     \end{subfigure}
%     \begin{subfigure}{0.475\textwidth}
%         \caption{Default}
%         \centering
%         \includegraphics[width=\textwidth]{Figuras/cdf_predchoose_tau_def.pdf}
%     \end{subfigure}
%     \end{center}
%      \scriptsize    CDF of the heterogeneous treatment effect for choosers vs non-choosers. The dotted line below indicates the points where the difference in the distributions is significant.  Instead of a single global null hypothesis (that the two CDFs are identical), there is a continuum of individual null hypotheses of CDF equality at each point. This methodology was proposed by \cite{GOLDMAN2018143}.
     
     
%      \hl{Isaac : If I recall correctly we agreed to not work with the propensities. Besides this is giving us different results(?) - this was due to not using actual choosers and the prop. score model not being very good. Thus this will be removed? }
%           %\footnotesize{ \textit{Do file: }  \texttt{benefit\_choice.do}}
% \end{figure}

















\newpage
\input{OA.tex}

\end{document}
